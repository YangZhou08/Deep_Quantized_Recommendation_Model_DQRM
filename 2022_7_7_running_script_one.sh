#PBS -N dlrm_training 
bash run_dist.sh -np 4 -ppn 4 -f $PBS_NODEFILE python dlrm_s_pytorch.py --arch-sparse-feature-size=16 --arch-mlp-bot=13-512-256-64-16 --arch-mlp-top=512-256-1 --data-generation=dataset --data-set=kaggle --raw-data-file=/tier1/utexas/kaggleAdCriteoDatasetDLRMNet/train.txt --loss-function=bce --round-targets=True --learning-rate=0.1 --mini-batch-size=128 --print-freq=1024 --print-time --test-mini-batch-size=16384 --test-num-workers=4 --dataset-multiprocessing | tee 7_7_2022_cpu_training_log_two.txt
