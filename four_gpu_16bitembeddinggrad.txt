rank: 1 test_accu: 2571092.0
get out
1 has test check 2571092.0 and sample count 3273728
Warning: Skipping the batch 3197 with size 602
rank: 0 test_accu: 2571092.0
get out
0 has test check 2571092.0 and sample count 3273728
Warning: Skipping the batch 3197 with size 602
rank: 3 test_accu: 2571092.0
get out
3 has test check 2571092.0 and sample count 3273728
 accuracy 78.537 %, best 78.537 %, roc auc score 0.7959, best 0.7959
Saving model to /home/yz25672/dlrm_criteo_kaggle/save_model_after_training_one1.0.pt
Finished training it 31744/76743 of epoch 1, 140.33 ms/it, loss 0.453437
Finished training it 31744/76743 of epoch 1, 139.82 ms/it, loss 0.450049
Finished training it 31744/76743 of epoch 1, 140.13 ms/it, loss 0.451299
Finished training it 31744/76743 of epoch 1, 140.30 ms/it, loss 0.452392
Finished training it 32768/76743 of epoch 1, 139.49 ms/it, loss 0.453839
Finished training it 32768/76743 of epoch 1, 139.74 ms/it, loss 0.449936
Finished training it 32768/76743 of epoch 1, 139.81 ms/it, loss 0.449566
Finished training it 32768/76743 of epoch 1, 139.87 ms/it, loss 0.452211
Finished training it 33792/76743 of epoch 1, 140.88 ms/it, loss 0.454147
Finished training it 33792/76743 of epoch 1, 141.22 ms/it, loss 0.451051
Finished training it 33792/76743 of epoch 1, 141.29 ms/it, loss 0.448184
Finished training it 33792/76743 of epoch 1, 141.40 ms/it, loss 0.454016
Finished training it 34816/76743 of epoch 1, 143.23 ms/it, loss 0.451172
Finished training it 34816/76743 of epoch 1, 143.62 ms/it, loss 0.450089
Finished training it 34816/76743 of epoch 1, 143.60 ms/it, loss 0.453119
Finished training it 34816/76743 of epoch 1, 143.84 ms/it, loss 0.451943
Finished training it 35840/76743 of epoch 1, 140.49 ms/it, loss 0.453520
Finished training it 35840/76743 of epoch 1, 140.37 ms/it, loss 0.451023
Finished training it 35840/76743 of epoch 1, 140.82 ms/it, loss 0.453279
Finished training it 35840/76743 of epoch 1, 140.97 ms/it, loss 0.451346
Finished training it 36864/76743 of epoch 1, 140.50 ms/it, loss 0.450543
Finished training it 36864/76743 of epoch 1, 140.04 ms/it, loss 0.450816
Finished training it 36864/76743 of epoch 1, 140.39 ms/it, loss 0.451907
Finished training it 36864/76743 of epoch 1, 140.52 ms/it, loss 0.452969
Finished training it 37888/76743 of epoch 1, 140.43 ms/it, loss 0.451264
Finished training it 37888/76743 of epoch 1, 140.96 ms/it, loss 0.452008
Finished training it 37888/76743 of epoch 1, 140.85 ms/it, loss 0.449950
Finished training it 37888/76743 of epoch 1, 140.98 ms/it, loss 0.451617
Finished training it 38912/76743 of epoch 1, 142.24 ms/it, loss 0.451511
Finished training it 38912/76743 of epoch 1, 142.69 ms/it, loss 0.448672
Finished training it 38912/76743 of epoch 1, 142.91 ms/it, loss 0.453573
Finished training it 38912/76743 of epoch 1, 142.91 ms/it, loss 0.451751
Finished training it 39936/76743 of epoch 1, 144.68 ms/it, loss 0.451941
Finished training it 39936/76743 of epoch 1, 143.98 ms/it, loss 0.453509
Finished training it 39936/76743 of epoch 1, 144.77 ms/it, loss 0.451814
Finished training it 39936/76743 of epoch 1, 144.69 ms/it, loss 0.451703
Finished training it 40960/76743 of epoch 1, 145.47 ms/it, loss 0.448846
Finished training it 40960/76743 of epoch 1, 146.27 ms/it, loss 0.452875
Finished training it 40960/76743 of epoch 1, 146.18 ms/it, loss 0.451968
Finished training it 40960/76743 of epoch 1, 146.29 ms/it, loss 0.452324
Testing at - 40960/76743 of epoch 1,
Testing at - 40960/76743 of epoch 1,
Testing at - 40960/76743 of epoch 1,
Testing at - 40960/76743 of epoch 1,
Warning: Skipping the batch 3197 with size 602
Warning: Skipping the batch 3197 with size 602
Warning: Skipping the batch 3197 with size 602
rank: 1 test_accu: 2566380.0
get out
1 has test check 2566380.0 and sample count 3273728
rank: 3 test_accu: 2566380.0
get out
3 has test check 2566380.0 and sample count 3273728
rank: 0 test_accu: 2566380.0
get out
Warning: Skipping the batch 3197 with size 602
0 has test check 2566380.0 and sample count 3273728
rank: 2 test_accu: 2566380.0
get out
2 has test check 2566380.0 and sample count 3273728
 accuracy 78.393 %, best 78.537 %, roc auc score 0.7963, best 0.7963
Saving model to /home/yz25672/dlrm_criteo_kaggle/save_model_after_training_one0.0.pt
Start documenting table 0 gradient in table0epoch1_gradient.txt
Documented table 0 gradients in file table0epoch1_gradient.txt
Start documenting table 3 gradient in table3epoch1_gradient.txt
Documented table 3 gradients in file table3epoch1_gradient.txt
Start documenting table 6 gradient in table6epoch1_gradient.txt
Documented table 6 gradients in file table6epoch1_gradient.txt
Start documenting table 18 gradient in table18epoch1_gradient.txt
Documented table 18 gradients in file table18epoch1_gradient.txt
Start documenting table 20 gradient in table20epoch1_gradient.txt
Documented table 20 gradients in file table20epoch1_gradient.txt
Finished training it 41984/76743 of epoch 1, 144.45 ms/it, loss 0.450697
Finished training it 41984/76743 of epoch 1, 144.16 ms/it, loss 0.451224
Finished training it 41984/76743 of epoch 1, 144.52 ms/it, loss 0.449689
Finished training it 41984/76743 of epoch 1, 144.74 ms/it, loss 0.448914
Finished training it 43008/76743 of epoch 1, 140.95 ms/it, loss 0.449865
Finished training it 43008/76743 of epoch 1, 140.81 ms/it, loss 0.450838
Finished training it 43008/76743 of epoch 1, 141.04 ms/it, loss 0.451166
Finished training it 43008/76743 of epoch 1, 140.48 ms/it, loss 0.451966
Finished training it 44032/76743 of epoch 1, 142.32 ms/it, loss 0.450376
Finished training it 44032/76743 of epoch 1, 142.82 ms/it, loss 0.453902
Finished training it 44032/76743 of epoch 1, 142.64 ms/it, loss 0.450429
Finished training it 44032/76743 of epoch 1, 142.89 ms/it, loss 0.449959
Finished training it 45056/76743 of epoch 1, 142.45 ms/it, loss 0.450043
Finished training it 45056/76743 of epoch 1, 142.87 ms/it, loss 0.452484
Finished training it 45056/76743 of epoch 1, 142.73 ms/it, loss 0.452425
Finished training it 45056/76743 of epoch 1, 142.19 ms/it, loss 0.448628
Finished training it 46080/76743 of epoch 1, 141.88 ms/it, loss 0.452641
Finished training it 46080/76743 of epoch 1, 142.31 ms/it, loss 0.451058
Finished training it 46080/76743 of epoch 1, 142.52 ms/it, loss 0.451271
Finished training it 46080/76743 of epoch 1, 142.63 ms/it, loss 0.450844
Finished training it 47104/76743 of epoch 1, 141.27 ms/it, loss 0.453636
Finished training it 47104/76743 of epoch 1, 140.70 ms/it, loss 0.450809
Finished training it 47104/76743 of epoch 1, 141.32 ms/it, loss 0.450944
Finished training it 47104/76743 of epoch 1, 141.49 ms/it, loss 0.450879
Finished training it 48128/76743 of epoch 1, 139.59 ms/it, loss 0.451876
Finished training it 48128/76743 of epoch 1, 139.31 ms/it, loss 0.450999
Finished training it 48128/76743 of epoch 1, 139.06 ms/it, loss 0.452520
Finished training it 48128/76743 of epoch 1, 139.93 ms/it, loss 0.452197
Finished training it 49152/76743 of epoch 1, 140.93 ms/it, loss 0.451176
Finished training it 49152/76743 of epoch 1, 141.20 ms/it, loss 0.454175
Finished training it 49152/76743 of epoch 1, 141.56 ms/it, loss 0.451547
Finished training it 49152/76743 of epoch 1, 141.41 ms/it, loss 0.450897
Finished training it 50176/76743 of epoch 1, 140.66 ms/it, loss 0.449705
Finished training it 50176/76743 of epoch 1, 141.02 ms/it, loss 0.451929
Finished training it 50176/76743 of epoch 1, 141.19 ms/it, loss 0.451798
Finished training it 50176/76743 of epoch 1, 141.26 ms/it, loss 0.452537
Finished training it 51200/76743 of epoch 1, 141.29 ms/it, loss 0.454097
Finished training it 51200/76743 of epoch 1, 141.97 ms/it, loss 0.449318
Finished training it 51200/76743 of epoch 1, 141.86 ms/it, loss 0.450911
Finished training it 51200/76743 of epoch 1, 142.02 ms/it, loss 0.452371
Testing at - 51200/76743 of epoch 1,
Testing at - 51200/76743 of epoch 1,
Testing at - 51200/76743 of epoch 1,
Testing at - 51200/76743 of epoch 1,
Warning: Skipping the batch 3197 with size 602
rank: 1 test_accu: 2574603.0
get out
1 has test check 2574603.0 and sample count 3273728
Warning: Skipping the batch 3197 with size 602
rank: 0 test_accu: 2574603.0
get out
0 has test check 2574603.0 and sample count 3273728
Warning: Skipping the batch 3197 with size 602
Warning: Skipping the batch 3197 with size 602
rank: 2 test_accu: 2574603.0
get out
rank: 3 test_accu: 2574603.0
2 has test check 2574603.0 and sample count 3273728
get out
3 has test check 2574603.0 and sample count 3273728
 accuracy 78.644 %, best 78.644 %, roc auc score 0.7976, best 0.7976
Saving model to /home/yz25672/dlrm_criteo_kaggle/save_model_after_training_one1.0.pt
Finished training it 52224/76743 of epoch 1, 141.51 ms/it, loss 0.451795
Finished training it 52224/76743 of epoch 1, 141.00 ms/it, loss 0.453058
Finished training it 52224/76743 of epoch 1, 141.85 ms/it, loss 0.447101
Finished training it 52224/76743 of epoch 1, 141.47 ms/it, loss 0.452351
Finished training it 53248/76743 of epoch 1, 140.17 ms/it, loss 0.448222
Finished training it 53248/76743 of epoch 1, 140.58 ms/it, loss 0.450570
Finished training it 53248/76743 of epoch 1, 140.68 ms/it, loss 0.448071
Finished training it 53248/76743 of epoch 1, 140.84 ms/it, loss 0.450754
Finished training it 54272/76743 of epoch 1, 142.32 ms/it, loss 0.449621
Finished training it 54272/76743 of epoch 1, 142.91 ms/it, loss 0.447733
Finished training it 54272/76743 of epoch 1, 142.93 ms/it, loss 0.453346
Finished training it 54272/76743 of epoch 1, 143.02 ms/it, loss 0.450767
Finished training it 55296/76743 of epoch 1, 142.40 ms/it, loss 0.451371
Finished training it 55296/76743 of epoch 1, 141.91 ms/it, loss 0.450407
Finished training it 55296/76743 of epoch 1, 142.54 ms/it, loss 0.448915
Finished training it 55296/76743 of epoch 1, 142.52 ms/it, loss 0.451062
Finished training it 56320/76743 of epoch 1, 141.82 ms/it, loss 0.453186
Finished training it 56320/76743 of epoch 1, 142.23 ms/it, loss 0.450799
Finished training it 56320/76743 of epoch 1, 142.36 ms/it, loss 0.452717
Finished training it 56320/76743 of epoch 1, 142.23 ms/it, loss 0.450847
Finished training it 57344/76743 of epoch 1, 139.79 ms/it, loss 0.450735
Finished training it 57344/76743 of epoch 1, 140.06 ms/it, loss 0.451620
Finished training it 57344/76743 of epoch 1, 140.28 ms/it, loss 0.452758
Finished training it 57344/76743 of epoch 1, 140.22 ms/it, loss 0.451500
Finished training it 58368/76743 of epoch 1, 138.80 ms/it, loss 0.451035
Finished training it 58368/76743 of epoch 1, 139.25 ms/it, loss 0.448301
Finished training it 58368/76743 of epoch 1, 139.28 ms/it, loss 0.448724
Finished training it 58368/76743 of epoch 1, 138.90 ms/it, loss 0.451932
Finished training it 59392/76743 of epoch 1, 144.06 ms/it, loss 0.447830
Finished training it 59392/76743 of epoch 1, 143.62 ms/it, loss 0.447385
Finished training it 59392/76743 of epoch 1, 144.21 ms/it, loss 0.449453
Finished training it 59392/76743 of epoch 1, 144.16 ms/it, loss 0.448249
Finished training it 60416/76743 of epoch 1, 141.57 ms/it, loss 0.449578
Finished training it 60416/76743 of epoch 1, 141.61 ms/it, loss 0.452637
Finished training it 60416/76743 of epoch 1, 141.61 ms/it, loss 0.446946
Finished training it 60416/76743 of epoch 1, 141.23 ms/it, loss 0.449271
Finished training it 61440/76743 of epoch 1, 145.19 ms/it, loss 0.448889
Finished training it 61440/76743 of epoch 1, 145.50 ms/it, loss 0.451275
Finished training it 61440/76743 of epoch 1, 145.63 ms/it, loss 0.451933
Finished training it 61440/76743 of epoch 1, 145.72 ms/it, loss 0.449638
Testing at - 61440/76743 of epoch 1,
Testing at - 61440/76743 of epoch 1,
Testing at - 61440/76743 of epoch 1,
Testing at - 61440/76743 of epoch 1,
Warning: Skipping the batch 3197 with size 602
Warning: Skipping the batch 3197 with size 602
rank: 3 test_accu: 2573300.0
get out
3 has test check 2573300.0 and sample count 3273728
Warning: Skipping the batch 3197 with size 602
rank: 1 test_accu: 2573300.0
get out
1 has test check 2573300.0 and sample count 3273728
rank: 0 test_accu: 2573300.0
get out
0 has test check 2573300.0 and sample count 3273728
Warning: Skipping the batch 3197 with size 602
rank: 2 test_accu: 2573300.0
get out
2 has test check 2573300.0 and sample count 3273728
 accuracy 78.605 %, best 78.644 %, roc auc score 0.7970, best 0.7976
Saving model to /home/yz25672/dlrm_criteo_kaggle/save_model_after_training_one0.0.pt
Start documenting table 0 gradient in table0epoch1_gradient.txt
Documented table 0 gradients in file table0epoch1_gradient.txt
Start documenting table 3 gradient in table3epoch1_gradient.txt
Documented table 3 gradients in file table3epoch1_gradient.txt
Start documenting table 6 gradient in table6epoch1_gradient.txt
Documented table 6 gradients in file table6epoch1_gradient.txt
Start documenting table 18 gradient in table18epoch1_gradient.txt
Documented table 18 gradients in file table18epoch1_gradient.txt
Start documenting table 20 gradient in table20epoch1_gradient.txt
Documented table 20 gradients in file table20epoch1_gradient.txt
Finished training it 62464/76743 of epoch 1, 143.28 ms/it, loss 0.451593
Finished training it 62464/76743 of epoch 1, 143.78 ms/it, loss 0.449519
Finished training it 62464/76743 of epoch 1, 143.54 ms/it, loss 0.450481
Finished training it 62464/76743 of epoch 1, 143.81 ms/it, loss 0.448924
Finished training it 63488/76743 of epoch 1, 142.72 ms/it, loss 0.447632
Finished training it 63488/76743 of epoch 1, 142.27 ms/it, loss 0.450014
Finished training it 63488/76743 of epoch 1, 142.71 ms/it, loss 0.451709
Finished training it 63488/76743 of epoch 1, 142.63 ms/it, loss 0.452377
Finished training it 64512/76743 of epoch 1, 142.22 ms/it, loss 0.453906
Finished training it 64512/76743 of epoch 1, 142.54 ms/it, loss 0.448761
Finished training it 64512/76743 of epoch 1, 142.78 ms/it, loss 0.451207
Finished training it 64512/76743 of epoch 1, 142.82 ms/it, loss 0.448454
Finished training it 65536/76743 of epoch 1, 141.53 ms/it, loss 0.450566
Finished training it 65536/76743 of epoch 1, 141.00 ms/it, loss 0.448576
Finished training it 65536/76743 of epoch 1, 141.49 ms/it, loss 0.450184
Finished training it 65536/76743 of epoch 1, 140.99 ms/it, loss 0.449714
Finished training it 66560/76743 of epoch 1, 142.45 ms/it, loss 0.450072
Finished training it 66560/76743 of epoch 1, 142.87 ms/it, loss 0.450698
Finished training it 66560/76743 of epoch 1, 143.14 ms/it, loss 0.453269
Finished training it 66560/76743 of epoch 1, 143.00 ms/it, loss 0.449423
Finished training it 67584/76743 of epoch 1, 143.00 ms/it, loss 0.448160
Finished training it 67584/76743 of epoch 1, 142.65 ms/it, loss 0.448207
Finished training it 67584/76743 of epoch 1, 143.23 ms/it, loss 0.450489
Finished training it 67584/76743 of epoch 1, 143.29 ms/it, loss 0.449316
Finished training it 68608/76743 of epoch 1, 143.77 ms/it, loss 0.452327
Finished training it 68608/76743 of epoch 1, 144.31 ms/it, loss 0.449631
Finished training it 68608/76743 of epoch 1, 144.19 ms/it, loss 0.451816
Finished training it 68608/76743 of epoch 1, 144.36 ms/it, loss 0.451161
Finished training it 69632/76743 of epoch 1, 142.54 ms/it, loss 0.447694
Finished training it 69632/76743 of epoch 1, 143.08 ms/it, loss 0.451223
Finished training it 69632/76743 of epoch 1, 143.02 ms/it, loss 0.453029
Finished training it 69632/76743 of epoch 1, 142.94 ms/it, loss 0.447605
Finished training it 70656/76743 of epoch 1, 143.19 ms/it, loss 0.449496
Finished training it 70656/76743 of epoch 1, 143.76 ms/it, loss 0.450375
Finished training it 70656/76743 of epoch 1, 143.69 ms/it, loss 0.447535
Finished training it 70656/76743 of epoch 1, 143.57 ms/it, loss 0.449151
Finished training it 71680/76743 of epoch 1, 139.86 ms/it, loss 0.449834
Finished training it 71680/76743 of epoch 1, 140.16 ms/it, loss 0.448995
Finished training it 71680/76743 of epoch 1, 140.31 ms/it, loss 0.452399
Finished training it 71680/76743 of epoch 1, 140.27 ms/it, loss 0.451414
Testing at - 71680/76743 of epoch 1,
Testing at - 71680/76743 of epoch 1,
Testing at - 71680/76743 of epoch 1,
Testing at - 71680/76743 of epoch 1,
Warning: Skipping the batch 3197 with size 602
Warning: Skipping the batch 3197 with size 602
rank: 1 test_accu: 2574563.0
get out
1 has test check 2574563.0 and sample count 3273728
rank: 0 test_accu: 2574563.0
get out
0 has test check 2574563.0 and sample count 3273728
Warning: Skipping the batch 3197 with size 602
rank: 2 test_accu: 2574563.0
get out
2 has test check 2574563.0 and sample count 3273728
Warning: Skipping the batch 3197 with size 602
rank: 3 test_accu: 2574563.0
get out
3 has test check 2574563.0 and sample count 3273728
 accuracy 78.643 %, best 78.644 %, roc auc score 0.7978, best 0.7978
Saving model to /home/yz25672/dlrm_criteo_kaggle/save_model_after_training_one1.0.pt
Finished training it 72704/76743 of epoch 1, 138.84 ms/it, loss 0.450020
Finished training it 72704/76743 of epoch 1, 139.42 ms/it, loss 0.449363
Finished training it 72704/76743 of epoch 1, 139.57 ms/it, loss 0.450117
Finished training it 72704/76743 of epoch 1, 139.56 ms/it, loss 0.450072
Finished training it 73728/76743 of epoch 1, 141.13 ms/it, loss 0.448899
Finished training it 73728/76743 of epoch 1, 141.75 ms/it, loss 0.448200
Finished training it 73728/76743 of epoch 1, 141.58 ms/it, loss 0.450477
Finished training it 73728/76743 of epoch 1, 141.62 ms/it, loss 0.449863
Finished training it 74752/76743 of epoch 1, 139.29 ms/it, loss 0.448318
Finished training it 74752/76743 of epoch 1, 139.41 ms/it, loss 0.450009
Finished training it 74752/76743 of epoch 1, 139.53 ms/it, loss 0.447962
Finished training it 74752/76743 of epoch 1, 139.63 ms/it, loss 0.450780
Finished training it 75776/76743 of epoch 1, 145.49 ms/it, loss 0.448067
Finished training it 75776/76743 of epoch 1, 145.86 ms/it, loss 0.453382
Finished training it 75776/76743 of epoch 1, 146.04 ms/it, loss 0.449431
Finished training it 75776/76743 of epoch 1, 145.85 ms/it, loss 0.450264
Warning: Skipping the batch 76742 with size 14
Warning: Skipping the batch 76742 with size 14
Warning: Skipping the batch 76742 with size 14
Warning: Skipping the batch 76742 with size 14
Finished training it 1024/76743 of epoch 2, 144.78 ms/it, loss 0.449454
Finished training it 1024/76743 of epoch 2, 145.23 ms/it, loss 0.450409
Finished training it 1024/76743 of epoch 2, 145.25 ms/it, loss 0.449145
Finished training it 1024/76743 of epoch 2, 145.34 ms/it, loss 0.449679
Finished training it 2048/76743 of epoch 2, 143.63 ms/it, loss 0.449356
Finished training it 2048/76743 of epoch 2, 144.07 ms/it, loss 0.451277
Finished training it 2048/76743 of epoch 2, 144.20 ms/it, loss 0.449593
Finished training it 2048/76743 of epoch 2, 144.18 ms/it, loss 0.450836
Finished training it 3072/76743 of epoch 2, 143.36 ms/it, loss 0.449255
Finished training it 3072/76743 of epoch 2, 143.79 ms/it, loss 0.450362
Finished training it 3072/76743 of epoch 2, 143.85 ms/it, loss 0.447490
Finished training it 3072/76743 of epoch 2, 143.92 ms/it, loss 0.449827
Finished training it 4096/76743 of epoch 2, 140.13 ms/it, loss 0.450411
Finished training it 4096/76743 of epoch 2, 140.68 ms/it, loss 0.452269
Finished training it 4096/76743 of epoch 2, 140.61 ms/it, loss 0.450631
Finished training it 4096/76743 of epoch 2, 140.51 ms/it, loss 0.448872
Finished training it 5120/76743 of epoch 2, 143.99 ms/it, loss 0.449676
Finished training it 5120/76743 of epoch 2, 144.40 ms/it, loss 0.448718
Finished training it 5120/76743 of epoch 2, 144.58 ms/it, loss 0.447709
Finished training it 5120/76743 of epoch 2, 144.54 ms/it, loss 0.446652
Finished training it 6144/76743 of epoch 2, 144.56 ms/it, loss 0.451335
Finished training it 6144/76743 of epoch 2, 144.99 ms/it, loss 0.450480
Finished training it 6144/76743 of epoch 2, 145.11 ms/it, loss 0.450413
Finished training it 6144/76743 of epoch 2, 145.19 ms/it, loss 0.452726
Finished training it 7168/76743 of epoch 2, 142.81 ms/it, loss 0.450625
Finished training it 7168/76743 of epoch 2, 142.52 ms/it, loss 0.448799
Finished training it 7168/76743 of epoch 2, 143.04 ms/it, loss 0.450811
Finished training it 7168/76743 of epoch 2, 143.18 ms/it, loss 0.452028
Finished training it 8192/76743 of epoch 2, 142.92 ms/it, loss 0.449526
Finished training it 8192/76743 of epoch 2, 143.54 ms/it, loss 0.448509
Finished training it 8192/76743 of epoch 2, 143.41 ms/it, loss 0.449789
Finished training it 8192/76743 of epoch 2, 143.42 ms/it, loss 0.452310
Finished training it 9216/76743 of epoch 2, 142.15 ms/it, loss 0.449844
Finished training it 9216/76743 of epoch 2, 142.56 ms/it, loss 0.451708
Finished training it 9216/76743 of epoch 2, 142.70 ms/it, loss 0.449488
Finished training it 9216/76743 of epoch 2, 142.57 ms/it, loss 0.447825
Finished training it 10240/76743 of epoch 2, 142.72 ms/it, loss 0.449203
Finished training it 10240/76743 of epoch 2, 143.24 ms/it, loss 0.451289
Finished training it 10240/76743 of epoch 2, 143.06 ms/it, loss 0.449153
Finished training it 10240/76743 of epoch 2, 143.27 ms/it, loss 0.449527
Testing at - 10240/76743 of epoch 2,
Testing at - 10240/76743 of epoch 2,
Testing at - 10240/76743 of epoch 2,
Testing at - 10240/76743 of epoch 2,
Warning: Skipping the batch 3197 with size 602
rank: 0 test_accu: 2574500.0
get out
0 has test check 2574500.0 and sample count 3273728
Warning: Skipping the batch 3197 with size 602
rank: 2 test_accu: 2574500.0
get out
2 has test check 2574500.0 and sample count 3273728
Warning: Skipping the batch 3197 with size 602
rank: 1 test_accu: 2574500.0
get out
Warning: Skipping the batch 3197 with size 602
1 has test check 2574500.0 and sample count 3273728
rank: 3 test_accu: 2574500.0
get out
3 has test check 2574500.0 and sample count 3273728
 accuracy 78.641 %, best 78.644 %, roc auc score 0.7977, best 0.7978
Saving model to /home/yz25672/dlrm_criteo_kaggle/save_model_after_training_one1.0.pt
Finished training it 11264/76743 of epoch 2, 140.76 ms/it, loss 0.448431
Finished training it 11264/76743 of epoch 2, 140.88 ms/it, loss 0.448691
Finished training it 11264/76743 of epoch 2, 140.36 ms/it, loss 0.452270
Finished training it 11264/76743 of epoch 2, 141.13 ms/it, loss 0.446091
Finished training it 12288/76743 of epoch 2, 142.45 ms/it, loss 0.449393
Finished training it 12288/76743 of epoch 2, 142.95 ms/it, loss 0.448064
Finished training it 12288/76743 of epoch 2, 142.94 ms/it, loss 0.449272
Finished training it 12288/76743 of epoch 2, 143.22 ms/it, loss 0.450096
Finished training it 13312/76743 of epoch 2, 140.97 ms/it, loss 0.447267
Finished training it 13312/76743 of epoch 2, 141.68 ms/it, loss 0.446779
Finished training it 13312/76743 of epoch 2, 141.49 ms/it, loss 0.446618
Finished training it 13312/76743 of epoch 2, 141.62 ms/it, loss 0.448260
Finished training it 14336/76743 of epoch 2, 143.82 ms/it, loss 0.447111
Finished training it 14336/76743 of epoch 2, 144.25 ms/it, loss 0.447459
Finished training it 14336/76743 of epoch 2, 144.30 ms/it, loss 0.448565
Finished training it 14336/76743 of epoch 2, 144.23 ms/it, loss 0.449213
Finished training it 15360/76743 of epoch 2, 143.35 ms/it, loss 0.449440
Finished training it 15360/76743 of epoch 2, 143.38 ms/it, loss 0.448126
Finished training it 15360/76743 of epoch 2, 142.94 ms/it, loss 0.451950
Finished training it 15360/76743 of epoch 2, 143.38 ms/it, loss 0.446647
Finished training it 16384/76743 of epoch 2, 144.43 ms/it, loss 0.450237
Finished training it 16384/76743 of epoch 2, 144.09 ms/it, loss 0.449007
Finished training it 16384/76743 of epoch 2, 144.62 ms/it, loss 0.448682
Finished training it 16384/76743 of epoch 2, 144.50 ms/it, loss 0.446984
Finished training it 17408/76743 of epoch 2, 141.91 ms/it, loss 0.451087
Finished training it 17408/76743 of epoch 2, 142.37 ms/it, loss 0.449330
Finished training it 17408/76743 of epoch 2, 142.42 ms/it, loss 0.450296
Finished training it 17408/76743 of epoch 2, 142.14 ms/it, loss 0.450675
Finished training it 18432/76743 of epoch 2, 141.48 ms/it, loss 0.452534
Finished training it 18432/76743 of epoch 2, 141.92 ms/it, loss 0.450061
Finished training it 18432/76743 of epoch 2, 141.82 ms/it, loss 0.449501
Finished training it 18432/76743 of epoch 2, 142.01 ms/it, loss 0.448678
Finished training it 19456/76743 of epoch 2, 143.12 ms/it, loss 0.448165
Finished training it 19456/76743 of epoch 2, 143.51 ms/it, loss 0.446429
Finished training it 19456/76743 of epoch 2, 143.57 ms/it, loss 0.449017
Finished training it 19456/76743 of epoch 2, 143.68 ms/it, loss 0.447725
Finished training it 20480/76743 of epoch 2, 140.50 ms/it, loss 0.450152
Finished training it 20480/76743 of epoch 2, 141.02 ms/it, loss 0.449754
Finished training it 20480/76743 of epoch 2, 140.91 ms/it, loss 0.448663
Finished training it 20480/76743 of epoch 2, 140.94 ms/it, loss 0.449891
Testing at - 20480/76743 of epoch 2,
Testing at - 20480/76743 of epoch 2,
Testing at - 20480/76743 of epoch 2,
Testing at - 20480/76743 of epoch 2,
Warning: Skipping the batch 3197 with size 602
Warning: Skipping the batch 3197 with size 602
rank: 0 test_accu: 2575047.0
get out
0 has test check 2575047.0 and sample count 3273728
Warning: Skipping the batch 3197 with size 602
rank: 1 test_accu: 2575047.0
get out
1 has test check 2575047.0 and sample count 3273728
rank: 2 test_accu: 2575047.0
get out
2 has test check 2575047.0 and sample count 3273728
Warning: Skipping the batch 3197 with size 602
rank: 3 test_accu: 2575047.0
get out
3 has test check 2575047.0 and sample count 3273728
 accuracy 78.658 %, best 78.658 %, roc auc score 0.7984, best 0.7984
Saving model to /home/yz25672/dlrm_criteo_kaggle/save_model_after_training_one0.0.pt
Start documenting table 0 gradient in table0epoch2_gradient.txt
Documented table 0 gradients in file table0epoch2_gradient.txt
Start documenting table 3 gradient in table3epoch2_gradient.txt
Documented table 3 gradients in file table3epoch2_gradient.txt
Start documenting table 6 gradient in table6epoch2_gradient.txt
Documented table 6 gradients in file table6epoch2_gradient.txt
Start documenting table 18 gradient in table18epoch2_gradient.txt
Documented table 18 gradients in file table18epoch2_gradient.txt
Start documenting table 20 gradient in table20epoch2_gradient.txt
Documented table 20 gradients in file table20epoch2_gradient.txt
Finished training it 21504/76743 of epoch 2, 146.05 ms/it, loss 0.448321
Finished training it 21504/76743 of epoch 2, 146.59 ms/it, loss 0.449071
Finished training it 21504/76743 of epoch 2, 146.00 ms/it, loss 0.446852
Finished training it 21504/76743 of epoch 2, 146.40 ms/it, loss 0.447151
Finished training it 22528/76743 of epoch 2, 145.33 ms/it, loss 0.448501
Finished training it 22528/76743 of epoch 2, 145.60 ms/it, loss 0.451439
Finished training it 22528/76743 of epoch 2, 145.94 ms/it, loss 0.447553
Finished training it 22528/76743 of epoch 2, 145.81 ms/it, loss 0.447948
Finished training it 23552/76743 of epoch 2, 144.20 ms/it, loss 0.450679
Finished training it 23552/76743 of epoch 2, 144.73 ms/it, loss 0.450467
Finished training it 23552/76743 of epoch 2, 144.59 ms/it, loss 0.449118
Finished training it 23552/76743 of epoch 2, 144.74 ms/it, loss 0.450327
Finished training it 24576/76743 of epoch 2, 142.57 ms/it, loss 0.447560
Finished training it 24576/76743 of epoch 2, 142.16 ms/it, loss 0.447656
Finished training it 24576/76743 of epoch 2, 142.53 ms/it, loss 0.445913
Finished training it 24576/76743 of epoch 2, 142.51 ms/it, loss 0.446600
Finished training it 25600/76743 of epoch 2, 142.97 ms/it, loss 0.448721
Finished training it 25600/76743 of epoch 2, 143.27 ms/it, loss 0.449917
Finished training it 25600/76743 of epoch 2, 143.37 ms/it, loss 0.448563
Finished training it 25600/76743 of epoch 2, 143.41 ms/it, loss 0.448764
Finished training it 26624/76743 of epoch 2, 143.28 ms/it, loss 0.450610
Finished training it 26624/76743 of epoch 2, 143.63 ms/it, loss 0.450622
Finished training it 26624/76743 of epoch 2, 143.81 ms/it, loss 0.449456
Finished training it 26624/76743 of epoch 2, 143.28 ms/it, loss 0.451264
Finished training it 27648/76743 of epoch 2, 144.12 ms/it, loss 0.448302
Finished training it 27648/76743 of epoch 2, 144.22 ms/it, loss 0.449618
Finished training it 27648/76743 of epoch 2, 144.62 ms/it, loss 0.448697
Finished training it 27648/76743 of epoch 2, 144.51 ms/it, loss 0.449612
Finished training it 28672/76743 of epoch 2, 139.55 ms/it, loss 0.450730
Finished training it 28672/76743 of epoch 2, 140.17 ms/it, loss 0.447484
Finished training it 28672/76743 of epoch 2, 140.37 ms/it, loss 0.446835
Finished training it 28672/76743 of epoch 2, 140.05 ms/it, loss 0.448353
Finished training it 29696/76743 of epoch 2, 142.70 ms/it, loss 0.449555
Finished training it 29696/76743 of epoch 2, 142.46 ms/it, loss 0.450159
Finished training it 29696/76743 of epoch 2, 143.00 ms/it, loss 0.444728
Finished training it 29696/76743 of epoch 2, 143.08 ms/it, loss 0.448482
Finished training it 30720/76743 of epoch 2, 145.33 ms/it, loss 0.448043
Finished training it 30720/76743 of epoch 2, 145.78 ms/it, loss 0.448685
Finished training it 30720/76743 of epoch 2, 145.95 ms/it, loss 0.450564
Finished training it 30720/76743 of epoch 2, 146.01 ms/it, loss 0.448287
Testing at - 30720/76743 of epoch 2,
Testing at - 30720/76743 of epoch 2,
Testing at - 30720/76743 of epoch 2,
Testing at - 30720/76743 of epoch 2,
Warning: Skipping the batch 3197 with size 602
Warning: Skipping the batch 3197 with size 602
Warning: Skipping the batch 3197 with size 602
rank: 2 test_accu: 2575083.0
get out
rank: 1 test_accu: 2575083.0
2 has test check 2575083.0 and sample count 3273728
get out
rank: 0 test_accu: 2575083.0
1 has test check 2575083.0 and sample count 3273728
get out
0 has test check 2575083.0 and sample count 3273728
Warning: Skipping the batch 3197 with size 602
rank: 3 test_accu: 2575083.0
get out
3 has test check 2575083.0 and sample count 3273728
 accuracy 78.659 %, best 78.659 %, roc auc score 0.7991, best 0.7991
Saving model to /home/yz25672/dlrm_criteo_kaggle/save_model_after_training_one1.0.pt
Finished training it 31744/76743 of epoch 2, 143.65 ms/it, loss 0.446894
Finished training it 31744/76743 of epoch 2, 144.25 ms/it, loss 0.448996
Finished training it 31744/76743 of epoch 2, 144.35 ms/it, loss 0.450062
Finished training it 31744/76743 of epoch 2, 144.16 ms/it, loss 0.447487
Finished training it 32768/76743 of epoch 2, 141.38 ms/it, loss 0.450140
Finished training it 32768/76743 of epoch 2, 141.79 ms/it, loss 0.446957
Finished training it 32768/76743 of epoch 2, 141.90 ms/it, loss 0.446507
Finished training it 32768/76743 of epoch 2, 142.15 ms/it, loss 0.448785
Finished training it 33792/76743 of epoch 2, 141.96 ms/it, loss 0.450664
Finished training it 33792/76743 of epoch 2, 142.59 ms/it, loss 0.448000
Finished training it 33792/76743 of epoch 2, 142.71 ms/it, loss 0.450800
Finished training it 33792/76743 of epoch 2, 142.56 ms/it, loss 0.444877
Finished training it 34816/76743 of epoch 2, 140.58 ms/it, loss 0.448067
Finished training it 34816/76743 of epoch 2, 140.92 ms/it, loss 0.449530
Finished training it 34816/76743 of epoch 2, 141.00 ms/it, loss 0.448653
Finished training it 34816/76743 of epoch 2, 141.00 ms/it, loss 0.446414
Finished training it 35840/76743 of epoch 2, 149.62 ms/it, loss 0.449922
Finished training it 35840/76743 of epoch 2, 149.27 ms/it, loss 0.447562
Finished training it 35840/76743 of epoch 2, 149.40 ms/it, loss 0.450519
Finished training it 35840/76743 of epoch 2, 149.82 ms/it, loss 0.448259
Finished training it 36864/76743 of epoch 2, 141.42 ms/it, loss 0.447531
Finished training it 36864/76743 of epoch 2, 141.88 ms/it, loss 0.447270
Finished training it 36864/76743 of epoch 2, 141.65 ms/it, loss 0.449109
Finished training it 36864/76743 of epoch 2, 142.03 ms/it, loss 0.449797
Finished training it 37888/76743 of epoch 2, 142.77 ms/it, loss 0.448524
Finished training it 37888/76743 of epoch 2, 143.46 ms/it, loss 0.448827
Finished training it 37888/76743 of epoch 2, 143.19 ms/it, loss 0.447305
Finished training it 37888/76743 of epoch 2, 143.21 ms/it, loss 0.448424
Finished training it 38912/76743 of epoch 2, 141.79 ms/it, loss 0.449000
Finished training it 38912/76743 of epoch 2, 142.20 ms/it, loss 0.449019
Finished training it 38912/76743 of epoch 2, 141.99 ms/it, loss 0.445605
Finished training it 38912/76743 of epoch 2, 142.42 ms/it, loss 0.450332
Finished training it 39936/76743 of epoch 2, 144.79 ms/it, loss 0.449889
Finished training it 39936/76743 of epoch 2, 145.37 ms/it, loss 0.448536
Finished training it 39936/76743 of epoch 2, 145.13 ms/it, loss 0.448698
Finished training it 39936/76743 of epoch 2, 145.19 ms/it, loss 0.448456
Finished training it 40960/76743 of epoch 2, 143.62 ms/it, loss 0.445738
Finished training it 40960/76743 of epoch 2, 144.21 ms/it, loss 0.448828
Finished training it 40960/76743 of epoch 2, 144.03 ms/it, loss 0.449861
Finished training it 40960/76743 of epoch 2, 143.85 ms/it, loss 0.449174
Testing at - 40960/76743 of epoch 2,
Testing at - 40960/76743 of epoch 2,
Testing at - 40960/76743 of epoch 2,
Testing at - 40960/76743 of epoch 2,
Warning: Skipping the batch 3197 with size 602
rank: 0 test_accu: 2572776.0
get out
0 has test check 2572776.0 and sample count 3273728
Warning: Skipping the batch 3197 with size 602
Warning: Skipping the batch 3197 with size 602
rank: 3 test_accu: 2572776.0
get out
3 has test check 2572776.0 and sample count 3273728
rank: 1 test_accu: 2572776.0
get out
1 has test check 2572776.0 and sample count 3273728
Warning: Skipping the batch 3197 with size 602
rank: 2 test_accu: 2572776.0
get out
2 has test check 2572776.0 and sample count 3273728
 accuracy 78.589 %, best 78.659 %, roc auc score 0.7993, best 0.7993
Saving model to /home/yz25672/dlrm_criteo_kaggle/save_model_after_training_one0.0.pt
Start documenting table 0 gradient in table0epoch2_gradient.txt
Documented table 0 gradients in file table0epoch2_gradient.txt
Start documenting table 3 gradient in table3epoch2_gradient.txt
Documented table 3 gradients in file table3epoch2_gradient.txt
Start documenting table 6 gradient in table6epoch2_gradient.txt
Documented table 6 gradients in file table6epoch2_gradient.txt
Start documenting table 18 gradient in table18epoch2_gradient.txt
Documented table 18 gradients in file table18epoch2_gradient.txt
Start documenting table 20 gradient in table20epoch2_gradient.txt
Documented table 20 gradients in file table20epoch2_gradient.txt
Finished training it 41984/76743 of epoch 2, 144.86 ms/it, loss 0.448479
Finished training it 41984/76743 of epoch 2, 145.32 ms/it, loss 0.445587
Finished training it 41984/76743 of epoch 2, 145.53 ms/it, loss 0.446826
Finished training it 41984/76743 of epoch 2, 145.29 ms/it, loss 0.447384
Finished training it 43008/76743 of epoch 2, 145.55 ms/it, loss 0.449161
Finished training it 43008/76743 of epoch 2, 145.96 ms/it, loss 0.448330
Finished training it 43008/76743 of epoch 2, 146.13 ms/it, loss 0.447020
Finished training it 43008/76743 of epoch 2, 145.95 ms/it, loss 0.447577
Finished training it 44032/76743 of epoch 2, 141.97 ms/it, loss 0.447545
Finished training it 44032/76743 of epoch 2, 142.58 ms/it, loss 0.446585
Finished training it 44032/76743 of epoch 2, 142.35 ms/it, loss 0.447141
Finished training it 44032/76743 of epoch 2, 142.49 ms/it, loss 0.450823
Finished training it 45056/76743 of epoch 2, 142.64 ms/it, loss 0.445766
Finished training it 45056/76743 of epoch 2, 143.20 ms/it, loss 0.449525
Finished training it 45056/76743 of epoch 2, 143.32 ms/it, loss 0.449611
Finished training it 45056/76743 of epoch 2, 143.02 ms/it, loss 0.447452
Finished training it 46080/76743 of epoch 2, 142.52 ms/it, loss 0.449976
Finished training it 46080/76743 of epoch 2, 142.79 ms/it, loss 0.448032
Finished training it 46080/76743 of epoch 2, 143.03 ms/it, loss 0.448212
Finished training it 46080/76743 of epoch 2, 143.20 ms/it, loss 0.447460
Finished training it 47104/76743 of epoch 2, 146.88 ms/it, loss 0.447560
Finished training it 47104/76743 of epoch 2, 147.27 ms/it, loss 0.448185
Finished training it 47104/76743 of epoch 2, 147.35 ms/it, loss 0.450257
Finished training it 47104/76743 of epoch 2, 147.45 ms/it, loss 0.447631
Finished training it 48128/76743 of epoch 2, 143.09 ms/it, loss 0.447734
Finished training it 48128/76743 of epoch 2, 142.88 ms/it, loss 0.448915
Finished training it 48128/76743 of epoch 2, 143.04 ms/it, loss 0.448973
Finished training it 48128/76743 of epoch 2, 142.34 ms/it, loss 0.449443
Finished training it 49152/76743 of epoch 2, 145.56 ms/it, loss 0.448362
Finished training it 49152/76743 of epoch 2, 146.25 ms/it, loss 0.448448
Finished training it 49152/76743 of epoch 2, 146.10 ms/it, loss 0.451127
Finished training it 49152/76743 of epoch 2, 146.15 ms/it, loss 0.448271
Finished training it 50176/76743 of epoch 2, 147.24 ms/it, loss 0.446869
Finished training it 50176/76743 of epoch 2, 147.92 ms/it, loss 0.449022
Finished training it 50176/76743 of epoch 2, 147.89 ms/it, loss 0.448637
Finished training it 50176/76743 of epoch 2, 147.95 ms/it, loss 0.449802
Finished training it 51200/76743 of epoch 2, 144.03 ms/it, loss 0.451063
Finished training it 51200/76743 of epoch 2, 144.49 ms/it, loss 0.446754
Finished training it 51200/76743 of epoch 2, 144.49 ms/it, loss 0.448032
Finished training it 51200/76743 of epoch 2, 144.69 ms/it, loss 0.449970
Testing at - 51200/76743 of epoch 2,
Testing at - 51200/76743 of epoch 2,
Testing at - 51200/76743 of epoch 2,
Testing at - 51200/76743 of epoch 2,
Warning: Skipping the batch 3197 with size 602
rank: 1 test_accu: 2577836.0
Warning: Skipping the batch 3197 with size 602
get out
1 has test check 2577836.0 and sample count 3273728
Warning: Skipping the batch 3197 with size 602
rank: 0 test_accu: 2577836.0
get out
0 has test check 2577836.0 and sample count 3273728
rank: 3 test_accu: 2577836.0
get out
3 has test check 2577836.0 and sample count 3273728
Warning: Skipping the batch 3197 with size 602
rank: 2 test_accu: 2577836.0
get out
2 has test check 2577836.0 and sample count 3273728
 accuracy 78.743 %, best 78.743 %, roc auc score 0.7998, best 0.7998
Saving model to /home/yz25672/dlrm_criteo_kaggle/save_model_after_training_one1.0.pt
Finished training it 52224/76743 of epoch 2, 144.08 ms/it, loss 0.450356
Finished training it 52224/76743 of epoch 2, 144.60 ms/it, loss 0.448861
Finished training it 52224/76743 of epoch 2, 144.83 ms/it, loss 0.443981
Finished training it 52224/76743 of epoch 2, 144.47 ms/it, loss 0.449346
Finished training it 53248/76743 of epoch 2, 140.25 ms/it, loss 0.445408
Finished training it 53248/76743 of epoch 2, 140.56 ms/it, loss 0.445229
Finished training it 53248/76743 of epoch 2, 140.92 ms/it, loss 0.447358
Finished training it 53248/76743 of epoch 2, 140.70 ms/it, loss 0.447670
Finished training it 54272/76743 of epoch 2, 144.67 ms/it, loss 0.446431
Finished training it 54272/76743 of epoch 2, 145.03 ms/it, loss 0.444988
Finished training it 54272/76743 of epoch 2, 145.00 ms/it, loss 0.450212
Finished training it 54272/76743 of epoch 2, 145.29 ms/it, loss 0.447649
Finished training it 55296/76743 of epoch 2, 143.38 ms/it, loss 0.447442
Finished training it 55296/76743 of epoch 2, 143.83 ms/it, loss 0.448076
Finished training it 55296/76743 of epoch 2, 144.00 ms/it, loss 0.446090
Finished training it 55296/76743 of epoch 2, 143.71 ms/it, loss 0.448726
Finished training it 56320/76743 of epoch 2, 143.96 ms/it, loss 0.450237
Finished training it 56320/76743 of epoch 2, 144.23 ms/it, loss 0.447716
Finished training it 56320/76743 of epoch 2, 144.59 ms/it, loss 0.448056
Finished training it 56320/76743 of epoch 2, 144.39 ms/it, loss 0.450012
Finished training it 57344/76743 of epoch 2, 141.17 ms/it, loss 0.447794
Finished training it 57344/76743 of epoch 2, 141.52 ms/it, loss 0.449160
Finished training it 57344/76743 of epoch 2, 141.48 ms/it, loss 0.449858
Finished training it 57344/76743 of epoch 2, 141.81 ms/it, loss 0.448673
Finished training it 58368/76743 of epoch 2, 143.58 ms/it, loss 0.448099
Finished training it 58368/76743 of epoch 2, 144.00 ms/it, loss 0.449146
Finished training it 58368/76743 of epoch 2, 144.01 ms/it, loss 0.445470
Finished training it 58368/76743 of epoch 2, 143.95 ms/it, loss 0.445904
Finished training it 59392/76743 of epoch 2, 140.59 ms/it, loss 0.444728
Finished training it 59392/76743 of epoch 2, 140.42 ms/it, loss 0.446278
Finished training it 59392/76743 of epoch 2, 140.10 ms/it, loss 0.444278
Finished training it 59392/76743 of epoch 2, 140.56 ms/it, loss 0.445315
Finished training it 60416/76743 of epoch 2, 144.80 ms/it, loss 0.449796
Finished training it 60416/76743 of epoch 2, 144.89 ms/it, loss 0.446222
Finished training it 60416/76743 of epoch 2, 144.40 ms/it, loss 0.446225
Finished training it 60416/76743 of epoch 2, 144.84 ms/it, loss 0.443866
Finished training it 61440/76743 of epoch 2, 142.41 ms/it, loss 0.445613
Finished training it 61440/76743 of epoch 2, 142.72 ms/it, loss 0.448766
Finished training it 61440/76743 of epoch 2, 142.85 ms/it, loss 0.448544
Finished training it 61440/76743 of epoch 2, 142.88 ms/it, loss 0.446428
Testing at - 61440/76743 of epoch 2,
Testing at - 61440/76743 of epoch 2,
Testing at - 61440/76743 of epoch 2,
Testing at - 61440/76743 of epoch 2,
Warning: Skipping the batch 3197 with size 602
Warning: Skipping the batch 3197 with size 602
Warning: Skipping the batch 3197 with size 602
rank: 1 test_accu: 2578031.0
Warning: Skipping the batch 3197 with size 602
get out
rank: 0 test_accu: 2578031.0
rank: 2 test_accu: 2578031.0
1 has test check 2578031.0 and sample count 3273728
get out
get out
0 has test check 2578031.0 and sample count 3273728
2 has test check 2578031.0 and sample count 3273728
rank: 3 test_accu: 2578031.0
get out
3 has test check 2578031.0 and sample count 3273728
 accuracy 78.749 %, best 78.749 %, roc auc score 0.7999, best 0.7999
Saving model to /home/yz25672/dlrm_criteo_kaggle/save_model_after_training_one0.0.pt
Start documenting table 0 gradient in table0epoch2_gradient.txt
Documented table 0 gradients in file table0epoch2_gradient.txt
Start documenting table 3 gradient in table3epoch2_gradient.txt
Documented table 3 gradients in file table3epoch2_gradient.txt
Start documenting table 6 gradient in table6epoch2_gradient.txt
Documented table 6 gradients in file table6epoch2_gradient.txt
Start documenting table 18 gradient in table18epoch2_gradient.txt
Documented table 18 gradients in file table18epoch2_gradient.txt
Start documenting table 20 gradient in table20epoch2_gradient.txt
Documented table 20 gradients in file table20epoch2_gradient.txt
Finished training it 62464/76743 of epoch 2, 143.71 ms/it, loss 0.448589
Finished training it 62464/76743 of epoch 2, 144.38 ms/it, loss 0.447194
Finished training it 62464/76743 of epoch 2, 144.16 ms/it, loss 0.446609
Finished training it 62464/76743 of epoch 2, 144.40 ms/it, loss 0.445971
Finished training it 63488/76743 of epoch 2, 142.82 ms/it, loss 0.447297
Finished training it 63488/76743 of epoch 2, 143.33 ms/it, loss 0.444911
Finished training it 63488/76743 of epoch 2, 143.41 ms/it, loss 0.448981
Finished training it 63488/76743 of epoch 2, 143.48 ms/it, loss 0.449430
Finished training it 64512/76743 of epoch 2, 144.77 ms/it, loss 0.451254
Finished training it 64512/76743 of epoch 2, 145.25 ms/it, loss 0.445881
Finished training it 64512/76743 of epoch 2, 145.34 ms/it, loss 0.448380
Finished training it 64512/76743 of epoch 2, 145.50 ms/it, loss 0.445585
Finished training it 65536/76743 of epoch 2, 143.47 ms/it, loss 0.446621
Finished training it 65536/76743 of epoch 2, 143.83 ms/it, loss 0.445682
Finished training it 65536/76743 of epoch 2, 143.97 ms/it, loss 0.447396
Finished training it 65536/76743 of epoch 2, 144.09 ms/it, loss 0.447877
Finished training it 66560/76743 of epoch 2, 142.30 ms/it, loss 0.447381
Finished training it 66560/76743 of epoch 2, 142.68 ms/it, loss 0.447947
Finished training it 66560/76743 of epoch 2, 142.60 ms/it, loss 0.446479
Finished training it 66560/76743 of epoch 2, 142.97 ms/it, loss 0.449992
Finished training it 67584/76743 of epoch 2, 140.31 ms/it, loss 0.444871
Finished training it 67584/76743 of epoch 2, 140.74 ms/it, loss 0.446514
Finished training it 67584/76743 of epoch 2, 140.76 ms/it, loss 0.445128
Finished training it 67584/76743 of epoch 2, 140.66 ms/it, loss 0.447616
Finished training it 68608/76743 of epoch 2, 142.17 ms/it, loss 0.449336
Finished training it 68608/76743 of epoch 2, 142.59 ms/it, loss 0.448835
Finished training it 68608/76743 of epoch 2, 142.71 ms/it, loss 0.448341
Finished training it 68608/76743 of epoch 2, 142.68 ms/it, loss 0.446579
Finished training it 69632/76743 of epoch 2, 144.95 ms/it, loss 0.445203
Finished training it 69632/76743 of epoch 2, 145.25 ms/it, loss 0.450381
Finished training it 69632/76743 of epoch 2, 145.37 ms/it, loss 0.444753
Finished training it 69632/76743 of epoch 2, 145.39 ms/it, loss 0.448705
Finished training it 70656/76743 of epoch 2, 140.89 ms/it, loss 0.446224
Finished training it 70656/76743 of epoch 2, 141.19 ms/it, loss 0.444714
Finished training it 70656/76743 of epoch 2, 140.77 ms/it, loss 0.446607
Finished training it 70656/76743 of epoch 2, 141.36 ms/it, loss 0.447568
Finished training it 71680/76743 of epoch 2, 142.55 ms/it, loss 0.446730
Finished training it 71680/76743 of epoch 2, 142.97 ms/it, loss 0.446308
Finished training it 71680/76743 of epoch 2, 143.10 ms/it, loss 0.449646
Finished training it 71680/76743 of epoch 2, 142.98 ms/it, loss 0.448330
Testing at - 71680/76743 of epoch 2,
Testing at - 71680/76743 of epoch 2,
Testing at - 71680/76743 of epoch 2,
Testing at - 71680/76743 of epoch 2,
Warning: Skipping the batch 3197 with size 602
rank: 1 test_accu: 2579152.0
get out
1 has test check 2579152.0 and sample count 3273728
Warning: Skipping the batch 3197 with size 602
rank: 0 test_accu: 2579152.0
get out
Warning: Skipping the batch 3197 with size 602
0 has test check 2579152.0 and sample count 3273728
rank: 2 test_accu: 2579152.0
get out
2 has test check 2579152.0 and sample count 3273728
Warning: Skipping the batch 3197 with size 602
rank: 3 test_accu: 2579152.0
get out
3 has test check 2579152.0 and sample count 3273728
 accuracy 78.783 %, best 78.783 %, roc auc score 0.8007, best 0.8007
Saving model to /home/yz25672/dlrm_criteo_kaggle/save_model_after_training_one1.0.pt
Finished training it 72704/76743 of epoch 2, 144.38 ms/it, loss 0.447085
Finished training it 72704/76743 of epoch 2, 144.83 ms/it, loss 0.446250
Finished training it 72704/76743 of epoch 2, 145.01 ms/it, loss 0.446937
Finished training it 72704/76743 of epoch 2, 145.01 ms/it, loss 0.447190
Finished training it 73728/76743 of epoch 2, 144.44 ms/it, loss 0.447501
Finished training it 73728/76743 of epoch 2, 144.54 ms/it, loss 0.446855
Finished training it 73728/76743 of epoch 2, 143.99 ms/it, loss 0.445897
Finished training it 73728/76743 of epoch 2, 144.58 ms/it, loss 0.445551
Finished training it 74752/76743 of epoch 2, 145.08 ms/it, loss 0.445568
Finished training it 74752/76743 of epoch 2, 145.46 ms/it, loss 0.447113
Finished training it 74752/76743 of epoch 2, 145.54 ms/it, loss 0.445123
Finished training it 74752/76743 of epoch 2, 145.60 ms/it, loss 0.447739
Finished training it 75776/76743 of epoch 2, 142.36 ms/it, loss 0.445403
Finished training it 75776/76743 of epoch 2, 142.74 ms/it, loss 0.450398
Finished training it 75776/76743 of epoch 2, 142.54 ms/it, loss 0.447593
Finished training it 75776/76743 of epoch 2, 143.01 ms/it, loss 0.446595
Warning: Skipping the batch 76742 with size 14
Warning: Skipping the batch 76742 with size 14
Warning: Skipping the batch 76742 with size 14
Warning: Skipping the batch 76742 with size 14
Finished training it 1024/76743 of epoch 3, 143.70 ms/it, loss 0.446275
Finished training it 1024/76743 of epoch 3, 143.26 ms/it, loss 0.446654
Finished training it 1024/76743 of epoch 3, 143.65 ms/it, loss 0.447215
Finished training it 1024/76743 of epoch 3, 143.72 ms/it, loss 0.446893
Finished training it 2048/76743 of epoch 3, 141.93 ms/it, loss 0.446632
Finished training it 2048/76743 of epoch 3, 142.01 ms/it, loss 0.448133
Finished training it 2048/76743 of epoch 3, 142.37 ms/it, loss 0.447846
Finished training it 2048/76743 of epoch 3, 142.31 ms/it, loss 0.446771
Finished training it 3072/76743 of epoch 3, 143.55 ms/it, loss 0.446368
Finished training it 3072/76743 of epoch 3, 144.10 ms/it, loss 0.447800
Finished training it 3072/76743 of epoch 3, 144.11 ms/it, loss 0.446855
Finished training it 3072/76743 of epoch 3, 144.25 ms/it, loss 0.444803
Finished training it 4096/76743 of epoch 3, 143.49 ms/it, loss 0.448021
Finished training it 4096/76743 of epoch 3, 144.01 ms/it, loss 0.445910
Finished training it 4096/76743 of epoch 3, 144.01 ms/it, loss 0.449815
Finished training it 4096/76743 of epoch 3, 144.12 ms/it, loss 0.447859
Finished training it 5120/76743 of epoch 3, 141.92 ms/it, loss 0.447010
Finished training it 5120/76743 of epoch 3, 142.24 ms/it, loss 0.444345
Finished training it 5120/76743 of epoch 3, 142.47 ms/it, loss 0.445219
Finished training it 5120/76743 of epoch 3, 142.28 ms/it, loss 0.446014
Finished training it 6144/76743 of epoch 3, 143.55 ms/it, loss 0.448415
Finished training it 6144/76743 of epoch 3, 144.11 ms/it, loss 0.447490
Finished training it 6144/76743 of epoch 3, 144.23 ms/it, loss 0.449919
Finished training it 6144/76743 of epoch 3, 144.10 ms/it, loss 0.447177
Finished training it 7168/76743 of epoch 3, 144.23 ms/it, loss 0.447642
Finished training it 7168/76743 of epoch 3, 143.71 ms/it, loss 0.445907
Finished training it 7168/76743 of epoch 3, 143.86 ms/it, loss 0.447514
Finished training it 7168/76743 of epoch 3, 144.38 ms/it, loss 0.449167
Finished training it 8192/76743 of epoch 3, 141.66 ms/it, loss 0.449353
Finished training it 8192/76743 of epoch 3, 141.32 ms/it, loss 0.446898
Finished training it 8192/76743 of epoch 3, 141.71 ms/it, loss 0.447582
Finished training it 8192/76743 of epoch 3, 141.85 ms/it, loss 0.446029
Finished training it 9216/76743 of epoch 3, 142.64 ms/it, loss 0.445242
Finished training it 9216/76743 of epoch 3, 142.27 ms/it, loss 0.446922
Finished training it 9216/76743 of epoch 3, 142.84 ms/it, loss 0.446795
Finished training it 9216/76743 of epoch 3, 142.72 ms/it, loss 0.448701
Finished training it 10240/76743 of epoch 3, 141.44 ms/it, loss 0.446524
Finished training it 10240/76743 of epoch 3, 141.91 ms/it, loss 0.446386
Finished training it 10240/76743 of epoch 3, 141.92 ms/it, loss 0.447142
Finished training it 10240/76743 of epoch 3, 141.98 ms/it, loss 0.448448
Testing at - 10240/76743 of epoch 3,
Testing at - 10240/76743 of epoch 3,
Testing at - 10240/76743 of epoch 3,
Testing at - 10240/76743 of epoch 3,
Warning: Skipping the batch 3197 with size 602
Warning: Skipping the batch 3197 with size 602
Warning: Skipping the batch 3197 with size 602
rank: 0 test_accu: 2578002.0
get out
0 has test check 2578002.0 and sample count 3273728
rank: 2 test_accu: 2578002.0
get out
2 has test check 2578002.0 and sample count 3273728
rank: 1 test_accu: 2578002.0
get out
1 has test check 2578002.0 and sample count 3273728
Warning: Skipping the batch 3197 with size 602
rank: 3 test_accu: 2578002.0
get out
3 has test check 2578002.0 and sample count 3273728
 accuracy 78.748 %, best 78.783 %, roc auc score 0.8001, best 0.8007
Saving model to /home/yz25672/dlrm_criteo_kaggle/save_model_after_training_one1.0.pt
Finished training it 11264/76743 of epoch 3, 143.54 ms/it, loss 0.445868
Finished training it 11264/76743 of epoch 3, 143.68 ms/it, loss 0.443462
Finished training it 11264/76743 of epoch 3, 143.18 ms/it, loss 0.445675
Finished training it 11264/76743 of epoch 3, 142.92 ms/it, loss 0.449686
Finished training it 12288/76743 of epoch 3, 143.36 ms/it, loss 0.446488
Finished training it 12288/76743 of epoch 3, 143.68 ms/it, loss 0.445066
Finished training it 12288/76743 of epoch 3, 143.59 ms/it, loss 0.446181
Finished training it 12288/76743 of epoch 3, 143.87 ms/it, loss 0.447638
Finished training it 13312/76743 of epoch 3, 143.30 ms/it, loss 0.444395
Finished training it 13312/76743 of epoch 3, 143.75 ms/it, loss 0.445667
Finished training it 13312/76743 of epoch 3, 143.89 ms/it, loss 0.444340
Finished training it 13312/76743 of epoch 3, 143.74 ms/it, loss 0.443924
Finished training it 14336/76743 of epoch 3, 139.94 ms/it, loss 0.444181
Finished training it 14336/76743 of epoch 3, 140.26 ms/it, loss 0.444911
Finished training it 14336/76743 of epoch 3, 140.41 ms/it, loss 0.445993
Finished training it 14336/76743 of epoch 3, 140.62 ms/it, loss 0.446650
Finished training it 15360/76743 of epoch 3, 140.35 ms/it, loss 0.449351
Finished training it 15360/76743 of epoch 3, 140.50 ms/it, loss 0.443706
Finished training it 15360/76743 of epoch 3, 140.71 ms/it, loss 0.445630
Finished training it 15360/76743 of epoch 3, 140.95 ms/it, loss 0.446736
Finished training it 16384/76743 of epoch 3, 141.29 ms/it, loss 0.446189
Finished training it 16384/76743 of epoch 3, 141.70 ms/it, loss 0.447165
Finished training it 16384/76743 of epoch 3, 141.93 ms/it, loss 0.445418
Finished training it 16384/76743 of epoch 3, 141.35 ms/it, loss 0.444031
Finished training it 17408/76743 of epoch 3, 143.62 ms/it, loss 0.448367
Finished training it 17408/76743 of epoch 3, 144.13 ms/it, loss 0.447610
Finished training it 17408/76743 of epoch 3, 143.95 ms/it, loss 0.445984
Finished training it 17408/76743 of epoch 3, 144.10 ms/it, loss 0.447985
Finished training it 18432/76743 of epoch 3, 140.49 ms/it, loss 0.449555
Finished training it 18432/76743 of epoch 3, 140.79 ms/it, loss 0.447163
Finished training it 18432/76743 of epoch 3, 141.09 ms/it, loss 0.445782
Finished training it 18432/76743 of epoch 3, 140.85 ms/it, loss 0.446957
Finished training it 19456/76743 of epoch 3, 142.01 ms/it, loss 0.445405
Finished training it 19456/76743 of epoch 3, 142.38 ms/it, loss 0.444005
Finished training it 19456/76743 of epoch 3, 142.50 ms/it, loss 0.445830
Finished training it 19456/76743 of epoch 3, 142.61 ms/it, loss 0.444902
Finished training it 20480/76743 of epoch 3, 145.35 ms/it, loss 0.446954
Finished training it 20480/76743 of epoch 3, 145.74 ms/it, loss 0.445842
Finished training it 20480/76743 of epoch 3, 145.96 ms/it, loss 0.446571
Finished training it 20480/76743 of epoch 3, 145.88 ms/it, loss 0.446901
Testing at - 20480/76743 of epoch 3,
Testing at - 20480/76743 of epoch 3,
Testing at - 20480/76743 of epoch 3,
Testing at - 20480/76743 of epoch 3,
Warning: Skipping the batch 3197 with size 602
rank: 1 test_accu: 2579805.0
get out
1 has test check 2579805.0 and sample count 3273728
Warning: Skipping the batch 3197 with size 602
Warning: Skipping the batch 3197 with size 602
rank: 0 test_accu: 2579805.0
get out
0 has test check 2579805.0 and sample count 3273728
rank: 2 test_accu: 2579805.0
get out
2 has test check 2579805.0 and sample count 3273728
Warning: Skipping the batch 3197 with size 602
rank: 3 test_accu: 2579805.0
get out
3 has test check 2579805.0 and sample count 3273728
 accuracy 78.803 %, best 78.803 %, roc auc score 0.8010, best 0.8010
Saving model to /home/yz25672/dlrm_criteo_kaggle/save_model_after_training_one0.0.pt
Start documenting table 0 gradient in table0epoch3_gradient.txt
Documented table 0 gradients in file table0epoch3_gradient.txt
Start documenting table 3 gradient in table3epoch3_gradient.txt
Documented table 3 gradients in file table3epoch3_gradient.txt
Start documenting table 6 gradient in table6epoch3_gradient.txt
Documented table 6 gradients in file table6epoch3_gradient.txt
Start documenting table 18 gradient in table18epoch3_gradient.txt
Documented table 18 gradients in file table18epoch3_gradient.txt
Start documenting table 20 gradient in table20epoch3_gradient.txt
Documented table 20 gradients in file table20epoch3_gradient.txt
Finished training it 21504/76743 of epoch 3, 142.92 ms/it, loss 0.445258
Finished training it 21504/76743 of epoch 3, 142.86 ms/it, loss 0.443902
Finished training it 21504/76743 of epoch 3, 143.47 ms/it, loss 0.446408
Finished training it 21504/76743 of epoch 3, 143.40 ms/it, loss 0.444039
Finished training it 22528/76743 of epoch 3, 142.34 ms/it, loss 0.445122
Finished training it 22528/76743 of epoch 3, 141.68 ms/it, loss 0.445139
Finished training it 22528/76743 of epoch 3, 142.08 ms/it, loss 0.448229
Finished training it 22528/76743 of epoch 3, 142.18 ms/it, loss 0.444631
Finished training it 23552/76743 of epoch 3, 142.77 ms/it, loss 0.447800
Finished training it 23552/76743 of epoch 3, 143.19 ms/it, loss 0.446201
Finished training it 23552/76743 of epoch 3, 143.29 ms/it, loss 0.447423
Finished training it 23552/76743 of epoch 3, 143.40 ms/it, loss 0.447199
Finished training it 24576/76743 of epoch 3, 143.26 ms/it, loss 0.444705
Finished training it 24576/76743 of epoch 3, 143.74 ms/it, loss 0.442978
Finished training it 24576/76743 of epoch 3, 143.91 ms/it, loss 0.444783
Finished training it 24576/76743 of epoch 3, 143.93 ms/it, loss 0.443649
Finished training it 25600/76743 of epoch 3, 141.68 ms/it, loss 0.446184
Finished training it 25600/76743 of epoch 3, 142.14 ms/it, loss 0.446111
Finished training it 25600/76743 of epoch 3, 142.31 ms/it, loss 0.445745
Finished training it 25600/76743 of epoch 3, 142.38 ms/it, loss 0.447482
Finished training it 26624/76743 of epoch 3, 141.50 ms/it, loss 0.447694
Finished training it 26624/76743 of epoch 3, 141.20 ms/it, loss 0.447426
Finished training it 26624/76743 of epoch 3, 141.65 ms/it, loss 0.446709
Finished training it 26624/76743 of epoch 3, 141.91 ms/it, loss 0.448113
Finished training it 27648/76743 of epoch 3, 143.00 ms/it, loss 0.445747
Finished training it 27648/76743 of epoch 3, 143.59 ms/it, loss 0.446936
Finished training it 27648/76743 of epoch 3, 143.59 ms/it, loss 0.445923
Finished training it 27648/76743 of epoch 3, 143.46 ms/it, loss 0.447080
Finished training it 28672/76743 of epoch 3, 142.22 ms/it, loss 0.448047
Finished training it 28672/76743 of epoch 3, 142.81 ms/it, loss 0.445082
Finished training it 28672/76743 of epoch 3, 142.74 ms/it, loss 0.445607
Finished training it 28672/76743 of epoch 3, 142.87 ms/it, loss 0.444121
Finished training it 29696/76743 of epoch 3, 140.05 ms/it, loss 0.447128
Finished training it 29696/76743 of epoch 3, 139.25 ms/it, loss 0.447610
Finished training it 29696/76743 of epoch 3, 140.17 ms/it, loss 0.445742
Finished training it 29696/76743 of epoch 3, 140.19 ms/it, loss 0.441982
Finished training it 30720/76743 of epoch 3, 140.42 ms/it, loss 0.445317
Finished training it 30720/76743 of epoch 3, 141.05 ms/it, loss 0.445542
Finished training it 30720/76743 of epoch 3, 140.91 ms/it, loss 0.445741
Finished training it 30720/76743 of epoch 3, 140.94 ms/it, loss 0.447981
Testing at - 30720/76743 of epoch 3,
Testing at - 30720/76743 of epoch 3,
Testing at - 30720/76743 of epoch 3,
Testing at - 30720/76743 of epoch 3,
Warning: Skipping the batch 3197 with size 602
rank: 1 test_accu: 2578786.0
Warning: Skipping the batch 3197 with size 602
get out
1 has test check 2578786.0 and sample count 3273728
rank: 0 test_accu: 2578786.0
get out
0 has test check 2578786.0 and sample count 3273728
Warning: Skipping the batch 3197 with size 602
Warning: Skipping the batch 3197 with size 602
rank: 2 test_accu: 2578786.0
get out
2 has test check 2578786.0 and sample count 3273728
rank: 3 test_accu: 2578786.0
get out
3 has test check 2578786.0 and sample count 3273728
 accuracy 78.772 %, best 78.803 %, roc auc score 0.8011, best 0.8011
Saving model to /home/yz25672/dlrm_criteo_kaggle/save_model_after_training_one1.0.pt
Finished training it 31744/76743 of epoch 3, 142.85 ms/it, loss 0.444575
Finished training it 31744/76743 of epoch 3, 143.27 ms/it, loss 0.444586
Finished training it 31744/76743 of epoch 3, 143.27 ms/it, loss 0.445983
Finished training it 31744/76743 of epoch 3, 143.45 ms/it, loss 0.447153
Finished training it 32768/76743 of epoch 3, 142.15 ms/it, loss 0.447083
Finished training it 32768/76743 of epoch 3, 142.48 ms/it, loss 0.443984
Finished training it 32768/76743 of epoch 3, 142.67 ms/it, loss 0.443583
Finished training it 32768/76743 of epoch 3, 142.67 ms/it, loss 0.445813
Finished training it 33792/76743 of epoch 3, 141.84 ms/it, loss 0.445332
Finished training it 33792/76743 of epoch 3, 141.54 ms/it, loss 0.441996
Finished training it 33792/76743 of epoch 3, 141.31 ms/it, loss 0.447496
Finished training it 33792/76743 of epoch 3, 141.88 ms/it, loss 0.448035
Finished training it 34816/76743 of epoch 3, 141.41 ms/it, loss 0.445683
Finished training it 34816/76743 of epoch 3, 141.59 ms/it, loss 0.446565
Finished training it 34816/76743 of epoch 3, 141.92 ms/it, loss 0.443618
Finished training it 34816/76743 of epoch 3, 141.83 ms/it, loss 0.446319
Finished training it 35840/76743 of epoch 3, 141.02 ms/it, loss 0.444576
Finished training it 35840/76743 of epoch 3, 141.44 ms/it, loss 0.447815
Finished training it 35840/76743 of epoch 3, 141.48 ms/it, loss 0.447538
Finished training it 35840/76743 of epoch 3, 141.59 ms/it, loss 0.445597
Finished training it 36864/76743 of epoch 3, 142.06 ms/it, loss 0.444933
Finished training it 36864/76743 of epoch 3, 142.46 ms/it, loss 0.446077
Finished training it 36864/76743 of epoch 3, 142.61 ms/it, loss 0.447188
Finished training it 36864/76743 of epoch 3, 142.57 ms/it, loss 0.444417
Finished training it 37888/76743 of epoch 3, 142.43 ms/it, loss 0.445696
Finished training it 37888/76743 of epoch 3, 142.91 ms/it, loss 0.445682
Finished training it 37888/76743 of epoch 3, 142.98 ms/it, loss 0.446045
Finished training it 37888/76743 of epoch 3, 142.84 ms/it, loss 0.444991
Finished training it 38912/76743 of epoch 3, 142.98 ms/it, loss 0.446222
Finished training it 38912/76743 of epoch 3, 143.48 ms/it, loss 0.445964
Finished training it 38912/76743 of epoch 3, 143.33 ms/it, loss 0.442591
Finished training it 38912/76743 of epoch 3, 143.55 ms/it, loss 0.447166
Finished training it 39936/76743 of epoch 3, 141.01 ms/it, loss 0.446690
Finished training it 39936/76743 of epoch 3, 141.38 ms/it, loss 0.445323
Finished training it 39936/76743 of epoch 3, 141.40 ms/it, loss 0.446033
Finished training it 39936/76743 of epoch 3, 141.57 ms/it, loss 0.445820
Finished training it 40960/76743 of epoch 3, 142.55 ms/it, loss 0.447431
Finished training it 40960/76743 of epoch 3, 141.83 ms/it, loss 0.442792
Finished training it 40960/76743 of epoch 3, 142.32 ms/it, loss 0.446222
Finished training it 40960/76743 of epoch 3, 142.59 ms/it, loss 0.445753
Testing at - 40960/76743 of epoch 3,
Testing at - 40960/76743 of epoch 3,
Testing at - 40960/76743 of epoch 3,
Testing at - 40960/76743 of epoch 3,
Warning: Skipping the batch 3197 with size 602
rank: 1 test_accu: 2577265.0
get out
1 has test check 2577265.0 and sample count 3273728
Warning: Skipping the batch 3197 with size 602
Warning: Skipping the batch 3197 with size 602
rank: 0 test_accu: 2577265.0
get out
0 has test check 2577265.0 and sample count 3273728
rank: 3 test_accu: 2577265.0
get out
3 has test check 2577265.0 and sample count 3273728
Warning: Skipping the batch 3197 with size 602
rank: 2 test_accu: 2577265.0
get out
2 has test check 2577265.0 and sample count 3273728
 accuracy 78.726 %, best 78.803 %, roc auc score 0.8011, best 0.8011
Saving model to /home/yz25672/dlrm_criteo_kaggle/save_model_after_training_one0.0.pt
Start documenting table 0 gradient in table0epoch3_gradient.txt
Documented table 0 gradients in file table0epoch3_gradient.txt
Start documenting table 3 gradient in table3epoch3_gradient.txt
Documented table 3 gradients in file table3epoch3_gradient.txt
Start documenting table 6 gradient in table6epoch3_gradient.txt
Documented table 6 gradients in file table6epoch3_gradient.txt
Start documenting table 18 gradient in table18epoch3_gradient.txt
Documented table 18 gradients in file table18epoch3_gradient.txt
Start documenting table 20 gradient in table20epoch3_gradient.txt
Documented table 20 gradients in file table20epoch3_gradient.txt
Finished training it 41984/76743 of epoch 3, 142.72 ms/it, loss 0.445401
Finished training it 41984/76743 of epoch 3, 143.36 ms/it, loss 0.444330
Finished training it 41984/76743 of epoch 3, 143.16 ms/it, loss 0.444528
Finished training it 41984/76743 of epoch 3, 143.46 ms/it, loss 0.442972
Finished training it 43008/76743 of epoch 3, 141.92 ms/it, loss 0.446552
Finished training it 43008/76743 of epoch 3, 142.42 ms/it, loss 0.444033
Finished training it 43008/76743 of epoch 3, 142.47 ms/it, loss 0.445713
Finished training it 43008/76743 of epoch 3, 142.39 ms/it, loss 0.444883
Finished training it 44032/76743 of epoch 3, 141.71 ms/it, loss 0.447685
Finished training it 44032/76743 of epoch 3, 141.26 ms/it, loss 0.444542
Finished training it 44032/76743 of epoch 3, 141.71 ms/it, loss 0.444545
Finished training it 44032/76743 of epoch 3, 142.00 ms/it, loss 0.443724
Finished training it 45056/76743 of epoch 3, 140.88 ms/it, loss 0.443341
Finished training it 45056/76743 of epoch 3, 141.08 ms/it, loss 0.446401
Finished training it 45056/76743 of epoch 3, 141.12 ms/it, loss 0.444470
Finished training it 45056/76743 of epoch 3, 141.55 ms/it, loss 0.446856
Finished training it 46080/76743 of epoch 3, 148.17 ms/it, loss 0.447160
Finished training it 46080/76743 of epoch 3, 148.85 ms/it, loss 0.444679
Finished training it 46080/76743 of epoch 3, 148.62 ms/it, loss 0.445479
Finished training it 46080/76743 of epoch 3, 148.71 ms/it, loss 0.445467
Finished training it 47104/76743 of epoch 3, 143.57 ms/it, loss 0.445022
Finished training it 47104/76743 of epoch 3, 143.98 ms/it, loss 0.445286
Finished training it 47104/76743 of epoch 3, 144.22 ms/it, loss 0.444992
Finished training it 47104/76743 of epoch 3, 144.08 ms/it, loss 0.447335
Finished training it 48128/76743 of epoch 3, 142.89 ms/it, loss 0.446572
Finished training it 48128/76743 of epoch 3, 143.30 ms/it, loss 0.445852
Finished training it 48128/76743 of epoch 3, 143.39 ms/it, loss 0.446461
Finished training it 48128/76743 of epoch 3, 143.46 ms/it, loss 0.444998
Finished training it 49152/76743 of epoch 3, 140.99 ms/it, loss 0.445835
Finished training it 49152/76743 of epoch 3, 141.28 ms/it, loss 0.448472
Finished training it 49152/76743 of epoch 3, 141.64 ms/it, loss 0.445709
Finished training it 49152/76743 of epoch 3, 141.55 ms/it, loss 0.445433
Finished training it 50176/76743 of epoch 3, 140.72 ms/it, loss 0.443973
Finished training it 50176/76743 of epoch 3, 141.43 ms/it, loss 0.446847
Finished training it 50176/76743 of epoch 3, 141.55 ms/it, loss 0.446301
Finished training it 50176/76743 of epoch 3, 141.34 ms/it, loss 0.446269
Finished training it 51200/76743 of epoch 3, 144.20 ms/it, loss 0.448680
Finished training it 51200/76743 of epoch 3, 144.69 ms/it, loss 0.445286
Finished training it 51200/76743 of epoch 3, 144.64 ms/it, loss 0.443932
Finished training it 51200/76743 of epoch 3, 144.72 ms/it, loss 0.447086
Testing at - 51200/76743 of epoch 3,
Testing at - 51200/76743 of epoch 3,
Testing at - 51200/76743 of epoch 3,
Testing at - 51200/76743 of epoch 3,
Warning: Skipping the batch 3197 with size 602
Warning: Skipping the batch 3197 with size 602
rank: 0 test_accu: 2580506.0
get out
0 has test check 2580506.0 and sample count 3273728
rank: 1 test_accu: 2580506.0
get out
1 has test check 2580506.0 and sample count 3273728
Warning: Skipping the batch 3197 with size 602
Warning: Skipping the batch 3197 with size 602
rank: 2 test_accu: 2580506.0
get out
2 has test check 2580506.0 and sample count 3273728
rank: 3 test_accu: 2580506.0
get out
3 has test check 2580506.0 and sample count 3273728
 accuracy 78.825 %, best 78.825 %, roc auc score 0.8020, best 0.8020
Saving model to /home/yz25672/dlrm_criteo_kaggle/save_model_after_training_one1.0.pt
Finished training it 52224/76743 of epoch 3, 144.56 ms/it, loss 0.448143
Finished training it 52224/76743 of epoch 3, 144.87 ms/it, loss 0.446404
Finished training it 52224/76743 of epoch 3, 145.07 ms/it, loss 0.446899
Finished training it 52224/76743 of epoch 3, 145.20 ms/it, loss 0.441814
Finished training it 53248/76743 of epoch 3, 142.41 ms/it, loss 0.443149
Finished training it 53248/76743 of epoch 3, 142.86 ms/it, loss 0.442533
Finished training it 53248/76743 of epoch 3, 142.61 ms/it, loss 0.445012
Finished training it 53248/76743 of epoch 3, 142.97 ms/it, loss 0.444920
Finished training it 54272/76743 of epoch 3, 141.18 ms/it, loss 0.442465
Finished training it 54272/76743 of epoch 3, 140.90 ms/it, loss 0.443539
Finished training it 54272/76743 of epoch 3, 141.42 ms/it, loss 0.445344
Finished training it 54272/76743 of epoch 3, 141.34 ms/it, loss 0.447876
Finished training it 55296/76743 of epoch 3, 142.39 ms/it, loss 0.444644
Finished training it 55296/76743 of epoch 3, 142.74 ms/it, loss 0.446154
Finished training it 55296/76743 of epoch 3, 143.13 ms/it, loss 0.443442
Finished training it 55296/76743 of epoch 3, 143.06 ms/it, loss 0.445761
Finished training it 56320/76743 of epoch 3, 140.87 ms/it, loss 0.447672
Finished training it 56320/76743 of epoch 3, 141.64 ms/it, loss 0.445508
Finished training it 56320/76743 of epoch 3, 141.45 ms/it, loss 0.445407
Finished training it 56320/76743 of epoch 3, 141.67 ms/it, loss 0.447533
Finished training it 57344/76743 of epoch 3, 142.63 ms/it, loss 0.445361
Finished training it 57344/76743 of epoch 3, 143.30 ms/it, loss 0.446018
Finished training it 57344/76743 of epoch 3, 143.07 ms/it, loss 0.446761
Finished training it 57344/76743 of epoch 3, 143.05 ms/it, loss 0.447658
Finished training it 58368/76743 of epoch 3, 140.81 ms/it, loss 0.445331
Finished training it 58368/76743 of epoch 3, 140.92 ms/it, loss 0.442859
Finished training it 58368/76743 of epoch 3, 141.20 ms/it, loss 0.443361
Finished training it 58368/76743 of epoch 3, 141.39 ms/it, loss 0.446365
Finished training it 59392/76743 of epoch 3, 144.84 ms/it, loss 0.441470
Finished training it 59392/76743 of epoch 3, 145.34 ms/it, loss 0.442297
Finished training it 59392/76743 of epoch 3, 145.41 ms/it, loss 0.442308
Finished training it 59392/76743 of epoch 3, 145.53 ms/it, loss 0.443923
Finished training it 60416/76743 of epoch 3, 144.71 ms/it, loss 0.443690
Finished training it 60416/76743 of epoch 3, 145.24 ms/it, loss 0.446793
Finished training it 60416/76743 of epoch 3, 145.36 ms/it, loss 0.444107
Finished training it 60416/76743 of epoch 3, 145.28 ms/it, loss 0.441492
Finished training it 61440/76743 of epoch 3, 141.06 ms/it, loss 0.443206
Finished training it 61440/76743 of epoch 3, 141.45 ms/it, loss 0.446264
Finished training it 61440/76743 of epoch 3, 141.36 ms/it, loss 0.444266
Finished training it 61440/76743 of epoch 3, 141.51 ms/it, loss 0.446287
Testing at - 61440/76743 of epoch 3,
Testing at - 61440/76743 of epoch 3,
Testing at - 61440/76743 of epoch 3,
Testing at - 61440/76743 of epoch 3,
Warning: Skipping the batch 3197 with size 602
Warning: Skipping the batch 3197 with size 602
rank: 0 test_accu: 2579847.0
get out
0 has test check 2579847.0 and sample count 3273728
rank: 3 test_accu: 2579847.0
get out
3 has test check 2579847.0 and sample count 3273728
Warning: Skipping the batch 3197 with size 602
rank: 1 test_accu: 2579847.0
get out
1 has test check 2579847.0 and sample count 3273728
Warning: Skipping the batch 3197 with size 602
rank: 2 test_accu: 2579847.0
get out
2 has test check 2579847.0 and sample count 3273728
 accuracy 78.805 %, best 78.825 %, roc auc score 0.8015, best 0.8020
Saving model to /home/yz25672/dlrm_criteo_kaggle/save_model_after_training_one0.0.pt
Start documenting table 0 gradient in table0epoch3_gradient.txt
Documented table 0 gradients in file table0epoch3_gradient.txt
Start documenting table 3 gradient in table3epoch3_gradient.txt
Documented table 3 gradients in file table3epoch3_gradient.txt
Start documenting table 6 gradient in table6epoch3_gradient.txt
Documented table 6 gradients in file table6epoch3_gradient.txt
Start documenting table 18 gradient in table18epoch3_gradient.txt
Documented table 18 gradients in file table18epoch3_gradient.txt
Start documenting table 20 gradient in table20epoch3_gradient.txt
Documented table 20 gradients in file table20epoch3_gradient.txt
Finished training it 62464/76743 of epoch 3, 142.74 ms/it, loss 0.444345
Finished training it 62464/76743 of epoch 3, 142.30 ms/it, loss 0.446275
Finished training it 62464/76743 of epoch 3, 142.63 ms/it, loss 0.444860
Finished training it 62464/76743 of epoch 3, 142.96 ms/it, loss 0.443424
Finished training it 63488/76743 of epoch 3, 143.41 ms/it, loss 0.444783
Finished training it 63488/76743 of epoch 3, 143.81 ms/it, loss 0.442518
Finished training it 63488/76743 of epoch 3, 143.80 ms/it, loss 0.446292
Finished training it 63488/76743 of epoch 3, 144.05 ms/it, loss 0.446798
Finished training it 64512/76743 of epoch 3, 138.17 ms/it, loss 0.448644
Finished training it 64512/76743 of epoch 3, 138.80 ms/it, loss 0.443415
Finished training it 64512/76743 of epoch 3, 138.72 ms/it, loss 0.445965
Finished training it 64512/76743 of epoch 3, 138.97 ms/it, loss 0.442891
Finished training it 65536/76743 of epoch 3, 141.93 ms/it, loss 0.444365
Finished training it 65536/76743 of epoch 3, 142.31 ms/it, loss 0.443291
Finished training it 65536/76743 of epoch 3, 142.11 ms/it, loss 0.445709
Finished training it 65536/76743 of epoch 3, 142.33 ms/it, loss 0.444843
Finished training it 66560/76743 of epoch 3, 144.05 ms/it, loss 0.445738
Finished training it 66560/76743 of epoch 3, 144.16 ms/it, loss 0.444164
Finished training it 66560/76743 of epoch 3, 144.31 ms/it, loss 0.447724
Finished training it 66560/76743 of epoch 3, 143.52 ms/it, loss 0.445454
Finished training it 67584/76743 of epoch 3, 141.77 ms/it, loss 0.442475
Finished training it 67584/76743 of epoch 3, 142.12 ms/it, loss 0.444497
Finished training it 67584/76743 of epoch 3, 142.03 ms/it, loss 0.445244
Finished training it 67584/76743 of epoch 3, 142.06 ms/it, loss 0.443107
Finished training it 68608/76743 of epoch 3, 140.84 ms/it, loss 0.447099
Finished training it 68608/76743 of epoch 3, 141.34 ms/it, loss 0.446302
Finished training it 68608/76743 of epoch 3, 141.20 ms/it, loss 0.444140
Finished training it 68608/76743 of epoch 3, 141.19 ms/it, loss 0.445857
Finished training it 69632/76743 of epoch 3, 139.78 ms/it, loss 0.442586
Finished training it 69632/76743 of epoch 3, 140.02 ms/it, loss 0.441799
Finished training it 69632/76743 of epoch 3, 140.05 ms/it, loss 0.446148
Finished training it 69632/76743 of epoch 3, 140.30 ms/it, loss 0.448116
Finished training it 70656/76743 of epoch 3, 140.86 ms/it, loss 0.444459
Finished training it 70656/76743 of epoch 3, 141.22 ms/it, loss 0.444039
Finished training it 70656/76743 of epoch 3, 141.39 ms/it, loss 0.442248
Finished training it 70656/76743 of epoch 3, 141.18 ms/it, loss 0.444947
Finished training it 71680/76743 of epoch 3, 140.78 ms/it, loss 0.443808
Finished training it 71680/76743 of epoch 3, 140.87 ms/it, loss 0.445912
Finished training it 71680/76743 of epoch 3, 140.32 ms/it, loss 0.444343
Finished training it 71680/76743 of epoch 3, 140.65 ms/it, loss 0.447271
Testing at - 71680/76743 of epoch 3,
Testing at - 71680/76743 of epoch 3,
Testing at - 71680/76743 of epoch 3,
Testing at - 71680/76743 of epoch 3,
Warning: Skipping the batch 3197 with size 602
Warning: Skipping the batch 3197 with size 602
rank: 3 test_accu: 2581586.0
get out
3 has test check 2581586.0 and sample count 3273728
rank: 0 test_accu: 2581586.0
get out
0 has test check 2581586.0 and sample count 3273728
Warning: Skipping the batch 3197 with size 602
Warning: Skipping the batch 3197 with size 602
rank: 2 test_accu: 2581586.0
get out
2 has test check 2581586.0 and sample count 3273728
rank: 1 test_accu: 2581586.0
get out
1 has test check 2581586.0 and sample count 3273728
 accuracy 78.858 %, best 78.858 %, roc auc score 0.8023, best 0.8023
Saving model to /home/yz25672/dlrm_criteo_kaggle/save_model_after_training_one1.0.pt
Finished training it 72704/76743 of epoch 3, 140.87 ms/it, loss 0.444828
Finished training it 72704/76743 of epoch 3, 140.33 ms/it, loss 0.444601
Finished training it 72704/76743 of epoch 3, 140.68 ms/it, loss 0.445062
Finished training it 72704/76743 of epoch 3, 140.92 ms/it, loss 0.443820
Finished training it 73728/76743 of epoch 3, 143.12 ms/it, loss 0.443389
Finished training it 73728/76743 of epoch 3, 143.45 ms/it, loss 0.445098
Finished training it 73728/76743 of epoch 3, 143.76 ms/it, loss 0.443398
Finished training it 73728/76743 of epoch 3, 143.60 ms/it, loss 0.444511
Finished training it 74752/76743 of epoch 3, 142.81 ms/it, loss 0.442977
Finished training it 74752/76743 of epoch 3, 143.13 ms/it, loss 0.444702
Finished training it 74752/76743 of epoch 3, 143.28 ms/it, loss 0.442555
Finished training it 74752/76743 of epoch 3, 143.48 ms/it, loss 0.445144
Finished training it 75776/76743 of epoch 3, 143.52 ms/it, loss 0.442971
Finished training it 75776/76743 of epoch 3, 143.98 ms/it, loss 0.447780
Finished training it 75776/76743 of epoch 3, 144.18 ms/it, loss 0.444228
Finished training it 75776/76743 of epoch 3, 144.09 ms/it, loss 0.445189
Warning: Skipping the batch 76742 with size 14
Warning: Skipping the batch 76742 with size 14
Warning: Skipping the batch 76742 with size 14
Warning: Skipping the batch 76742 with size 14
Finished training it 1024/76743 of epoch 4, 143.15 ms/it, loss 0.443996
Finished training it 1024/76743 of epoch 4, 143.68 ms/it, loss 0.443904
Finished training it 1024/76743 of epoch 4, 143.52 ms/it, loss 0.444686
Finished training it 1024/76743 of epoch 4, 143.86 ms/it, loss 0.444398
Finished training it 2048/76743 of epoch 4, 142.06 ms/it, loss 0.443954
Finished training it 2048/76743 of epoch 4, 142.43 ms/it, loss 0.445748
Finished training it 2048/76743 of epoch 4, 142.75 ms/it, loss 0.444443
Finished training it 2048/76743 of epoch 4, 142.57 ms/it, loss 0.445023
Finished training it 3072/76743 of epoch 4, 142.53 ms/it, loss 0.443841
Finished training it 3072/76743 of epoch 4, 143.23 ms/it, loss 0.442311
Finished training it 3072/76743 of epoch 4, 142.96 ms/it, loss 0.445235
Finished training it 3072/76743 of epoch 4, 143.03 ms/it, loss 0.444475
Finished training it 4096/76743 of epoch 4, 141.46 ms/it, loss 0.445148
Finished training it 4096/76743 of epoch 4, 141.25 ms/it, loss 0.447460
Finished training it 4096/76743 of epoch 4, 140.80 ms/it, loss 0.445193
Finished training it 4096/76743 of epoch 4, 141.00 ms/it, loss 0.443351
Finished training it 5120/76743 of epoch 4, 141.19 ms/it, loss 0.443241
Finished training it 5120/76743 of epoch 4, 140.72 ms/it, loss 0.444144
Finished training it 5120/76743 of epoch 4, 141.27 ms/it, loss 0.442709
Finished training it 5120/76743 of epoch 4, 140.96 ms/it, loss 0.441787
Finished training it 6144/76743 of epoch 4, 142.66 ms/it, loss 0.444949
Finished training it 6144/76743 of epoch 4, 142.74 ms/it, loss 0.447333
Finished training it 6144/76743 of epoch 4, 142.21 ms/it, loss 0.445431
Finished training it 6144/76743 of epoch 4, 142.63 ms/it, loss 0.444711
Finished training it 7168/76743 of epoch 4, 142.89 ms/it, loss 0.447147
Finished training it 7168/76743 of epoch 4, 142.30 ms/it, loss 0.443672
Finished training it 7168/76743 of epoch 4, 142.49 ms/it, loss 0.445298
Finished training it 7168/76743 of epoch 4, 142.64 ms/it, loss 0.445232
Finished training it 8192/76743 of epoch 4, 139.69 ms/it, loss 0.444087
Finished training it 8192/76743 of epoch 4, 139.94 ms/it, loss 0.444972
Finished training it 8192/76743 of epoch 4, 140.33 ms/it, loss 0.443337
Finished training it 8192/76743 of epoch 4, 139.83 ms/it, loss 0.446468
Finished training it 9216/76743 of epoch 4, 143.11 ms/it, loss 0.444323
Finished training it 9216/76743 of epoch 4, 143.55 ms/it, loss 0.446098
Finished training it 9216/76743 of epoch 4, 143.54 ms/it, loss 0.443011
Finished training it 9216/76743 of epoch 4, 143.67 ms/it, loss 0.444267
Finished training it 10240/76743 of epoch 4, 141.25 ms/it, loss 0.444016
Finished training it 10240/76743 of epoch 4, 141.72 ms/it, loss 0.445795
Finished training it 10240/76743 of epoch 4, 141.84 ms/it, loss 0.444730
Finished training it 10240/76743 of epoch 4, 141.65 ms/it, loss 0.443982
Testing at - 10240/76743 of epoch 4,
Testing at - 10240/76743 of epoch 4,
Testing at - 10240/76743 of epoch 4,
Testing at - 10240/76743 of epoch 4,
Warning: Skipping the batch 3197 with size 602
Warning: Skipping the batch 3197 with size 602
Warning: Skipping the batch 3197 with size 602
rank: 0 test_accu: 2580211.0
get out
0 has test check 2580211.0 and sample count 3273728
rank: 3 test_accu: 2580211.0
Warning: Skipping the batch 3197 with size 602
get out
rank: 1 test_accu: 2580211.0
3 has test check 2580211.0 and sample count 3273728
get out
1 has test check 2580211.0 and sample count 3273728
rank: 2 test_accu: 2580211.0
get out
2 has test check 2580211.0 and sample count 3273728
 accuracy 78.816 %, best 78.858 %, roc auc score 0.8020, best 0.8023
Saving model to /home/yz25672/dlrm_criteo_kaggle/save_model_after_training_one1.0.pt
Finished training it 11264/76743 of epoch 4, 140.85 ms/it, loss 0.443514
Finished training it 11264/76743 of epoch 4, 140.36 ms/it, loss 0.447451
Finished training it 11264/76743 of epoch 4, 140.85 ms/it, loss 0.443138
Finished training it 11264/76743 of epoch 4, 140.84 ms/it, loss 0.440863
Finished training it 12288/76743 of epoch 4, 142.30 ms/it, loss 0.444391
Finished training it 12288/76743 of epoch 4, 142.76 ms/it, loss 0.442418
Finished training it 12288/76743 of epoch 4, 142.80 ms/it, loss 0.445109
Finished training it 12288/76743 of epoch 4, 142.82 ms/it, loss 0.443835
Finished training it 13312/76743 of epoch 4, 143.04 ms/it, loss 0.441690
Finished training it 13312/76743 of epoch 4, 143.37 ms/it, loss 0.441561
Finished training it 13312/76743 of epoch 4, 143.54 ms/it, loss 0.443172
Finished training it 13312/76743 of epoch 4, 143.55 ms/it, loss 0.442014
Finished training it 14336/76743 of epoch 4, 144.14 ms/it, loss 0.442580
Finished training it 14336/76743 of epoch 4, 144.20 ms/it, loss 0.443737
Finished training it 14336/76743 of epoch 4, 143.75 ms/it, loss 0.442102
Finished training it 14336/76743 of epoch 4, 144.28 ms/it, loss 0.444096
Finished training it 15360/76743 of epoch 4, 142.23 ms/it, loss 0.443638
Finished training it 15360/76743 of epoch 4, 141.79 ms/it, loss 0.447220
Finished training it 15360/76743 of epoch 4, 142.26 ms/it, loss 0.441211
Finished training it 15360/76743 of epoch 4, 142.32 ms/it, loss 0.444463
Finished training it 16384/76743 of epoch 4, 143.22 ms/it, loss 0.443745
Finished training it 16384/76743 of epoch 4, 143.72 ms/it, loss 0.443490
Finished training it 16384/76743 of epoch 4, 143.81 ms/it, loss 0.441928
Finished training it 16384/76743 of epoch 4, 143.78 ms/it, loss 0.444772
Finished training it 17408/76743 of epoch 4, 146.84 ms/it, loss 0.445796
Finished training it 17408/76743 of epoch 4, 147.22 ms/it, loss 0.443894
Finished training it 17408/76743 of epoch 4, 147.33 ms/it, loss 0.445878
Finished training it 17408/76743 of epoch 4, 147.34 ms/it, loss 0.445782
Finished training it 18432/76743 of epoch 4, 140.85 ms/it, loss 0.447109
Finished training it 18432/76743 of epoch 4, 141.05 ms/it, loss 0.443820
Finished training it 18432/76743 of epoch 4, 141.29 ms/it, loss 0.444397
Finished training it 18432/76743 of epoch 4, 141.07 ms/it, loss 0.444851
Finished training it 19456/76743 of epoch 4, 141.08 ms/it, loss 0.443278
Finished training it 19456/76743 of epoch 4, 141.55 ms/it, loss 0.441568
Finished training it 19456/76743 of epoch 4, 141.55 ms/it, loss 0.442693
Finished training it 19456/76743 of epoch 4, 141.39 ms/it, loss 0.443698
Finished training it 20480/76743 of epoch 4, 138.82 ms/it, loss 0.444868
Finished training it 20480/76743 of epoch 4, 139.27 ms/it, loss 0.443704
Finished training it 20480/76743 of epoch 4, 139.10 ms/it, loss 0.444700
Finished training it 20480/76743 of epoch 4, 139.02 ms/it, loss 0.444635
Testing at - 20480/76743 of epoch 4,
Testing at - 20480/76743 of epoch 4,
Testing at - 20480/76743 of epoch 4,
Testing at - 20480/76743 of epoch 4,
Warning: Skipping the batch 3197 with size 602
rank: 1 test_accu: 2581221.0
get out
1 has test check 2581221.0 and sample count 3273728
Warning: Skipping the batch 3197 with size 602
rank: 0 test_accu: 2581221.0
get out
0 has test check 2581221.0 and sample count 3273728
Warning: Skipping the batch 3197 with size 602
Warning: Skipping the batch 3197 with size 602
rank: 2 test_accu: 2581221.0
get out
2 has test check 2581221.0 and sample count 3273728
rank: 3 test_accu: 2581221.0
get out
3 has test check 2581221.0 and sample count 3273728
 accuracy 78.847 %, best 78.858 %, roc auc score 0.8023, best 0.8023
Saving model to /home/yz25672/dlrm_criteo_kaggle/save_model_after_training_one0.0.pt
Start documenting table 0 gradient in table0epoch4_gradient.txt
Documented table 0 gradients in file table0epoch4_gradient.txt
Start documenting table 3 gradient in table3epoch4_gradient.txt
Documented table 3 gradients in file table3epoch4_gradient.txt
Start documenting table 6 gradient in table6epoch4_gradient.txt
Documented table 6 gradients in file table6epoch4_gradient.txt
Start documenting table 18 gradient in table18epoch4_gradient.txt
Documented table 18 gradients in file table18epoch4_gradient.txt
Start documenting table 20 gradient in table20epoch4_gradient.txt
Documented table 20 gradients in file table20epoch4_gradient.txt
Finished training it 21504/76743 of epoch 4, 143.34 ms/it, loss 0.442946
Finished training it 21504/76743 of epoch 4, 143.76 ms/it, loss 0.441590
Finished training it 21504/76743 of epoch 4, 143.80 ms/it, loss 0.444119
Finished training it 21504/76743 of epoch 4, 143.79 ms/it, loss 0.441954
Finished training it 22528/76743 of epoch 4, 143.79 ms/it, loss 0.442760
Finished training it 22528/76743 of epoch 4, 144.45 ms/it, loss 0.442252
Finished training it 22528/76743 of epoch 4, 144.34 ms/it, loss 0.446017
Finished training it 22528/76743 of epoch 4, 144.62 ms/it, loss 0.442866
Finished training it 23552/76743 of epoch 4, 140.99 ms/it, loss 0.445475
Finished training it 23552/76743 of epoch 4, 141.54 ms/it, loss 0.445458
Finished training it 23552/76743 of epoch 4, 141.63 ms/it, loss 0.445109
Finished training it 23552/76743 of epoch 4, 141.39 ms/it, loss 0.443688
Finished training it 24576/76743 of epoch 4, 143.33 ms/it, loss 0.442326
Finished training it 24576/76743 of epoch 4, 143.88 ms/it, loss 0.441396
Finished training it 24576/76743 of epoch 4, 143.71 ms/it, loss 0.440614
Finished training it 24576/76743 of epoch 4, 143.72 ms/it, loss 0.442507
Finished training it 25600/76743 of epoch 4, 141.70 ms/it, loss 0.443880
Finished training it 25600/76743 of epoch 4, 142.29 ms/it, loss 0.443839
Finished training it 25600/76743 of epoch 4, 142.65 ms/it, loss 0.445159
Finished training it 25600/76743 of epoch 4, 142.41 ms/it, loss 0.443561
Finished training it 26624/76743 of epoch 4, 141.22 ms/it, loss 0.444504
Finished training it 26624/76743 of epoch 4, 141.20 ms/it, loss 0.445968
Finished training it 26624/76743 of epoch 4, 140.49 ms/it, loss 0.445472
Finished training it 26624/76743 of epoch 4, 141.04 ms/it, loss 0.445842
Finished training it 27648/76743 of epoch 4, 142.72 ms/it, loss 0.443496
Finished training it 27648/76743 of epoch 4, 142.83 ms/it, loss 0.445038
Finished training it 27648/76743 of epoch 4, 142.86 ms/it, loss 0.444707
Finished training it 27648/76743 of epoch 4, 142.28 ms/it, loss 0.443384
Finished training it 28672/76743 of epoch 4, 141.48 ms/it, loss 0.445459
Finished training it 28672/76743 of epoch 4, 142.04 ms/it, loss 0.443623
Finished training it 28672/76743 of epoch 4, 141.74 ms/it, loss 0.442526
Finished training it 28672/76743 of epoch 4, 142.07 ms/it, loss 0.442020
Finished training it 29696/76743 of epoch 4, 140.79 ms/it, loss 0.445461
Finished training it 29696/76743 of epoch 4, 141.30 ms/it, loss 0.443601
Finished training it 29696/76743 of epoch 4, 141.30 ms/it, loss 0.439902
Finished training it 29696/76743 of epoch 4, 141.29 ms/it, loss 0.445174
Finished training it 30720/76743 of epoch 4, 142.67 ms/it, loss 0.443016
Finished training it 30720/76743 of epoch 4, 143.28 ms/it, loss 0.443253
Finished training it 30720/76743 of epoch 4, 143.10 ms/it, loss 0.443440
Finished training it 30720/76743 of epoch 4, 143.11 ms/it, loss 0.445725
Testing at - 30720/76743 of epoch 4,
Testing at - 30720/76743 of epoch 4,
Testing at - 30720/76743 of epoch 4,
Testing at - 30720/76743 of epoch 4,
Warning: Skipping the batch 3197 with size 602
Warning: Skipping the batch 3197 with size 602
Warning: Skipping the batch 3197 with size 602
rank: 1 test_accu: 2581471.0
get out
rank: 2 test_accu: 2581471.0
1 has test check 2581471.0 and sample count 3273728
rank: 0 test_accu: 2581471.0
get out
get out
2 has test check 2581471.0 and sample count 3273728
0 has test check 2581471.0 and sample count 3273728
Warning: Skipping the batch 3197 with size 602
rank: 3 test_accu: 2581471.0
get out
3 has test check 2581471.0 and sample count 3273728
 accuracy 78.854 %, best 78.858 %, roc auc score 0.8026, best 0.8026
Saving model to /home/yz25672/dlrm_criteo_kaggle/save_model_after_training_one1.0.pt
Finished training it 31744/76743 of epoch 4, 142.57 ms/it, loss 0.445361
Finished training it 31744/76743 of epoch 4, 142.38 ms/it, loss 0.442233
Finished training it 31744/76743 of epoch 4, 142.18 ms/it, loss 0.443959
Finished training it 31744/76743 of epoch 4, 141.80 ms/it, loss 0.442557
Finished training it 32768/76743 of epoch 4, 142.73 ms/it, loss 0.445064
Finished training it 32768/76743 of epoch 4, 143.17 ms/it, loss 0.441841
Finished training it 32768/76743 of epoch 4, 143.26 ms/it, loss 0.443910
Finished training it 32768/76743 of epoch 4, 143.29 ms/it, loss 0.441128
Finished training it 33792/76743 of epoch 4, 142.94 ms/it, loss 0.445300
Finished training it 33792/76743 of epoch 4, 143.31 ms/it, loss 0.439897
Finished training it 33792/76743 of epoch 4, 143.39 ms/it, loss 0.442996
Finished training it 33792/76743 of epoch 4, 143.50 ms/it, loss 0.445630
Finished training it 34816/76743 of epoch 4, 138.31 ms/it, loss 0.443479
Finished training it 34816/76743 of epoch 4, 138.60 ms/it, loss 0.443825
Finished training it 34816/76743 of epoch 4, 138.61 ms/it, loss 0.444181
Finished training it 34816/76743 of epoch 4, 138.77 ms/it, loss 0.441174
Finished training it 35840/76743 of epoch 4, 142.41 ms/it, loss 0.442263
Finished training it 35840/76743 of epoch 4, 142.85 ms/it, loss 0.445288
Finished training it 35840/76743 of epoch 4, 142.68 ms/it, loss 0.445218
Finished training it 35840/76743 of epoch 4, 142.80 ms/it, loss 0.443477
Finished training it 36864/76743 of epoch 4, 140.63 ms/it, loss 0.442458
Finished training it 36864/76743 of epoch 4, 140.94 ms/it, loss 0.443535
Finished training it 36864/76743 of epoch 4, 141.07 ms/it, loss 0.442379
Finished training it 36864/76743 of epoch 4, 141.19 ms/it, loss 0.445159
Finished training it 37888/76743 of epoch 4, 143.98 ms/it, loss 0.442821
Finished training it 37888/76743 of epoch 4, 143.88 ms/it, loss 0.443449
Finished training it 37888/76743 of epoch 4, 144.18 ms/it, loss 0.443651
Finished training it 37888/76743 of epoch 4, 143.52 ms/it, loss 0.443391
Finished training it 38912/76743 of epoch 4, 141.22 ms/it, loss 0.443973
Finished training it 38912/76743 of epoch 4, 141.43 ms/it, loss 0.445150
Finished training it 38912/76743 of epoch 4, 141.56 ms/it, loss 0.443744
Finished training it 38912/76743 of epoch 4, 141.55 ms/it, loss 0.440614
Finished training it 39936/76743 of epoch 4, 140.40 ms/it, loss 0.444500
Finished training it 39936/76743 of epoch 4, 140.62 ms/it, loss 0.444017
Finished training it 39936/76743 of epoch 4, 140.68 ms/it, loss 0.443791
Finished training it 39936/76743 of epoch 4, 140.77 ms/it, loss 0.443062
Finished training it 40960/76743 of epoch 4, 139.93 ms/it, loss 0.440887
Finished training it 40960/76743 of epoch 4, 140.18 ms/it, loss 0.444151
Finished training it 40960/76743 of epoch 4, 140.32 ms/it, loss 0.445126
Finished training it 40960/76743 of epoch 4, 140.35 ms/it, loss 0.443971
Testing at - 40960/76743 of epoch 4,
Testing at - 40960/76743 of epoch 4,
Testing at - 40960/76743 of epoch 4,
Testing at - 40960/76743 of epoch 4,
Warning: Skipping the batch 3197 with size 602
rank: 1 test_accu: 2577915.0
get out
1 has test check 2577915.0 and sample count 3273728
Warning: Skipping the batch 3197 with size 602
Warning: Skipping the batch 3197 with size 602
Warning: Skipping the batch 3197 with size 602
rank: 3 test_accu: 2577915.0
get out
rank: 2 test_accu: 2577915.0
3 has test check 2577915.0 and sample count 3273728
get out
2 has test check 2577915.0 and sample count 3273728
rank: 0 test_accu: 2577915.0
get out
0 has test check 2577915.0 and sample count 3273728
 accuracy 78.746 %, best 78.858 %, roc auc score 0.8024, best 0.8026
Saving model to /home/yz25672/dlrm_criteo_kaggle/save_model_after_training_one0.0.pt
Start documenting table 0 gradient in table0epoch4_gradient.txt
Documented table 0 gradients in file table0epoch4_gradient.txt
Start documenting table 3 gradient in table3epoch4_gradient.txt
Documented table 3 gradients in file table3epoch4_gradient.txt
Start documenting table 6 gradient in table6epoch4_gradient.txt
Documented table 6 gradients in file table6epoch4_gradient.txt
Start documenting table 18 gradient in table18epoch4_gradient.txt
Documented table 18 gradients in file table18epoch4_gradient.txt
Start documenting table 20 gradient in table20epoch4_gradient.txt
Documented table 20 gradients in file table20epoch4_gradient.txt
Finished training it 41984/76743 of epoch 4, 143.68 ms/it, loss 0.443191
Finished training it 41984/76743 of epoch 4, 144.50 ms/it, loss 0.442345
Finished training it 41984/76743 of epoch 4, 144.64 ms/it, loss 0.440627
Finished training it 41984/76743 of epoch 4, 144.60 ms/it, loss 0.442181
Finished training it 43008/76743 of epoch 4, 143.91 ms/it, loss 0.444453
Finished training it 43008/76743 of epoch 4, 144.31 ms/it, loss 0.442746
Finished training it 43008/76743 of epoch 4, 144.45 ms/it, loss 0.442097
Finished training it 43008/76743 of epoch 4, 144.50 ms/it, loss 0.443329
Finished training it 44032/76743 of epoch 4, 140.87 ms/it, loss 0.442834
Finished training it 44032/76743 of epoch 4, 141.45 ms/it, loss 0.441581
Finished training it 44032/76743 of epoch 4, 141.30 ms/it, loss 0.445477
Finished training it 44032/76743 of epoch 4, 141.20 ms/it, loss 0.442404
Finished training it 45056/76743 of epoch 4, 143.25 ms/it, loss 0.441261
Finished training it 45056/76743 of epoch 4, 143.87 ms/it, loss 0.445081
Finished training it 45056/76743 of epoch 4, 143.64 ms/it, loss 0.442438
Finished training it 45056/76743 of epoch 4, 143.64 ms/it, loss 0.444166
Finished training it 46080/76743 of epoch 4, 144.01 ms/it, loss 0.444985
Finished training it 46080/76743 of epoch 4, 144.46 ms/it, loss 0.443220
Finished training it 46080/76743 of epoch 4, 144.40 ms/it, loss 0.443239
Finished training it 46080/76743 of epoch 4, 144.56 ms/it, loss 0.442818
Finished training it 47104/76743 of epoch 4, 142.42 ms/it, loss 0.443110
Finished training it 47104/76743 of epoch 4, 143.00 ms/it, loss 0.443117
Finished training it 47104/76743 of epoch 4, 143.10 ms/it, loss 0.445049
Finished training it 47104/76743 of epoch 4, 143.14 ms/it, loss 0.442854
Finished training it 48128/76743 of epoch 4, 142.63 ms/it, loss 0.444501
Finished training it 48128/76743 of epoch 4, 143.23 ms/it, loss 0.443827
Finished training it 48128/76743 of epoch 4, 143.10 ms/it, loss 0.442787
Finished training it 48128/76743 of epoch 4, 143.41 ms/it, loss 0.444292
Finished training it 49152/76743 of epoch 4, 142.05 ms/it, loss 0.443563
Finished training it 49152/76743 of epoch 4, 142.54 ms/it, loss 0.445970
Finished training it 49152/76743 of epoch 4, 142.74 ms/it, loss 0.443311
Finished training it 49152/76743 of epoch 4, 142.15 ms/it, loss 0.443118
Finished training it 50176/76743 of epoch 4, 141.06 ms/it, loss 0.444612
Finished training it 50176/76743 of epoch 4, 141.05 ms/it, loss 0.444207
Finished training it 50176/76743 of epoch 4, 140.34 ms/it, loss 0.441717
Finished training it 50176/76743 of epoch 4, 141.27 ms/it, loss 0.443971
Finished training it 51200/76743 of epoch 4, 142.66 ms/it, loss 0.441760
Finished training it 51200/76743 of epoch 4, 142.23 ms/it, loss 0.446365
Finished training it 51200/76743 of epoch 4, 142.74 ms/it, loss 0.443140
Finished training it 51200/76743 of epoch 4, 142.75 ms/it, loss 0.444972
Testing at - 51200/76743 of epoch 4,
Testing at - 51200/76743 of epoch 4,
Testing at - 51200/76743 of epoch 4,
Testing at - 51200/76743 of epoch 4,
Warning: Skipping the batch 3197 with size 602
Warning: Skipping the batch 3197 with size 602
rank: 2 test_accu: 2581048.0
Warning: Skipping the batch 3197 with size 602
get out
rank: 3 test_accu: 2581048.0
2 has test check 2581048.0 and sample count 3273728
get out
3 has test check 2581048.0 and sample count 3273728
rank: 0 test_accu: 2581048.0
Warning: Skipping the batch 3197 with size 602
get out
0 has test check 2581048.0 and sample count 3273728
rank: 1 test_accu: 2581048.0
get out
1 has test check 2581048.0 and sample count 3273728
 accuracy 78.841 %, best 78.858 %, roc auc score 0.8029, best 0.8029
Saving model to /home/yz25672/dlrm_criteo_kaggle/save_model_after_training_one1.0.pt
Finished training it 52224/76743 of epoch 4, 143.19 ms/it, loss 0.445962
Finished training it 52224/76743 of epoch 4, 143.56 ms/it, loss 0.444626
Finished training it 52224/76743 of epoch 4, 143.80 ms/it, loss 0.444090
Finished training it 52224/76743 of epoch 4, 143.92 ms/it, loss 0.439463
Finished training it 53248/76743 of epoch 4, 141.12 ms/it, loss 0.440850
Finished training it 53248/76743 of epoch 4, 141.42 ms/it, loss 0.442768
Finished training it 53248/76743 of epoch 4, 141.55 ms/it, loss 0.439910
Finished training it 53248/76743 of epoch 4, 141.84 ms/it, loss 0.442587
Finished training it 54272/76743 of epoch 4, 143.77 ms/it, loss 0.441130
Finished training it 54272/76743 of epoch 4, 144.05 ms/it, loss 0.440423
Finished training it 54272/76743 of epoch 4, 144.55 ms/it, loss 0.445461
Finished training it 54272/76743 of epoch 4, 144.67 ms/it, loss 0.443029
Finished training it 55296/76743 of epoch 4, 141.00 ms/it, loss 0.442490
Finished training it 55296/76743 of epoch 4, 141.45 ms/it, loss 0.443893
Finished training it 55296/76743 of epoch 4, 141.85 ms/it, loss 0.443660
Finished training it 55296/76743 of epoch 4, 141.80 ms/it, loss 0.440728
Finished training it 56320/76743 of epoch 4, 143.51 ms/it, loss 0.445391
Finished training it 56320/76743 of epoch 4, 143.80 ms/it, loss 0.443136
Finished training it 56320/76743 of epoch 4, 143.96 ms/it, loss 0.445035
Finished training it 56320/76743 of epoch 4, 144.04 ms/it, loss 0.443170
Finished training it 57344/76743 of epoch 4, 141.94 ms/it, loss 0.443420
Finished training it 57344/76743 of epoch 4, 142.23 ms/it, loss 0.444535
Finished training it 57344/76743 of epoch 4, 142.38 ms/it, loss 0.445166
Finished training it 57344/76743 of epoch 4, 142.62 ms/it, loss 0.443771
Finished training it 58368/76743 of epoch 4, 141.23 ms/it, loss 0.443167
Finished training it 58368/76743 of epoch 4, 141.43 ms/it, loss 0.440678
Finished training it 58368/76743 of epoch 4, 141.84 ms/it, loss 0.444261
Finished training it 58368/76743 of epoch 4, 141.74 ms/it, loss 0.441100
Finished training it 59392/76743 of epoch 4, 140.78 ms/it, loss 0.439166
Finished training it 59392/76743 of epoch 4, 141.46 ms/it, loss 0.441655
Finished training it 59392/76743 of epoch 4, 141.06 ms/it, loss 0.440370
Finished training it 59392/76743 of epoch 4, 141.23 ms/it, loss 0.440271
Finished training it 60416/76743 of epoch 4, 141.31 ms/it, loss 0.441438
Finished training it 60416/76743 of epoch 4, 141.72 ms/it, loss 0.444745
Finished training it 60416/76743 of epoch 4, 141.87 ms/it, loss 0.439006
Finished training it 60416/76743 of epoch 4, 141.76 ms/it, loss 0.441612
Finished training it 61440/76743 of epoch 4, 142.04 ms/it, loss 0.441334
Finished training it 61440/76743 of epoch 4, 142.73 ms/it, loss 0.441950
Finished training it 61440/76743 of epoch 4, 142.51 ms/it, loss 0.443749
Finished training it 61440/76743 of epoch 4, 142.33 ms/it, loss 0.443743
Testing at - 61440/76743 of epoch 4,
Testing at - 61440/76743 of epoch 4,
Testing at - 61440/76743 of epoch 4,
Testing at - 61440/76743 of epoch 4,
Warning: Skipping the batch 3197 with size 602
rank: 0 test_accu: 2581734.0
get out
0 has test check 2581734.0 and sample count 3273728
Warning: Skipping the batch 3197 with size 602
Warning: Skipping the batch 3197 with size 602
rank: 1 test_accu: 2581734.0
rank: 3 test_accu: 2581734.0
get out
Warning: Skipping the batch 3197 with size 602
get out
1 has test check 2581734.0 and sample count 3273728
3 has test check 2581734.0 and sample count 3273728
rank: 2 test_accu: 2581734.0
get out
2 has test check 2581734.0 and sample count 3273728
 accuracy 78.862 %, best 78.862 %, roc auc score 0.8026, best 0.8029
Saving model to /home/yz25672/dlrm_criteo_kaggle/save_model_after_training_one0.0.pt
Start documenting table 0 gradient in table0epoch4_gradient.txt
Documented table 0 gradients in file table0epoch4_gradient.txt
Start documenting table 3 gradient in table3epoch4_gradient.txt
Documented table 3 gradients in file table3epoch4_gradient.txt
Start documenting table 6 gradient in table6epoch4_gradient.txt
Documented table 6 gradients in file table6epoch4_gradient.txt
Start documenting table 18 gradient in table18epoch4_gradient.txt
Documented table 18 gradients in file table18epoch4_gradient.txt
Start documenting table 20 gradient in table20epoch4_gradient.txt
Documented table 20 gradients in file table20epoch4_gradient.txt
Finished training it 62464/76743 of epoch 4, 143.30 ms/it, loss 0.443837
Finished training it 62464/76743 of epoch 4, 143.77 ms/it, loss 0.441797
Finished training it 62464/76743 of epoch 4, 143.61 ms/it, loss 0.442526
Finished training it 62464/76743 of epoch 4, 144.06 ms/it, loss 0.440710
Finished training it 63488/76743 of epoch 4, 140.64 ms/it, loss 0.442805
Finished training it 63488/76743 of epoch 4, 141.16 ms/it, loss 0.444429
Finished training it 63488/76743 of epoch 4, 141.07 ms/it, loss 0.443963
Finished training it 63488/76743 of epoch 4, 140.83 ms/it, loss 0.440072
Finished training it 64512/76743 of epoch 4, 144.92 ms/it, loss 0.446325
Finished training it 64512/76743 of epoch 4, 145.51 ms/it, loss 0.444007
Finished training it 64512/76743 of epoch 4, 145.61 ms/it, loss 0.440503
Finished training it 64512/76743 of epoch 4, 145.31 ms/it, loss 0.441172
Finished training it 65536/76743 of epoch 4, 142.96 ms/it, loss 0.441941
Finished training it 65536/76743 of epoch 4, 143.63 ms/it, loss 0.442721
Finished training it 65536/76743 of epoch 4, 143.53 ms/it, loss 0.440952
Finished training it 65536/76743 of epoch 4, 143.45 ms/it, loss 0.443643
Finished training it 66560/76743 of epoch 4, 140.02 ms/it, loss 0.443458
Finished training it 66560/76743 of epoch 4, 139.52 ms/it, loss 0.443260
Finished training it 66560/76743 of epoch 4, 139.65 ms/it, loss 0.445410
Finished training it 66560/76743 of epoch 4, 139.81 ms/it, loss 0.441867
Finished training it 67584/76743 of epoch 4, 141.96 ms/it, loss 0.440116
Finished training it 67584/76743 of epoch 4, 142.26 ms/it, loss 0.442942
Finished training it 67584/76743 of epoch 4, 142.10 ms/it, loss 0.442018
Finished training it 67584/76743 of epoch 4, 142.37 ms/it, loss 0.440780
Finished training it 68608/76743 of epoch 4, 140.30 ms/it, loss 0.444580
Finished training it 68608/76743 of epoch 4, 140.83 ms/it, loss 0.444132
Finished training it 68608/76743 of epoch 4, 140.49 ms/it, loss 0.441661
Finished training it 68608/76743 of epoch 4, 140.97 ms/it, loss 0.443472
Finished training it 69632/76743 of epoch 4, 145.45 ms/it, loss 0.440467
Finished training it 69632/76743 of epoch 4, 145.89 ms/it, loss 0.439812
Finished training it 69632/76743 of epoch 4, 145.76 ms/it, loss 0.445822
Finished training it 69632/76743 of epoch 4, 145.74 ms/it, loss 0.444137
Finished training it 70656/76743 of epoch 4, 141.39 ms/it, loss 0.442312
Finished training it 70656/76743 of epoch 4, 141.84 ms/it, loss 0.441645
Finished training it 70656/76743 of epoch 4, 141.70 ms/it, loss 0.440073
Finished training it 70656/76743 of epoch 4, 141.80 ms/it, loss 0.442473
Finished training it 71680/76743 of epoch 4, 140.60 ms/it, loss 0.442742
Finished training it 71680/76743 of epoch 4, 140.93 ms/it, loss 0.441765
Finished training it 71680/76743 of epoch 4, 140.85 ms/it, loss 0.443939
Finished training it 71680/76743 of epoch 4, 140.94 ms/it, loss 0.445367
Testing at - 71680/76743 of epoch 4,
Testing at - 71680/76743 of epoch 4,
Testing at - 71680/76743 of epoch 4,
Testing at - 71680/76743 of epoch 4,
Warning: Skipping the batch 3197 with size 602
Warning: Skipping the batch 3197 with size 602
Warning: Skipping the batch 3197 with size 602
rank: 1 test_accu: 2582249.0
rank: 0 test_accu: 2582249.0
get out
Warning: Skipping the batch 3197 with size 602
get out
1 has test check 2582249.0 and sample count 3273728
0 has test check 2582249.0 and sample count 3273728
rank: 3 test_accu: 2582249.0
get out
3 has test check 2582249.0 and sample count 3273728
rank: 2 test_accu: 2582249.0
get out
2 has test check 2582249.0 and sample count 3273728
 accuracy 78.878 %, best 78.878 %, roc auc score 0.8032, best 0.8032
Saving model to /home/yz25672/dlrm_criteo_kaggle/save_model_after_training_one1.0.pt
Finished training it 72704/76743 of epoch 4, 143.54 ms/it, loss 0.441858
Finished training it 72704/76743 of epoch 4, 143.15 ms/it, loss 0.442527
Finished training it 72704/76743 of epoch 4, 143.95 ms/it, loss 0.442856
Finished training it 72704/76743 of epoch 4, 143.77 ms/it, loss 0.442806
Finished training it 73728/76743 of epoch 4, 143.69 ms/it, loss 0.441449
Finished training it 73728/76743 of epoch 4, 144.25 ms/it, loss 0.442954
Finished training it 73728/76743 of epoch 4, 144.28 ms/it, loss 0.442305
Finished training it 73728/76743 of epoch 4, 144.42 ms/it, loss 0.440961
Finished training it 74752/76743 of epoch 4, 143.17 ms/it, loss 0.441340
Finished training it 74752/76743 of epoch 4, 143.63 ms/it, loss 0.440487
Finished training it 74752/76743 of epoch 4, 143.57 ms/it, loss 0.442457
Finished training it 74752/76743 of epoch 4, 143.76 ms/it, loss 0.443315
Finished training it 75776/76743 of epoch 4, 141.61 ms/it, loss 0.440846
Finished training it 75776/76743 of epoch 4, 141.90 ms/it, loss 0.443368
Finished training it 75776/76743 of epoch 4, 142.05 ms/it, loss 0.445894
Finished training it 75776/76743 of epoch 4, 142.23 ms/it, loss 0.441741
Warning: Skipping the batch 76742 with size 14
Testing at - 76743/76743 of epoch 5,
Warning: Skipping the batch 76742 with size 14
Testing at - 76743/76743 of epoch 5,
Warning: Skipping the batch 76742 with size 14
Testing at - 76743/76743 of epoch 5,
Warning: Skipping the batch 76742 with size 14
Testing at - 76743/76743 of epoch 5,
Warning: Skipping the batch 3197 with size 602
Warning: Skipping the batch 3197 with size 602
rank: 0 test_accu: 2581854.0
get out
0 has test check 2581854.0 and sample count 3273728
rank: 3 test_accu: 2581854.0
get out
3 has test check 2581854.0 and sample count 3273728
Warning: Skipping the batch 3197 with size 602
Warning: Skipping the batch 3197 with size 602
rank: 2 test_accu: 2581854.0
get out
2 has test check 2581854.0 and sample count 3273728
rank: 1 test_accu: 2581854.0
get out
1 has test check 2581854.0 and sample count 3273728
 accuracy 78.866 %, best 78.878 %, roc auc score 0.8031, best 0.8032
(base) yz25672@hopper:~/Training_DLRM_fast$ ls
2022_7_7_running_script_one.sh     dlrm_s_pytorch.py                          run_dlrm_kaggle_gpu_four.sh
cython                             dlrm_training_16bit_2.txt                  run_dlrm_kaggle_gpu_gtone.sh
data_loader_terabyte.py            extend_distributed.py                      run_dlrm_kaggle_gpu_onegpu.sh
data_utils.py                      files_title.txt                            run_dlrm_kaggle_gpu_pretrain_and_quantize.sh
discovering_rowise_hotness.py      kaggle_dac_loss_accuracy_plots.png         run_dlrm_kaggle_pseudo_gpus.sh
discovering_rowise_hotness_s.sh    looking_into_tables_and_quantize.py        run_kaggle_pt
dlrm_3pochs.txt                    looking_into_tables_and_quantize_split.py  run_para.sh
dlrm_data_pytorch.py               looking_into_tables.py                     run_t.sh
dlrm_four_gpu_experiment.txt       mlperf_logger.py                           run_t_two.sh
dlrm_grademb8bit.txt               optim                                      sgd_quantized_gradients_parallel_comm.py
dlrm_moving_bound_periter_300.txt  __pycache__                                sgd_quantized_gradients.py
dlrm_s_pytorch_comm_grad.py        quantization_supp                          terabyte_0875_loss_accuracy_plots.png
dlrm_s_pytorch_dp_only.py          README.md                                  tools
dlrm_s_pytorch_one_gpu.py          requirements.txt                           training_imagenet_speedup.py
dlrm_s_pytorch_pseudo_multigpu.py  run_dist.sh                                tricks
(base) yz25672@hopper:~/Training_DLRM_fast$ bash -x run_dlrm_kaggle_gpu_four.sh
+ python dlrm_s_pytorch_comm_grad.py --arch-sparse-feature-size=16 --arch-mlp-bot=13-512-256-64-16 --arch-mlp-top=512-256-1 --nepochs=5 --data-generation=dataset --data-set=kaggle --raw-data-file=/home/yz25672
/dlrm_criteo_kaggle/train.txt --processed-data-file=/home/yz25672/dlrm_criteo_kaggle/kaggleAdDisplayChallenge_processed.npz --loss-function=bce --round-targets=True --learning-rate=0.1 --mini-batch-size=128 --
print-freq=1024 --print-time --test-mini-batch-size=1024 --use-gpu --save-model=/home/yz25672/dlrm_criteo_kaggle/save_model_after_training_one.pt --quantization_flag --embedding_bit=4 --quantize_act_and_lin --
weight_bit=4 --linear_channel --test-freq=10240 --embedding_bag_gradient_bit_num=16 --quantize_embedding_bag_gradient -n 1 -g 4 -nr 0
Unable to import mlperf_logging,  No module named 'mlperf_logging'
^CTraceback (most recent call last):
  File "/home/yz25672/Training_DLRM_fast/dlrm_s_pytorch_comm_grad.py", line 93, in <module>
    from torch.utils.tensorboard import SummaryWriter
  File "/home/yz25672/anaconda3/lib/python3.9/site-packages/torch/utils/tensorboard/__init__.py", line 12, in <module>
    from .writer import FileWriter, SummaryWriter  # noqa: F401
  File "/home/yz25672/anaconda3/lib/python3.9/site-packages/torch/utils/tensorboard/writer.py", line 9, in <module>
    from tensorboard.compat.proto.event_pb2 import SessionLog
  File "/home/yz25672/anaconda3/lib/python3.9/site-packages/tensorboard/compat/proto/event_pb2.py", line 8, in <module>
    from google.protobuf import descriptor as _descriptor
  File "/home/yz25672/anaconda3/lib/python3.9/site-packages/google/protobuf/descriptor.py", line 47, in <module>
    from google.protobuf.pyext import _message
  File "/home/yz25672/anaconda3/lib/python3.9/abc.py", line 110, in register
    def register(cls, subclass):
KeyboardInterrupt

(base) yz25672@hopper:~/Training_DLRM_fast$ bash -x run_dlrm_kaggle_gpu_four.sh
+ python dlrm_s_pytorch_comm_grad.py --arch-sparse-feature-size=16 --arch-mlp-bot=13-512-256-64-16 --arch-mlp-top=512-256-1 --nepochs=5 --data-generation=dataset --data-set=kaggle --raw-data-file=/home/yz25672
/dlrm_criteo_kaggle/train.txt --processed-data-file=/home/yz25672/dlrm_criteo_kaggle/kaggleAdDisplayChallenge_processed.npz --loss-function=bce --round-targets=True --learning-rate=0.1 --mini-batch-size=128 --
print-freq=1024 --print-time --test-mini-batch-size=1024 --use-gpu --save-model=/home/yz25672/dlrm_criteo_kaggle/save_model_after_training_one.pt --quantization_flag --embedding_bit=4 --quantize_act_and_lin --
weight_bit=4 --linear_channel --test-freq=10240 --embedding_bag_gradient_bit_num=16 --quantize_embedding_bag_gradient -n 1 -g 4 -nr 0
Unable to import mlperf_logging,  No module named 'mlperf_logging'
Unable to import mlperf_logging,  No module named 'mlperf_logging'
Unable to import mlperf_logging,  No module named 'mlperf_logging'
Unable to import mlperf_logging,  No module named 'mlperf_logging'
Unable to import mlperf_logging,  No module named 'mlperf_logging'
Warning: local_rank gpu mismatch
4 out of -1 (GPU)
---------- embedding bag gradient quantized in 16 bits
Reading pre-processed data=/home/yz25672/dlrm_criteo_kaggle/kaggleAdDisplayChallenge_processed.npz
Warning: local_rank gpu mismatch
4 out of -1 (GPU)
---------- embedding bag gradient quantized in 16 bits
Reading pre-processed data=/home/yz25672/dlrm_criteo_kaggle/kaggleAdDisplayChallenge_processed.npz
Warning: local_rank gpu mismatch
4 out of -1 (GPU)
---------- embedding bag gradient quantized in 16 bits
Reading pre-processed data=/home/yz25672/dlrm_criteo_kaggle/kaggleAdDisplayChallenge_processed.npz
Warning: local_rank gpu mismatch
4 out of -1 (GPU)
---------- embedding bag gradient quantized in 16 bits
Reading pre-processed data=/home/yz25672/dlrm_criteo_kaggle/kaggleAdDisplayChallenge_processed.npz
Sparse fea = 26, Dense fea = 13
Defined train indices...
Randomized indices across days ...
Sparse fea = 26, Dense fea = 13
Defined train indices...
Randomized indices across days ...
Sparse fea = 26, Dense fea = 13
Defined train indices...
Sparse fea = 26, Dense fea = 13
Randomized indices across days ...
Defined train indices...
Randomized indices across days ...
Split data according to indices...
Reading pre-processed data=/home/yz25672/dlrm_criteo_kaggle/kaggleAdDisplayChallenge_processed.npz
Split data according to indices...
Reading pre-processed data=/home/yz25672/dlrm_criteo_kaggle/kaggleAdDisplayChallenge_processed.npz
Split data according to indices...
Reading pre-processed data=/home/yz25672/dlrm_criteo_kaggle/kaggleAdDisplayChallenge_processed.npz
Split data according to indices...
Reading pre-processed data=/home/yz25672/dlrm_criteo_kaggle/kaggleAdDisplayChallenge_processed.npz
Sparse fea = 26, Dense fea = 13
Defined test indices...
Randomized indices across days ...
Split data according to indices...
number of devices 1
world size found is -1
---------- Embedding Table 0, quantization used, n = 1460, m = 16, quantization bit set to 4
---------- Embedding Table 1, quantization used, n = 583, m = 16, quantization bit set to 4
---------- Embedding Table 2, quantization used, n = 10131227, m = 16, quantization bit set to 4
---------- Embedding Table 3, quantization used, n = 2202608, m = 16, quantization bit set to 4
---------- Embedding Table 4, quantization used, n = 305, m = 16, quantization bit set to 4
---------- Embedding Table 5, quantization used, n = 24, m = 16, quantization bit set to 4
Sparse fea = 26, Dense fea = 13
Defined test indices...
Randomized indices across days ...
Sparse fea = 26, Dense fea = 13
Defined test indices...
Split data according to indices...
number of devices 1
world size found is -1
---------- Embedding Table 0, quantization used, n = 1460, m = 16, quantization bit set to 4
---------- Embedding Table 1, quantization used, n = 583, m = 16, quantization bit set to 4
---------- Embedding Table 2, quantization used, n = 10131227, m = 16, quantization bit set to 4
Randomized indices across days ...
Sparse fea = 26, Dense fea = 13
^CTraceback (most recent call last):
  File "/home/yz25672/Training_DLRM_fast/dlrm_s_pytorch_comm_grad.py", line 2180, in <module>
    run()
  File "/home/yz25672/Training_DLRM_fast/dlrm_s_pytorch_comm_grad.py", line 1157, in run
    mp.spawn(train, nprocs = args.gpus, args = (args,))
  File "/home/yz25672/anaconda3/lib/python3.9/site-packages/torch/multiprocessing/spawn.py", line 240, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/home/yz25672/anaconda3/lib/python3.9/site-packages/torch/multiprocessing/spawn.py", line 198, in start_processes
    while not context.join():
  File "/home/yz25672/anaconda3/lib/python3.9/site-packages/torch/multiprocessing/spawn.py", line 109, in join
    ready = multiprocessing.connection.wait(
  File "/home/yz25672/anaconda3/lib/python3.9/multiprocessing/connection.py", line 936, in wait
    ready = selector.select(timeout)
  File "/home/yz25672/anaconda3/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
KeyboardInterrupt

(base) yz25672@hopper:~/Training_DLRM_fast$
