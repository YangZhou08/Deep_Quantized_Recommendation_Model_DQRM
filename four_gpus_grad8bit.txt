Unable to import mlperf_logging,  No module named 'mlperf_logging'
Unable to import mlperf_logging,  No module named 'mlperf_logging'
Warning: local_rank gpu mismatch
4 out of -1 (GPU)
---------- embedding bag gradient quantized in 8 bits
Reading pre-processed data=/home/yzhou/dlrm_criteo_kaggle/kaggleAdDisplayChallenge_processed.npz
Sparse fea = 26, Dense fea = 13
Defined train indices...
Randomized indices across days ...
Split data according to indices...
Reading pre-processed data=/home/yzhou/dlrm_criteo_kaggle/kaggleAdDisplayChallenge_processed.npz
Sparse fea = 26, Dense fea = 13
Defined test indices...
Randomized indices across days ...
Split data according to indices...
number of devices 1
world size found is -1
---------- Embedding Table 0, quantization used, n = 1460, m = 16, quantization bit set to 4
---------- Embedding Table 1, quantization used, n = 583, m = 16, quantization bit set to 4
---------- Embedding Table 2, quantization used, n = 10131227, m = 16, quantization bit set to 4
---------- Embedding Table 3, quantization used, n = 2202608, m = 16, quantization bit set to 4
---------- Embedding Table 4, quantization used, n = 305, m = 16, quantization bit set to 4
---------- Embedding Table 5, quantization used, n = 24, m = 16, quantization bit set to 4
---------- Embedding Table 6, quantization used, n = 12517, m = 16, quantization bit set to 4
---------- Embedding Table 7, quantization used, n = 633, m = 16, quantization bit set to 4
---------- Embedding Table 8, quantization used, n = 3, m = 16, quantization bit set to 4
---------- Embedding Table 9, quantization used, n = 93145, m = 16, quantization bit set to 4
---------- Embedding Table 10, quantization used, n = 5683, m = 16, quantization bit set to 4
---------- Embedding Table 11, quantization used, n = 8351593, m = 16, quantization bit set to 4
---------- Embedding Table 12, quantization used, n = 3194, m = 16, quantization bit set to 4
---------- Embedding Table 13, quantization used, n = 27, m = 16, quantization bit set to 4
---------- Embedding Table 14, quantization used, n = 14992, m = 16, quantization bit set to 4
---------- Embedding Table 15, quantization used, n = 5461306, m = 16, quantization bit set to 4
---------- Embedding Table 16, quantization used, n = 10, m = 16, quantization bit set to 4
---------- Embedding Table 17, quantization used, n = 5652, m = 16, quantization bit set to 4
---------- Embedding Table 18, quantization used, n = 2173, m = 16, quantization bit set to 4
---------- Embedding Table 19, quantization used, n = 4, m = 16, quantization bit set to 4
---------- Embedding Table 20, quantization used, n = 7046547, m = 16, quantization bit set to 4
---------- Embedding Table 21, quantization used, n = 18, m = 16, quantization bit set to 4
---------- Embedding Table 22, quantization used, n = 15, m = 16, quantization bit set to 4
---------- Embedding Table 23, quantization used, n = 286181, m = 16, quantization bit set to 4
---------- Embedding Table 24, quantization used, n = 105, m = 16, quantization bit set to 4
---------- Embedding Table 25, quantization used, n = 142572, m = 16, quantization bit set to 4
use quant linear, input 13, output 512, quantization bit width 4, use full precision quantized and channelwise status channelwise
use quant linear, input 512, output 256, quantization bit width 4, use full precision quantized and channelwise status channelwise
use quant linear, input 256, output 64, quantization bit width 4, use full precision quantized and channelwise status channelwise
use quant linear, input 64, output 16, quantization bit width 4, use full precision quantized and channelwise status channelwise
use quant linear, input 367, output 512, quantization bit width 4, use full precision quantized and channelwise status channelwise
use quant linear, input 512, output 256, quantization bit width 4, use full precision quantized and channelwise status channelwise
use quant linear, input 256, output 1, quantization bit width 4, use full precision quantized and channelwise status channelwise
not quantize activations, quantize weights
before training, checking models
tensor([ 0.0180,  0.0035,  0.0122,  0.0228, -0.0098, -0.0068,  0.0115, -0.0027,
        -0.0164, -0.0222, -0.0084, -0.0023,  0.0215,  0.0132,  0.0130,  0.0021])
log path is written: /home/yzhou/dlrm_criteo_kaggle/
optimizer selected is  sgd
Finished training it 1024/76743 of epoch 0, 139.62 ms/it, loss 0.550601
Unable to import mlperf_logging,  No module named 'mlperf_logging'
Warning: local_rank gpu mismatch
4 out of -1 (GPU)
---------- embedding bag gradient quantized in 8 bits
Reading pre-processed data=/home/yzhou/dlrm_criteo_kaggle/kaggleAdDisplayChallenge_processed.npz
Sparse fea = 26, Dense fea = 13
Defined train indices...
Randomized indices across days ...
Split data according to indices...
Reading pre-processed data=/home/yzhou/dlrm_criteo_kaggle/kaggleAdDisplayChallenge_processed.npz
Sparse fea = 26, Dense fea = 13
Defined test indices...
Randomized indices across days ...
Split data according to indices...
number of devices 1
world size found is -1
---------- Embedding Table 0, quantization used, n = 1460, m = 16, quantization bit set to 4
---------- Embedding Table 1, quantization used, n = 583, m = 16, quantization bit set to 4
---------- Embedding Table 2, quantization used, n = 10131227, m = 16, quantization bit set to 4
---------- Embedding Table 3, quantization used, n = 2202608, m = 16, quantization bit set to 4
---------- Embedding Table 4, quantization used, n = 305, m = 16, quantization bit set to 4
---------- Embedding Table 5, quantization used, n = 24, m = 16, quantization bit set to 4
---------- Embedding Table 6, quantization used, n = 12517, m = 16, quantization bit set to 4
---------- Embedding Table 7, quantization used, n = 633, m = 16, quantization bit set to 4
---------- Embedding Table 8, quantization used, n = 3, m = 16, quantization bit set to 4
---------- Embedding Table 9, quantization used, n = 93145, m = 16, quantization bit set to 4
---------- Embedding Table 10, quantization used, n = 5683, m = 16, quantization bit set to 4
---------- Embedding Table 11, quantization used, n = 8351593, m = 16, quantization bit set to 4
---------- Embedding Table 12, quantization used, n = 3194, m = 16, quantization bit set to 4
---------- Embedding Table 13, quantization used, n = 27, m = 16, quantization bit set to 4
---------- Embedding Table 14, quantization used, n = 14992, m = 16, quantization bit set to 4
---------- Embedding Table 15, quantization used, n = 5461306, m = 16, quantization bit set to 4
---------- Embedding Table 16, quantization used, n = 10, m = 16, quantization bit set to 4
---------- Embedding Table 17, quantization used, n = 5652, m = 16, quantization bit set to 4
---------- Embedding Table 18, quantization used, n = 2173, m = 16, quantization bit set to 4
---------- Embedding Table 19, quantization used, n = 4, m = 16, quantization bit set to 4
---------- Embedding Table 20, quantization used, n = 7046547, m = 16, quantization bit set to 4
---------- Embedding Table 21, quantization used, n = 18, m = 16, quantization bit set to 4
---------- Embedding Table 22, quantization used, n = 15, m = 16, quantization bit set to 4
---------- Embedding Table 23, quantization used, n = 286181, m = 16, quantization bit set to 4
---------- Embedding Table 24, quantization used, n = 105, m = 16, quantization bit set to 4
---------- Embedding Table 25, quantization used, n = 142572, m = 16, quantization bit set to 4
use quant linear, input 13, output 512, quantization bit width 4, use full precision quantized and channelwise status channelwise
use quant linear, input 512, output 256, quantization bit width 4, use full precision quantized and channelwise status channelwise
use quant linear, input 256, output 64, quantization bit width 4, use full precision quantized and channelwise status channelwise
use quant linear, input 64, output 16, quantization bit width 4, use full precision quantized and channelwise status channelwise
use quant linear, input 367, output 512, quantization bit width 4, use full precision quantized and channelwise status channelwise
use quant linear, input 512, output 256, quantization bit width 4, use full precision quantized and channelwise status channelwise
use quant linear, input 256, output 1, quantization bit width 4, use full precision quantized and channelwise status channelwise
not quantize activations, quantize weights
before training, checking models
tensor([-0.0078,  0.0072,  0.0018,  0.0187, -0.0143, -0.0192, -0.0255,  0.0098,
        -0.0216, -0.0237, -0.0206, -0.0073,  0.0052,  0.0219,  0.0060,  0.0209])
log path is written: /home/yzhou/dlrm_criteo_kaggle/
optimizer selected is  sgd
Finished training it 1024/76743 of epoch 0, 140.01 ms/it, loss 0.553555
Unable to import mlperf_logging,  No module named 'mlperf_logging'
Warning: local_rank gpu mismatch
4 out of -1 (GPU)
---------- embedding bag gradient quantized in 8 bits
Reading pre-processed data=/home/yzhou/dlrm_criteo_kaggle/kaggleAdDisplayChallenge_processed.npz
Sparse fea = 26, Dense fea = 13
Defined train indices...
Randomized indices across days ...
Split data according to indices...
Reading pre-processed data=/home/yzhou/dlrm_criteo_kaggle/kaggleAdDisplayChallenge_processed.npz
Sparse fea = 26, Dense fea = 13
Defined test indices...
Randomized indices across days ...
Split data according to indices...
number of devices 1
world size found is -1
---------- Embedding Table 0, quantization used, n = 1460, m = 16, quantization bit set to 4
---------- Embedding Table 1, quantization used, n = 583, m = 16, quantization bit set to 4
---------- Embedding Table 2, quantization used, n = 10131227, m = 16, quantization bit set to 4
---------- Embedding Table 3, quantization used, n = 2202608, m = 16, quantization bit set to 4
---------- Embedding Table 4, quantization used, n = 305, m = 16, quantization bit set to 4
---------- Embedding Table 5, quantization used, n = 24, m = 16, quantization bit set to 4
---------- Embedding Table 6, quantization used, n = 12517, m = 16, quantization bit set to 4
---------- Embedding Table 7, quantization used, n = 633, m = 16, quantization bit set to 4
---------- Embedding Table 8, quantization used, n = 3, m = 16, quantization bit set to 4
---------- Embedding Table 9, quantization used, n = 93145, m = 16, quantization bit set to 4
---------- Embedding Table 10, quantization used, n = 5683, m = 16, quantization bit set to 4
---------- Embedding Table 11, quantization used, n = 8351593, m = 16, quantization bit set to 4
---------- Embedding Table 12, quantization used, n = 3194, m = 16, quantization bit set to 4
---------- Embedding Table 13, quantization used, n = 27, m = 16, quantization bit set to 4
---------- Embedding Table 14, quantization used, n = 14992, m = 16, quantization bit set to 4
---------- Embedding Table 15, quantization used, n = 5461306, m = 16, quantization bit set to 4
---------- Embedding Table 16, quantization used, n = 10, m = 16, quantization bit set to 4
---------- Embedding Table 17, quantization used, n = 5652, m = 16, quantization bit set to 4
---------- Embedding Table 18, quantization used, n = 2173, m = 16, quantization bit set to 4
---------- Embedding Table 19, quantization used, n = 4, m = 16, quantization bit set to 4
---------- Embedding Table 20, quantization used, n = 7046547, m = 16, quantization bit set to 4
---------- Embedding Table 21, quantization used, n = 18, m = 16, quantization bit set to 4
---------- Embedding Table 22, quantization used, n = 15, m = 16, quantization bit set to 4
---------- Embedding Table 23, quantization used, n = 286181, m = 16, quantization bit set to 4
---------- Embedding Table 24, quantization used, n = 105, m = 16, quantization bit set to 4
---------- Embedding Table 25, quantization used, n = 142572, m = 16, quantization bit set to 4
use quant linear, input 13, output 512, quantization bit width 4, use full precision quantized and channelwise status channelwise
use quant linear, input 512, output 256, quantization bit width 4, use full precision quantized and channelwise status channelwise
use quant linear, input 256, output 64, quantization bit width 4, use full precision quantized and channelwise status channelwise
use quant linear, input 64, output 16, quantization bit width 4, use full precision quantized and channelwise status channelwise
use quant linear, input 367, output 512, quantization bit width 4, use full precision quantized and channelwise status channelwise
use quant linear, input 512, output 256, quantization bit width 4, use full precision quantized and channelwise status channelwise
use quant linear, input 256, output 1, quantization bit width 4, use full precision quantized and channelwise status channelwise
not quantize activations, quantize weights
before training, checking models
tensor([ 0.0213, -0.0191, -0.0021, -0.0175,  0.0102,  0.0103,  0.0071, -0.0210,
        -0.0249, -0.0022,  0.0034,  0.0220,  0.0179, -0.0169, -0.0070, -0.0105])
log path is written: /home/yzhou/dlrm_criteo_kaggle/
optimizer selected is  sgd
Finished training it 1024/76743 of epoch 0, 139.44 ms/it, loss 0.550826
Unable to import mlperf_logging,  No module named 'mlperf_logging'
Warning: local_rank gpu mismatch
4 out of -1 (GPU)
---------- embedding bag gradient quantized in 8 bits
Reading pre-processed data=/home/yzhou/dlrm_criteo_kaggle/kaggleAdDisplayChallenge_processed.npz
Sparse fea = 26, Dense fea = 13
Defined train indices...
Randomized indices across days ...
Split data according to indices...
Reading pre-processed data=/home/yzhou/dlrm_criteo_kaggle/kaggleAdDisplayChallenge_processed.npz
Sparse fea = 26, Dense fea = 13
Defined test indices...
Randomized indices across days ...
Split data according to indices...
number of devices 1
world size found is -1
---------- Embedding Table 0, quantization used, n = 1460, m = 16, quantization bit set to 4
---------- Embedding Table 1, quantization used, n = 583, m = 16, quantization bit set to 4
---------- Embedding Table 2, quantization used, n = 10131227, m = 16, quantization bit set to 4
---------- Embedding Table 3, quantization used, n = 2202608, m = 16, quantization bit set to 4
---------- Embedding Table 4, quantization used, n = 305, m = 16, quantization bit set to 4
---------- Embedding Table 5, quantization used, n = 24, m = 16, quantization bit set to 4
---------- Embedding Table 6, quantization used, n = 12517, m = 16, quantization bit set to 4
---------- Embedding Table 7, quantization used, n = 633, m = 16, quantization bit set to 4
---------- Embedding Table 8, quantization used, n = 3, m = 16, quantization bit set to 4
---------- Embedding Table 9, quantization used, n = 93145, m = 16, quantization bit set to 4
---------- Embedding Table 10, quantization used, n = 5683, m = 16, quantization bit set to 4
---------- Embedding Table 11, quantization used, n = 8351593, m = 16, quantization bit set to 4
---------- Embedding Table 12, quantization used, n = 3194, m = 16, quantization bit set to 4
---------- Embedding Table 13, quantization used, n = 27, m = 16, quantization bit set to 4
---------- Embedding Table 14, quantization used, n = 14992, m = 16, quantization bit set to 4
---------- Embedding Table 15, quantization used, n = 5461306, m = 16, quantization bit set to 4
---------- Embedding Table 16, quantization used, n = 10, m = 16, quantization bit set to 4
---------- Embedding Table 17, quantization used, n = 5652, m = 16, quantization bit set to 4
---------- Embedding Table 18, quantization used, n = 2173, m = 16, quantization bit set to 4
---------- Embedding Table 19, quantization used, n = 4, m = 16, quantization bit set to 4
---------- Embedding Table 20, quantization used, n = 7046547, m = 16, quantization bit set to 4
---------- Embedding Table 21, quantization used, n = 18, m = 16, quantization bit set to 4
---------- Embedding Table 22, quantization used, n = 15, m = 16, quantization bit set to 4
---------- Embedding Table 23, quantization used, n = 286181, m = 16, quantization bit set to 4
---------- Embedding Table 24, quantization used, n = 105, m = 16, quantization bit set to 4
---------- Embedding Table 25, quantization used, n = 142572, m = 16, quantization bit set to 4
use quant linear, input 13, output 512, quantization bit width 4, use full precision quantized and channelwise status channelwise
use quant linear, input 512, output 256, quantization bit width 4, use full precision quantized and channelwise status channelwise
use quant linear, input 256, output 64, quantization bit width 4, use full precision quantized and channelwise status channelwise
use quant linear, input 64, output 16, quantization bit width 4, use full precision quantized and channelwise status channelwise
use quant linear, input 367, output 512, quantization bit width 4, use full precision quantized and channelwise status channelwise
use quant linear, input 512, output 256, quantization bit width 4, use full precision quantized and channelwise status channelwise
use quant linear, input 256, output 1, quantization bit width 4, use full precision quantized and channelwise status channelwise
not quantize activations, quantize weights
before training, checking models
tensor([-0.0092,  0.0058,  0.0106, -0.0247,  0.0193,  0.0101, -0.0039,  0.0052,
         0.0196, -0.0010, -0.0099, -0.0152,  0.0099, -0.0216,  0.0136, -0.0029])
log path is written: /home/yzhou/dlrm_criteo_kaggle/
optimizer selected is  sgd
Finished training it 1024/76743 of epoch 0, 139.25 ms/it, loss 0.552885
Finished training it 2048/76743 of epoch 0, 138.95 ms/it, loss 0.511868
Finished training it 2048/76743 of epoch 0, 139.81 ms/it, loss 0.514343
Finished training it 2048/76743 of epoch 0, 139.87 ms/it, loss 0.515882
Finished training it 2048/76743 of epoch 0, 140.01 ms/it, loss 0.514261
Finished training it 3072/76743 of epoch 0, 142.47 ms/it, loss 0.508182
Finished training it 3072/76743 of epoch 0, 142.44 ms/it, loss 0.506002
Finished training it 3072/76743 of epoch 0, 141.86 ms/it, loss 0.507691
Finished training it 3072/76743 of epoch 0, 142.59 ms/it, loss 0.506828
Finished training it 4096/76743 of epoch 0, 141.10 ms/it, loss 0.502533
Finished training it 4096/76743 of epoch 0, 141.16 ms/it, loss 0.500238
Finished training it 4096/76743 of epoch 0, 141.09 ms/it, loss 0.502378
Finished training it 4096/76743 of epoch 0, 140.45 ms/it, loss 0.502297
Finished training it 5120/76743 of epoch 0, 140.86 ms/it, loss 0.497000
Finished training it 5120/76743 of epoch 0, 140.92 ms/it, loss 0.495426
Finished training it 5120/76743 of epoch 0, 140.79 ms/it, loss 0.498308
Finished training it 5120/76743 of epoch 0, 140.18 ms/it, loss 0.494754
Finished training it 6144/76743 of epoch 0, 140.50 ms/it, loss 0.489350
Finished training it 6144/76743 of epoch 0, 139.82 ms/it, loss 0.489538
Finished training it 6144/76743 of epoch 0, 140.44 ms/it, loss 0.487496
Finished training it 6144/76743 of epoch 0, 140.40 ms/it, loss 0.489315
Finished training it 7168/76743 of epoch 0, 139.74 ms/it, loss 0.485259
Finished training it 7168/76743 of epoch 0, 138.98 ms/it, loss 0.484732
Finished training it 7168/76743 of epoch 0, 139.74 ms/it, loss 0.482320
Finished training it 7168/76743 of epoch 0, 139.69 ms/it, loss 0.482714
Finished training it 8192/76743 of epoch 0, 138.96 ms/it, loss 0.479810
Finished training it 8192/76743 of epoch 0, 139.57 ms/it, loss 0.479325
Finished training it 8192/76743 of epoch 0, 139.61 ms/it, loss 0.479048
Finished training it 8192/76743 of epoch 0, 139.61 ms/it, loss 0.479550
Finished training it 9216/76743 of epoch 0, 138.93 ms/it, loss 0.475446
Finished training it 9216/76743 of epoch 0, 138.43 ms/it, loss 0.475466
Finished training it 9216/76743 of epoch 0, 138.98 ms/it, loss 0.475963
Finished training it 9216/76743 of epoch 0, 138.96 ms/it, loss 0.477437
Finished training it 10240/76743 of epoch 0, 138.02 ms/it, loss 0.475398
Finished training it 10240/76743 of epoch 0, 138.04 ms/it, loss 0.476130
Finished training it 10240/76743 of epoch 0, 137.53 ms/it, loss 0.474037
Finished training it 10240/76743 of epoch 0, 138.03 ms/it, loss 0.477528
Testing at - 10240/76743 of epoch 0,
steps testing: 0.0steps testing: 0.06253908692933083steps testing: 0.12507817385866166steps testing: 0.18761726078799248steps testing: 0.2501563477173233steps testing: 0.31269543464665417steps testing: 0.37523452157598497steps testing: 0.4377736085053158steps testing: 0.5003126954346466steps testing: 0.5628517823639775steps testing: 0.6253908692933083steps testing: 0.6879299562226392steps testing: 0.7504690431519699steps testing: 0.8130081300813008steps testing: 0.8755472170106317steps testing: 0.9380863039399625Warning: Skipping the batch 3197 with size 602
rank: 0 test_accu: 2539976.0
get out
0 has test check 2539976.0 and sample count 3273728
 accuracy 77.587 %, best 77.587 %, roc auc score 0.7740, best 0.7740
Testing at - 10240/76743 of epoch 0,
Warning: Skipping the batch 3197 with size 602
rank: 2 test_accu: 2539976.0
get out
2 has test check 2539976.0 and sample count 3273728
Finished training it 11264/76743 of epoch 0, 138.76 ms/it, loss 0.471419
Testing at - 10240/76743 of epoch 0,
Warning: Skipping the batch 3197 with size 602
rank: 3 test_accu: 2539976.0
get out
3 has test check 2539976.0 and sample count 3273728
Finished training it 11264/76743 of epoch 0, 139.03 ms/it, loss 0.471898
Saving model to /home/yzhou/dlrm_criteo_kaggle/save_model_after_training_one1.0.pt
Finished training it 11264/76743 of epoch 0, 138.82 ms/it, loss 0.470232
Testing at - 10240/76743 of epoch 0,
Warning: Skipping the batch 3197 with size 602
rank: 1 test_accu: 2539976.0
get out
1 has test check 2539976.0 and sample count 3273728
Finished training it 11264/76743 of epoch 0, 138.89 ms/it, loss 0.473744
Finished training it 12288/76743 of epoch 0, 139.82 ms/it, loss 0.470680
Finished training it 12288/76743 of epoch 0, 139.86 ms/it, loss 0.471758
Finished training it 12288/76743 of epoch 0, 139.81 ms/it, loss 0.470253
Finished training it 12288/76743 of epoch 0, 139.85 ms/it, loss 0.468576
Finished training it 13312/76743 of epoch 0, 138.88 ms/it, loss 0.472207
Finished training it 13312/76743 of epoch 0, 138.87 ms/it, loss 0.469008
Finished training it 13312/76743 of epoch 0, 138.79 ms/it, loss 0.468439
Finished training it 13312/76743 of epoch 0, 138.82 ms/it, loss 0.471501
Finished training it 14336/76743 of epoch 0, 139.31 ms/it, loss 0.469439
Finished training it 14336/76743 of epoch 0, 139.26 ms/it, loss 0.467221
Finished training it 14336/76743 of epoch 0, 139.20 ms/it, loss 0.468249
Finished training it 14336/76743 of epoch 0, 139.25 ms/it, loss 0.469082
Finished training it 15360/76743 of epoch 0, 140.22 ms/it, loss 0.468953
Finished training it 15360/76743 of epoch 0, 140.19 ms/it, loss 0.470259
Finished training it 15360/76743 of epoch 0, 140.27 ms/it, loss 0.467972
Finished training it 15360/76743 of epoch 0, 140.17 ms/it, loss 0.467524
Finished training it 16384/76743 of epoch 0, 139.22 ms/it, loss 0.464857
Finished training it 16384/76743 of epoch 0, 139.26 ms/it, loss 0.466993
Finished training it 16384/76743 of epoch 0, 139.22 ms/it, loss 0.463645
Finished training it 16384/76743 of epoch 0, 139.16 ms/it, loss 0.467111
Finished training it 17408/76743 of epoch 0, 139.54 ms/it, loss 0.465777
Finished training it 17408/76743 of epoch 0, 139.62 ms/it, loss 0.468108
Finished training it 17408/76743 of epoch 0, 139.57 ms/it, loss 0.466172
Finished training it 17408/76743 of epoch 0, 139.61 ms/it, loss 0.465366
Finished training it 18432/76743 of epoch 0, 139.28 ms/it, loss 0.466004
Finished training it 18432/76743 of epoch 0, 139.30 ms/it, loss 0.464566
Finished training it 18432/76743 of epoch 0, 139.37 ms/it, loss 0.465791
Finished training it 18432/76743 of epoch 0, 139.27 ms/it, loss 0.464158
Finished training it 19456/76743 of epoch 0, 139.17 ms/it, loss 0.464921
Finished training it 19456/76743 of epoch 0, 139.21 ms/it, loss 0.464511
Finished training it 19456/76743 of epoch 0, 139.21 ms/it, loss 0.461923
Finished training it 19456/76743 of epoch 0, 139.20 ms/it, loss 0.463981
Finished training it 20480/76743 of epoch 0, 139.54 ms/it, loss 0.466755
Finished training it 20480/76743 of epoch 0, 139.52 ms/it, loss 0.462479
Finished training it 20480/76743 of epoch 0, 139.62 ms/it, loss 0.463788
Finished training it 20480/76743 of epoch 0, 139.60 ms/it, loss 0.463160
Testing at - 20480/76743 of epoch 0,
steps testing: 0.0steps testing: 0.06253908692933083steps testing: 0.12507817385866166steps testing: 0.18761726078799248steps testing: 0.2501563477173233steps testing: 0.31269543464665417steps testing: 0.37523452157598497steps testing: 0.4377736085053158steps testing: 0.5003126954346466steps testing: 0.5628517823639775steps testing: 0.6253908692933083steps testing: 0.6879299562226392steps testing: 0.7504690431519699steps testing: 0.8130081300813008steps testing: 0.8755472170106317steps testing: 0.9380863039399625Warning: Skipping the batch 3197 with size 602
rank: 0 test_accu: 2550489.0
get out
0 has test check 2550489.0 and sample count 3273728
 accuracy 77.908 %, best 77.908 %, roc auc score 0.7831, best 0.7831
Testing at - 20480/76743 of epoch 0,
Warning: Skipping the batch 3197 with size 602
rank: 3 test_accu: 2550489.0
get out
3 has test check 2550489.0 and sample count 3273728
Finished training it 21504/76743 of epoch 0, 139.53 ms/it, loss 0.460783
Testing at - 20480/76743 of epoch 0,
Warning: Skipping the batch 3197 with size 602
rank: 2 test_accu: 2550489.0
get out
2 has test check 2550489.0 and sample count 3273728
Finished training it 21504/76743 of epoch 0, 139.44 ms/it, loss 0.468316
Saving model to /home/yzhou/dlrm_criteo_kaggle/save_model_after_training_one0.0.pt
Finished training it 21504/76743 of epoch 0, 139.30 ms/it, loss 0.464121
Testing at - 20480/76743 of epoch 0,
Warning: Skipping the batch 3197 with size 602
rank: 1 test_accu: 2550489.0
get out
1 has test check 2550489.0 and sample count 3273728
Finished training it 21504/76743 of epoch 0, 139.48 ms/it, loss 0.465926
Finished training it 22528/76743 of epoch 0, 139.43 ms/it, loss 0.464567
Finished training it 22528/76743 of epoch 0, 139.48 ms/it, loss 0.464634
Finished training it 22528/76743 of epoch 0, 139.42 ms/it, loss 0.465251
Finished training it 22528/76743 of epoch 0, 139.42 ms/it, loss 0.466242
Finished training it 23552/76743 of epoch 0, 139.70 ms/it, loss 0.462202
Finished training it 23552/76743 of epoch 0, 139.64 ms/it, loss 0.462001
Finished training it 23552/76743 of epoch 0, 139.65 ms/it, loss 0.465777
Finished training it 23552/76743 of epoch 0, 139.66 ms/it, loss 0.463068
Finished training it 24576/76743 of epoch 0, 139.39 ms/it, loss 0.466188
Finished training it 24576/76743 of epoch 0, 139.43 ms/it, loss 0.463110
Finished training it 24576/76743 of epoch 0, 139.45 ms/it, loss 0.462816
Finished training it 24576/76743 of epoch 0, 139.41 ms/it, loss 0.465045
Finished training it 25600/76743 of epoch 0, 139.49 ms/it, loss 0.461312
Finished training it 25600/76743 of epoch 0, 139.50 ms/it, loss 0.466988
Finished training it 25600/76743 of epoch 0, 139.57 ms/it, loss 0.461631
Finished training it 25600/76743 of epoch 0, 139.56 ms/it, loss 0.461094
Finished training it 26624/76743 of epoch 0, 138.86 ms/it, loss 0.462997
Finished training it 26624/76743 of epoch 0, 138.90 ms/it, loss 0.460252
Finished training it 26624/76743 of epoch 0, 138.87 ms/it, loss 0.461971
Finished training it 26624/76743 of epoch 0, 138.95 ms/it, loss 0.462853
Finished training it 27648/76743 of epoch 0, 139.41 ms/it, loss 0.463864
Finished training it 27648/76743 of epoch 0, 139.44 ms/it, loss 0.461819
Finished training it 27648/76743 of epoch 0, 139.50 ms/it, loss 0.464165
Finished training it 27648/76743 of epoch 0, 139.41 ms/it, loss 0.463317
Finished training it 28672/76743 of epoch 0, 139.08 ms/it, loss 0.461531
Finished training it 28672/76743 of epoch 0, 139.01 ms/it, loss 0.459881
Finished training it 28672/76743 of epoch 0, 138.97 ms/it, loss 0.463246
Finished training it 28672/76743 of epoch 0, 139.06 ms/it, loss 0.462177
Finished training it 29696/76743 of epoch 0, 139.57 ms/it, loss 0.461207
Finished training it 29696/76743 of epoch 0, 139.51 ms/it, loss 0.462359
Finished training it 29696/76743 of epoch 0, 139.49 ms/it, loss 0.465476
Finished training it 29696/76743 of epoch 0, 139.44 ms/it, loss 0.463154
Finished training it 30720/76743 of epoch 0, 138.72 ms/it, loss 0.462946
Finished training it 30720/76743 of epoch 0, 138.77 ms/it, loss 0.463547
Finished training it 30720/76743 of epoch 0, 138.71 ms/it, loss 0.462790
Finished training it 30720/76743 of epoch 0, 138.71 ms/it, loss 0.464910
Testing at - 30720/76743 of epoch 0,
steps testing: 0.0steps testing: 0.06253908692933083steps testing: 0.12507817385866166steps testing: 0.18761726078799248steps testing: 0.2501563477173233steps testing: 0.31269543464665417steps testing: 0.37523452157598497steps testing: 0.4377736085053158steps testing: 0.5003126954346466steps testing: 0.5628517823639775steps testing: 0.6253908692933083steps testing: 0.6879299562226392steps testing: 0.7504690431519699steps testing: 0.8130081300813008steps testing: 0.8755472170106317steps testing: 0.9380863039399625Warning: Skipping the batch 3197 with size 602
rank: 0 test_accu: 2556538.0
get out
0 has test check 2556538.0 and sample count 3273728
 accuracy 78.093 %, best 78.093 %, roc auc score 0.7857, best 0.7857
Testing at - 30720/76743 of epoch 0,
Warning: Skipping the batch 3197 with size 602
rank: 3 test_accu: 2556538.0
get out
3 has test check 2556538.0 and sample count 3273728
Finished training it 31744/76743 of epoch 0, 139.35 ms/it, loss 0.460691
Testing at - 30720/76743 of epoch 0,
Warning: Skipping the batch 3197 with size 602
rank: 2 test_accu: 2556538.0
get out
2 has test check 2556538.0 and sample count 3273728
Finished training it 31744/76743 of epoch 0, 139.41 ms/it, loss 0.464188
Saving model to /home/yzhou/dlrm_criteo_kaggle/save_model_after_training_one1.0.pt
Finished training it 31744/76743 of epoch 0, 139.28 ms/it, loss 0.462362
Testing at - 30720/76743 of epoch 0,
Warning: Skipping the batch 3197 with size 602
rank: 1 test_accu: 2556538.0
get out
1 has test check 2556538.0 and sample count 3273728
Finished training it 31744/76743 of epoch 0, 139.40 ms/it, loss 0.461340
Finished training it 32768/76743 of epoch 0, 138.66 ms/it, loss 0.462464
Finished training it 32768/76743 of epoch 0, 138.65 ms/it, loss 0.460022
Finished training it 32768/76743 of epoch 0, 138.66 ms/it, loss 0.462352
Finished training it 32768/76743 of epoch 0, 138.63 ms/it, loss 0.461405
Finished training it 33792/76743 of epoch 0, 138.26 ms/it, loss 0.458748
Finished training it 33792/76743 of epoch 0, 138.31 ms/it, loss 0.457742
Finished training it 33792/76743 of epoch 0, 138.15 ms/it, loss 0.462861
Finished training it 33792/76743 of epoch 0, 138.25 ms/it, loss 0.461588
Finished training it 34816/76743 of epoch 0, 138.44 ms/it, loss 0.462374
Finished training it 34816/76743 of epoch 0, 138.52 ms/it, loss 0.462471
Finished training it 34816/76743 of epoch 0, 138.41 ms/it, loss 0.462202
Finished training it 34816/76743 of epoch 0, 138.46 ms/it, loss 0.461629
Finished training it 35840/76743 of epoch 0, 138.70 ms/it, loss 0.462882
Finished training it 35840/76743 of epoch 0, 138.66 ms/it, loss 0.461865
Finished training it 35840/76743 of epoch 0, 138.80 ms/it, loss 0.461037
Finished training it 35840/76743 of epoch 0, 138.75 ms/it, loss 0.461224
Finished training it 36864/76743 of epoch 0, 138.65 ms/it, loss 0.457212
Finished training it 36864/76743 of epoch 0, 138.74 ms/it, loss 0.460333
Finished training it 36864/76743 of epoch 0, 138.62 ms/it, loss 0.460001
Finished training it 36864/76743 of epoch 0, 138.68 ms/it, loss 0.458011
Finished training it 37888/76743 of epoch 0, 138.17 ms/it, loss 0.460231
Finished training it 37888/76743 of epoch 0, 138.12 ms/it, loss 0.457311
Finished training it 37888/76743 of epoch 0, 138.11 ms/it, loss 0.462066
Finished training it 37888/76743 of epoch 0, 138.14 ms/it, loss 0.462197
Finished training it 38912/76743 of epoch 0, 138.54 ms/it, loss 0.460419
Finished training it 38912/76743 of epoch 0, 138.48 ms/it, loss 0.458740
Finished training it 38912/76743 of epoch 0, 138.47 ms/it, loss 0.461154
Finished training it 38912/76743 of epoch 0, 138.53 ms/it, loss 0.459892
Finished training it 39936/76743 of epoch 0, 139.04 ms/it, loss 0.461057
Finished training it 39936/76743 of epoch 0, 139.06 ms/it, loss 0.459430
Finished training it 39936/76743 of epoch 0, 139.09 ms/it, loss 0.460929
Finished training it 39936/76743 of epoch 0, 139.04 ms/it, loss 0.460011
Finished training it 40960/76743 of epoch 0, 139.20 ms/it, loss 0.460428
Finished training it 40960/76743 of epoch 0, 139.12 ms/it, loss 0.460971
Finished training it 40960/76743 of epoch 0, 139.23 ms/it, loss 0.459400
Finished training it 40960/76743 of epoch 0, 139.24 ms/it, loss 0.459011
Testing at - 40960/76743 of epoch 0,
steps testing: 0.0steps testing: 0.06253908692933083steps testing: 0.12507817385866166steps testing: 0.18761726078799248steps testing: 0.2501563477173233steps testing: 0.31269543464665417steps testing: 0.37523452157598497steps testing: 0.4377736085053158steps testing: 0.5003126954346466steps testing: 0.5628517823639775steps testing: 0.6253908692933083steps testing: 0.6879299562226392steps testing: 0.7504690431519699steps testing: 0.8130081300813008steps testing: 0.8755472170106317steps testing: 0.9380863039399625Warning: Skipping the batch 3197 with size 602
rank: 0 test_accu: 2550806.0
get out
0 has test check 2550806.0 and sample count 3273728
 accuracy 77.917 %, best 78.093 %, roc auc score 0.7877, best 0.7877
Testing at - 40960/76743 of epoch 0,
Warning: Skipping the batch 3197 with size 602
rank: 1 test_accu: 2550806.0
get out
1 has test check 2550806.0 and sample count 3273728
Finished training it 41984/76743 of epoch 0, 139.36 ms/it, loss 0.458637
Saving model to /home/yzhou/dlrm_criteo_kaggle/save_model_after_training_one0.0.pt
Finished training it 41984/76743 of epoch 0, 139.28 ms/it, loss 0.461099
Testing at - 40960/76743 of epoch 0,
Warning: Skipping the batch 3197 with size 602
rank: 2 test_accu: 2550806.0
get out
2 has test check 2550806.0 and sample count 3273728
Finished training it 41984/76743 of epoch 0, 139.28 ms/it, loss 0.459790
Testing at - 40960/76743 of epoch 0,
Warning: Skipping the batch 3197 with size 602
rank: 3 test_accu: 2550806.0
get out
3 has test check 2550806.0 and sample count 3273728
Finished training it 41984/76743 of epoch 0, 139.36 ms/it, loss 0.460561
Finished training it 43008/76743 of epoch 0, 139.54 ms/it, loss 0.458612
Finished training it 43008/76743 of epoch 0, 139.52 ms/it, loss 0.460950
Finished training it 43008/76743 of epoch 0, 139.45 ms/it, loss 0.460273
Finished training it 43008/76743 of epoch 0, 139.51 ms/it, loss 0.457235
Finished training it 44032/76743 of epoch 0, 138.88 ms/it, loss 0.458332
Finished training it 44032/76743 of epoch 0, 138.95 ms/it, loss 0.458138
Finished training it 44032/76743 of epoch 0, 138.91 ms/it, loss 0.460714
Finished training it 44032/76743 of epoch 0, 138.85 ms/it, loss 0.459929
Finished training it 45056/76743 of epoch 0, 138.96 ms/it, loss 0.460664
Finished training it 45056/76743 of epoch 0, 139.02 ms/it, loss 0.457368
Finished training it 45056/76743 of epoch 0, 139.02 ms/it, loss 0.458087
Finished training it 45056/76743 of epoch 0, 138.97 ms/it, loss 0.461667
Finished training it 46080/76743 of epoch 0, 138.65 ms/it, loss 0.455181
Finished training it 46080/76743 of epoch 0, 138.73 ms/it, loss 0.460172
Finished training it 46080/76743 of epoch 0, 138.69 ms/it, loss 0.456959
Finished training it 46080/76743 of epoch 0, 138.64 ms/it, loss 0.458088
Finished training it 47104/76743 of epoch 0, 139.31 ms/it, loss 0.460056
Finished training it 47104/76743 of epoch 0, 139.29 ms/it, loss 0.456868
Finished training it 47104/76743 of epoch 0, 139.31 ms/it, loss 0.460186
Finished training it 47104/76743 of epoch 0, 139.30 ms/it, loss 0.458117
Finished training it 48128/76743 of epoch 0, 139.36 ms/it, loss 0.458371
Finished training it 48128/76743 of epoch 0, 139.29 ms/it, loss 0.460165
Finished training it 48128/76743 of epoch 0, 139.38 ms/it, loss 0.458488
Finished training it 48128/76743 of epoch 0, 139.33 ms/it, loss 0.456678
Finished training it 49152/76743 of epoch 0, 139.21 ms/it, loss 0.457895
Finished training it 49152/76743 of epoch 0, 139.35 ms/it, loss 0.459399
Finished training it 49152/76743 of epoch 0, 139.27 ms/it, loss 0.458808
Finished training it 49152/76743 of epoch 0, 139.33 ms/it, loss 0.457027
Finished training it 50176/76743 of epoch 0, 138.62 ms/it, loss 0.459210
Finished training it 50176/76743 of epoch 0, 138.61 ms/it, loss 0.460140
Finished training it 50176/76743 of epoch 0, 138.63 ms/it, loss 0.458969
Finished training it 50176/76743 of epoch 0, 138.64 ms/it, loss 0.459275
Finished training it 51200/76743 of epoch 0, 139.17 ms/it, loss 0.456859
Finished training it 51200/76743 of epoch 0, 139.09 ms/it, loss 0.458277
Finished training it 51200/76743 of epoch 0, 139.16 ms/it, loss 0.458669
Finished training it 51200/76743 of epoch 0, 139.11 ms/it, loss 0.459652
Testing at - 51200/76743 of epoch 0,
steps testing: 0.0steps testing: 0.06253908692933083steps testing: 0.12507817385866166steps testing: 0.18761726078799248steps testing: 0.2501563477173233steps testing: 0.31269543464665417steps testing: 0.37523452157598497steps testing: 0.4377736085053158steps testing: 0.5003126954346466steps testing: 0.5628517823639775steps testing: 0.6253908692933083steps testing: 0.6879299562226392steps testing: 0.7504690431519699steps testing: 0.8130081300813008steps testing: 0.8755472170106317steps testing: 0.9380863039399625Warning: Skipping the batch 3197 with size 602
rank: 0 test_accu: 2561512.0
get out
0 has test check 2561512.0 and sample count 3273728
 accuracy 78.244 %, best 78.244 %, roc auc score 0.7894, best 0.7894
Testing at - 51200/76743 of epoch 0,
Warning: Skipping the batch 3197 with size 602
rank: 2 test_accu: 2561512.0
get out
2 has test check 2561512.0 and sample count 3273728
Finished training it 52224/76743 of epoch 0, 139.34 ms/it, loss 0.458040
Saving model to /home/yzhou/dlrm_criteo_kaggle/save_model_after_training_one1.0.pt
Finished training it 52224/76743 of epoch 0, 139.33 ms/it, loss 0.459717
Testing at - 51200/76743 of epoch 0,
Warning: Skipping the batch 3197 with size 602
rank: 3 test_accu: 2561512.0
get out
3 has test check 2561512.0 and sample count 3273728
Finished training it 52224/76743 of epoch 0, 139.36 ms/it, loss 0.458009
Testing at - 51200/76743 of epoch 0,
Warning: Skipping the batch 3197 with size 602
rank: 1 test_accu: 2561512.0
get out
1 has test check 2561512.0 and sample count 3273728
Finished training it 52224/76743 of epoch 0, 139.41 ms/it, loss 0.459347
Finished training it 53248/76743 of epoch 0, 139.70 ms/it, loss 0.454994
Finished training it 53248/76743 of epoch 0, 139.72 ms/it, loss 0.461238
Finished training it 53248/76743 of epoch 0, 139.70 ms/it, loss 0.457598
Finished training it 53248/76743 of epoch 0, 139.62 ms/it, loss 0.458252
Finished training it 54272/76743 of epoch 0, 138.75 ms/it, loss 0.456933
Finished training it 54272/76743 of epoch 0, 138.77 ms/it, loss 0.459291
Finished training it 54272/76743 of epoch 0, 138.71 ms/it, loss 0.458196
Finished training it 54272/76743 of epoch 0, 138.79 ms/it, loss 0.456011
Finished training it 55296/76743 of epoch 0, 139.52 ms/it, loss 0.459514
Finished training it 55296/76743 of epoch 0, 139.49 ms/it, loss 0.458242
Finished training it 55296/76743 of epoch 0, 139.55 ms/it, loss 0.459046
Finished training it 55296/76743 of epoch 0, 139.54 ms/it, loss 0.458661
Finished training it 56320/76743 of epoch 0, 139.62 ms/it, loss 0.455891
Finished training it 56320/76743 of epoch 0, 139.46 ms/it, loss 0.457644
Finished training it 56320/76743 of epoch 0, 139.61 ms/it, loss 0.458341
Finished training it 56320/76743 of epoch 0, 139.59 ms/it, loss 0.458710
Finished training it 57344/76743 of epoch 0, 139.24 ms/it, loss 0.456167
Finished training it 57344/76743 of epoch 0, 139.19 ms/it, loss 0.458540
Finished training it 57344/76743 of epoch 0, 139.20 ms/it, loss 0.459639
Finished training it 57344/76743 of epoch 0, 139.23 ms/it, loss 0.459660
Finished training it 58368/76743 of epoch 0, 138.89 ms/it, loss 0.460887
Finished training it 58368/76743 of epoch 0, 138.89 ms/it, loss 0.458136
Finished training it 58368/76743 of epoch 0, 138.85 ms/it, loss 0.458154
Finished training it 58368/76743 of epoch 0, 138.85 ms/it, loss 0.459333
Finished training it 59392/76743 of epoch 0, 139.08 ms/it, loss 0.454678
Finished training it 59392/76743 of epoch 0, 139.08 ms/it, loss 0.455597
Finished training it 59392/76743 of epoch 0, 139.07 ms/it, loss 0.455098
Finished training it 59392/76743 of epoch 0, 139.03 ms/it, loss 0.457277
Finished training it 60416/76743 of epoch 0, 139.77 ms/it, loss 0.457611
Finished training it 60416/76743 of epoch 0, 139.75 ms/it, loss 0.459887
Finished training it 60416/76743 of epoch 0, 139.73 ms/it, loss 0.457011
Finished training it 60416/76743 of epoch 0, 139.77 ms/it, loss 0.457328
Finished training it 61440/76743 of epoch 0, 138.55 ms/it, loss 0.455971
Finished training it 61440/76743 of epoch 0, 138.61 ms/it, loss 0.455160
Finished training it 61440/76743 of epoch 0, 138.66 ms/it, loss 0.459400
Finished training it 61440/76743 of epoch 0, 138.59 ms/it, loss 0.456619
Testing at - 61440/76743 of epoch 0,
steps testing: 0.0steps testing: 0.06253908692933083steps testing: 0.12507817385866166steps testing: 0.18761726078799248steps testing: 0.2501563477173233steps testing: 0.31269543464665417steps testing: 0.37523452157598497steps testing: 0.4377736085053158steps testing: 0.5003126954346466steps testing: 0.5628517823639775steps testing: 0.6253908692933083steps testing: 0.6879299562226392steps testing: 0.7504690431519699steps testing: 0.8130081300813008steps testing: 0.8755472170106317steps testing: 0.9380863039399625Warning: Skipping the batch 3197 with size 602
rank: 0 test_accu: 2564527.0
get out
0 has test check 2564527.0 and sample count 3273728
 accuracy 78.337 %, best 78.337 %, roc auc score 0.7910, best 0.7910
Testing at - 61440/76743 of epoch 0,
Warning: Skipping the batch 3197 with size 602
rank: 2 test_accu: 2564527.0
get out
2 has test check 2564527.0 and sample count 3273728
Finished training it 62464/76743 of epoch 0, 138.87 ms/it, loss 0.456633
Saving model to /home/yzhou/dlrm_criteo_kaggle/save_model_after_training_one0.0.pt
Finished training it 62464/76743 of epoch 0, 138.91 ms/it, loss 0.453752
Testing at - 61440/76743 of epoch 0,
Warning: Skipping the batch 3197 with size 602
rank: 3 test_accu: 2564527.0
get out
3 has test check 2564527.0 and sample count 3273728
Finished training it 62464/76743 of epoch 0, 138.90 ms/it, loss 0.458021
Testing at - 61440/76743 of epoch 0,
Warning: Skipping the batch 3197 with size 602
rank: 1 test_accu: 2564527.0
get out
1 has test check 2564527.0 and sample count 3273728
Finished training it 62464/76743 of epoch 0, 138.84 ms/it, loss 0.456109
Finished training it 63488/76743 of epoch 0, 138.78 ms/it, loss 0.457601
Finished training it 63488/76743 of epoch 0, 138.73 ms/it, loss 0.457023
Finished training it 63488/76743 of epoch 0, 138.78 ms/it, loss 0.456421
Finished training it 63488/76743 of epoch 0, 138.74 ms/it, loss 0.456282
Finished training it 64512/76743 of epoch 0, 140.21 ms/it, loss 0.457293
Finished training it 64512/76743 of epoch 0, 140.10 ms/it, loss 0.454818
Finished training it 64512/76743 of epoch 0, 140.16 ms/it, loss 0.458811
Finished training it 64512/76743 of epoch 0, 140.19 ms/it, loss 0.455778
Finished training it 65536/76743 of epoch 0, 139.95 ms/it, loss 0.459423
Finished training it 65536/76743 of epoch 0, 139.88 ms/it, loss 0.457067
Finished training it 65536/76743 of epoch 0, 139.87 ms/it, loss 0.456005
Finished training it 65536/76743 of epoch 0, 139.93 ms/it, loss 0.458507
Finished training it 66560/76743 of epoch 0, 138.57 ms/it, loss 0.459266
Finished training it 66560/76743 of epoch 0, 138.60 ms/it, loss 0.455436
Finished training it 66560/76743 of epoch 0, 138.57 ms/it, loss 0.455401
Finished training it 66560/76743 of epoch 0, 138.55 ms/it, loss 0.458487
Finished training it 67584/76743 of epoch 0, 139.67 ms/it, loss 0.457069
Finished training it 67584/76743 of epoch 0, 139.61 ms/it, loss 0.454519
Finished training it 67584/76743 of epoch 0, 139.63 ms/it, loss 0.457290
Finished training it 67584/76743 of epoch 0, 139.68 ms/it, loss 0.461428
Finished training it 68608/76743 of epoch 0, 139.83 ms/it, loss 0.457832
Finished training it 68608/76743 of epoch 0, 139.86 ms/it, loss 0.455166
Finished training it 68608/76743 of epoch 0, 139.82 ms/it, loss 0.456880
Finished training it 68608/76743 of epoch 0, 139.84 ms/it, loss 0.457322
Finished training it 69632/76743 of epoch 0, 139.22 ms/it, loss 0.458098
Finished training it 69632/76743 of epoch 0, 139.30 ms/it, loss 0.458068
Finished training it 69632/76743 of epoch 0, 139.21 ms/it, loss 0.456016
Finished training it 69632/76743 of epoch 0, 139.28 ms/it, loss 0.460358
Finished training it 70656/76743 of epoch 0, 138.64 ms/it, loss 0.458873
Finished training it 70656/76743 of epoch 0, 138.72 ms/it, loss 0.454834
Finished training it 70656/76743 of epoch 0, 138.67 ms/it, loss 0.455014
Finished training it 70656/76743 of epoch 0, 138.68 ms/it, loss 0.456095
Finished training it 71680/76743 of epoch 0, 138.57 ms/it, loss 0.457711
Finished training it 71680/76743 of epoch 0, 138.67 ms/it, loss 0.455736
Finished training it 71680/76743 of epoch 0, 138.63 ms/it, loss 0.457223
Finished training it 71680/76743 of epoch 0, 138.68 ms/it, loss 0.457476
Testing at - 71680/76743 of epoch 0,
steps testing: 0.0steps testing: 0.06253908692933083steps testing: 0.12507817385866166steps testing: 0.18761726078799248steps testing: 0.2501563477173233steps testing: 0.31269543464665417steps testing: 0.37523452157598497steps testing: 0.4377736085053158steps testing: 0.5003126954346466steps testing: 0.5628517823639775steps testing: 0.6253908692933083steps testing: 0.6879299562226392steps testing: 0.7504690431519699steps testing: 0.8130081300813008steps testing: 0.8755472170106317steps testing: 0.9380863039399625Warning: Skipping the batch 3197 with size 602
rank: 0 test_accu: 2564438.0
get out
0 has test check 2564438.0 and sample count 3273728
 accuracy 78.334 %, best 78.337 %, roc auc score 0.7912, best 0.7912
Saving model to /home/yzhou/dlrm_criteo_kaggle/save_model_after_training_one1.0.pt
Finished training it 72704/76743 of epoch 0, 138.68 ms/it, loss 0.457929
Testing at - 71680/76743 of epoch 0,
Warning: Skipping the batch 3197 with size 602
rank: 1 test_accu: 2564438.0
get out
1 has test check 2564438.0 and sample count 3273728
Finished training it 72704/76743 of epoch 0, 138.74 ms/it, loss 0.458393
Testing at - 71680/76743 of epoch 0,
Warning: Skipping the batch 3197 with size 602
rank: 3 test_accu: 2564438.0
get out
3 has test check 2564438.0 and sample count 3273728
Finished training it 72704/76743 of epoch 0, 138.70 ms/it, loss 0.455575
Testing at - 71680/76743 of epoch 0,
Warning: Skipping the batch 3197 with size 602
rank: 2 test_accu: 2564438.0
get out
2 has test check 2564438.0 and sample count 3273728
Finished training it 72704/76743 of epoch 0, 138.69 ms/it, loss 0.454915
Finished training it 73728/76743 of epoch 0, 138.01 ms/it, loss 0.454775
Finished training it 73728/76743 of epoch 0, 138.08 ms/it, loss 0.455208
Finished training it 73728/76743 of epoch 0, 138.12 ms/it, loss 0.456901
Finished training it 73728/76743 of epoch 0, 138.08 ms/it, loss 0.456836
Finished training it 74752/76743 of epoch 0, 139.79 ms/it, loss 0.455348
Finished training it 74752/76743 of epoch 0, 139.86 ms/it, loss 0.456463
Finished training it 74752/76743 of epoch 0, 139.86 ms/it, loss 0.456205
Finished training it 74752/76743 of epoch 0, 139.81 ms/it, loss 0.457247
Finished training it 75776/76743 of epoch 0, 139.04 ms/it, loss 0.457578
Finished training it 75776/76743 of epoch 0, 139.08 ms/it, loss 0.455223
Finished training it 75776/76743 of epoch 0, 138.97 ms/it, loss 0.453731
Finished training it 75776/76743 of epoch 0, 139.02 ms/it, loss 0.457538
Warning: Skipping the batch 76742 with size 14
Finished training it 1024/76743 of epoch 1, 140.66 ms/it, loss 0.454663
Warning: Skipping the batch 76742 with size 14
Finished training it 1024/76743 of epoch 1, 141.19 ms/it, loss 0.457368
Warning: Skipping the batch 76742 with size 14
Finished training it 1024/76743 of epoch 1, 140.73 ms/it, loss 0.454620
Warning: Skipping the batch 76742 with size 14
Finished training it 1024/76743 of epoch 1, 140.84 ms/it, loss 0.457857
Finished training it 2048/76743 of epoch 1, 139.31 ms/it, loss 0.455883
Finished training it 2048/76743 of epoch 1, 139.32 ms/it, loss 0.456931
Finished training it 2048/76743 of epoch 1, 139.35 ms/it, loss 0.456264
Finished training it 2048/76743 of epoch 1, 139.31 ms/it, loss 0.453199
Finished training it 3072/76743 of epoch 1, 139.29 ms/it, loss 0.455500
Finished training it 3072/76743 of epoch 1, 139.21 ms/it, loss 0.457123
Finished training it 3072/76743 of epoch 1, 139.17 ms/it, loss 0.455749
Finished training it 3072/76743 of epoch 1, 139.20 ms/it, loss 0.457507
Finished training it 4096/76743 of epoch 1, 140.63 ms/it, loss 0.455289
Finished training it 4096/76743 of epoch 1, 140.56 ms/it, loss 0.458081
Finished training it 4096/76743 of epoch 1, 140.62 ms/it, loss 0.457330
Finished training it 4096/76743 of epoch 1, 140.60 ms/it, loss 0.457424
Finished training it 5120/76743 of epoch 1, 138.85 ms/it, loss 0.454998
Finished training it 5120/76743 of epoch 1, 138.78 ms/it, loss 0.458008
Finished training it 5120/76743 of epoch 1, 138.83 ms/it, loss 0.458622
Finished training it 5120/76743 of epoch 1, 138.81 ms/it, loss 0.455748
Finished training it 6144/76743 of epoch 1, 138.46 ms/it, loss 0.456455
Finished training it 6144/76743 of epoch 1, 138.45 ms/it, loss 0.456187
Finished training it 6144/76743 of epoch 1, 138.45 ms/it, loss 0.455732
Finished training it 6144/76743 of epoch 1, 138.41 ms/it, loss 0.453910
Finished training it 7168/76743 of epoch 1, 138.95 ms/it, loss 0.454210
Finished training it 7168/76743 of epoch 1, 138.97 ms/it, loss 0.456069
Finished training it 7168/76743 of epoch 1, 138.94 ms/it, loss 0.456431
Finished training it 7168/76743 of epoch 1, 138.96 ms/it, loss 0.452787
Finished training it 8192/76743 of epoch 1, 138.97 ms/it, loss 0.455871
Finished training it 8192/76743 of epoch 1, 138.98 ms/it, loss 0.455248
Finished training it 8192/76743 of epoch 1, 138.94 ms/it, loss 0.455524
Finished training it 8192/76743 of epoch 1, 139.04 ms/it, loss 0.456225
Finished training it 9216/76743 of epoch 1, 139.25 ms/it, loss 0.455296
Finished training it 9216/76743 of epoch 1, 139.20 ms/it, loss 0.454476
Finished training it 9216/76743 of epoch 1, 139.15 ms/it, loss 0.454809
Finished training it 9216/76743 of epoch 1, 139.23 ms/it, loss 0.456009
Finished training it 10240/76743 of epoch 1, 139.09 ms/it, loss 0.459030
Finished training it 10240/76743 of epoch 1, 139.08 ms/it, loss 0.455589
Finished training it 10240/76743 of epoch 1, 138.99 ms/it, loss 0.457444
Finished training it 10240/76743 of epoch 1, 139.10 ms/it, loss 0.457005
Testing at - 10240/76743 of epoch 1,
steps testing: 0.0steps testing: 0.06253908692933083steps testing: 0.12507817385866166steps testing: 0.18761726078799248steps testing: 0.2501563477173233steps testing: 0.31269543464665417steps testing: 0.37523452157598497steps testing: 0.4377736085053158steps testing: 0.5003126954346466steps testing: 0.5628517823639775steps testing: 0.6253908692933083steps testing: 0.6879299562226392steps testing: 0.7504690431519699steps testing: 0.8130081300813008steps testing: 0.8755472170106317steps testing: 0.9380863039399625Warning: Skipping the batch 3197 with size 602
rank: 0 test_accu: 2568067.0
get out
0 has test check 2568067.0 and sample count 3273728
 accuracy 78.445 %, best 78.445 %, roc auc score 0.7926, best 0.7926
Saving model to /home/yzhou/dlrm_criteo_kaggle/save_model_after_training_one1.0.pt
Finished training it 11264/76743 of epoch 1, 142.85 ms/it, loss 0.452313
Testing at - 10240/76743 of epoch 1,
Warning: Skipping the batch 3197 with size 602
rank: 1 test_accu: 2568067.0
get out
1 has test check 2568067.0 and sample count 3273728
Finished training it 11264/76743 of epoch 1, 142.71 ms/it, loss 0.456558
Testing at - 10240/76743 of epoch 1,
Warning: Skipping the batch 3197 with size 602
rank: 2 test_accu: 2568067.0
get out
2 has test check 2568067.0 and sample count 3273728
Finished training it 11264/76743 of epoch 1, 142.77 ms/it, loss 0.454225
Testing at - 10240/76743 of epoch 1,
Warning: Skipping the batch 3197 with size 602
rank: 3 test_accu: 2568067.0
get out
3 has test check 2568067.0 and sample count 3273728
Finished training it 11264/76743 of epoch 1, 142.76 ms/it, loss 0.453361
Finished training it 12288/76743 of epoch 1, 139.50 ms/it, loss 0.454430
Finished training it 12288/76743 of epoch 1, 139.56 ms/it, loss 0.453031
Finished training it 12288/76743 of epoch 1, 139.45 ms/it, loss 0.456059
Finished training it 12288/76743 of epoch 1, 139.51 ms/it, loss 0.455686
Finished training it 13312/76743 of epoch 1, 139.61 ms/it, loss 0.454285
Finished training it 13312/76743 of epoch 1, 139.64 ms/it, loss 0.456987
Finished training it 13312/76743 of epoch 1, 139.57 ms/it, loss 0.456984
Finished training it 13312/76743 of epoch 1, 139.65 ms/it, loss 0.454284
Finished training it 14336/76743 of epoch 1, 140.84 ms/it, loss 0.454654
Finished training it 14336/76743 of epoch 1, 140.80 ms/it, loss 0.456078
Finished training it 14336/76743 of epoch 1, 140.77 ms/it, loss 0.454047
Finished training it 14336/76743 of epoch 1, 140.82 ms/it, loss 0.455368
Finished training it 15360/76743 of epoch 1, 142.45 ms/it, loss 0.454561
Finished training it 15360/76743 of epoch 1, 142.51 ms/it, loss 0.456376
Finished training it 15360/76743 of epoch 1, 142.54 ms/it, loss 0.456557
Finished training it 15360/76743 of epoch 1, 142.51 ms/it, loss 0.454642
Finished training it 16384/76743 of epoch 1, 140.76 ms/it, loss 0.455045
Finished training it 16384/76743 of epoch 1, 140.60 ms/it, loss 0.454871
Finished training it 16384/76743 of epoch 1, 140.69 ms/it, loss 0.452371
Finished training it 16384/76743 of epoch 1, 140.79 ms/it, loss 0.451633
Finished training it 17408/76743 of epoch 1, 140.07 ms/it, loss 0.454162
Finished training it 17408/76743 of epoch 1, 140.07 ms/it, loss 0.454861
Finished training it 17408/76743 of epoch 1, 140.07 ms/it, loss 0.457049
Finished training it 17408/76743 of epoch 1, 140.09 ms/it, loss 0.453197
Finished training it 18432/76743 of epoch 1, 139.27 ms/it, loss 0.453715
Finished training it 18432/76743 of epoch 1, 139.34 ms/it, loss 0.455160
Finished training it 18432/76743 of epoch 1, 139.31 ms/it, loss 0.453477
Finished training it 18432/76743 of epoch 1, 139.29 ms/it, loss 0.454159
Finished training it 19456/76743 of epoch 1, 140.59 ms/it, loss 0.452912
Finished training it 19456/76743 of epoch 1, 140.58 ms/it, loss 0.452765
Finished training it 19456/76743 of epoch 1, 140.66 ms/it, loss 0.453688
Finished training it 19456/76743 of epoch 1, 140.56 ms/it, loss 0.450720
Finished training it 20480/76743 of epoch 1, 139.13 ms/it, loss 0.451703
Finished training it 20480/76743 of epoch 1, 139.11 ms/it, loss 0.451479
Finished training it 20480/76743 of epoch 1, 139.11 ms/it, loss 0.456417
Finished training it 20480/76743 of epoch 1, 139.15 ms/it, loss 0.452706
Testing at - 20480/76743 of epoch 1,
steps testing: 0.0steps testing: 0.06253908692933083steps testing: 0.12507817385866166steps testing: 0.18761726078799248steps testing: 0.2501563477173233steps testing: 0.31269543464665417steps testing: 0.37523452157598497steps testing: 0.4377736085053158steps testing: 0.5003126954346466steps testing: 0.5628517823639775steps testing: 0.6253908692933083steps testing: 0.6879299562226392steps testing: 0.7504690431519699steps testing: 0.8130081300813008steps testing: 0.8755472170106317steps testing: 0.9380863039399625Warning: Skipping the batch 3197 with size 602
rank: 0 test_accu: 2567847.0
get out
0 has test check 2567847.0 and sample count 3273728
 accuracy 78.438 %, best 78.445 %, roc auc score 0.7936, best 0.7936
Testing at - 20480/76743 of epoch 1,
Warning: Skipping the batch 3197 with size 602
rank: 2 test_accu: 2567847.0
get out
2 has test check 2567847.0 and sample count 3273728
Finished training it 21504/76743 of epoch 1, 139.24 ms/it, loss 0.458367
Saving model to /home/yzhou/dlrm_criteo_kaggle/save_model_after_training_one0.0.pt
Finished training it 21504/76743 of epoch 1, 139.16 ms/it, loss 0.454076
Testing at - 20480/76743 of epoch 1,
Warning: Skipping the batch 3197 with size 602
rank: 1 test_accu: 2567847.0
get out
1 has test check 2567847.0 and sample count 3273728
Finished training it 21504/76743 of epoch 1, 139.25 ms/it, loss 0.456264
Testing at - 20480/76743 of epoch 1,
Warning: Skipping the batch 3197 with size 602
rank: 3 test_accu: 2567847.0
get out
3 has test check 2567847.0 and sample count 3273728
Finished training it 21504/76743 of epoch 1, 139.29 ms/it, loss 0.450341
Finished training it 22528/76743 of epoch 1, 139.82 ms/it, loss 0.454693
Finished training it 22528/76743 of epoch 1, 139.92 ms/it, loss 0.456141
Finished training it 22528/76743 of epoch 1, 139.92 ms/it, loss 0.455797
Finished training it 22528/76743 of epoch 1, 139.84 ms/it, loss 0.454716
Finished training it 23552/76743 of epoch 1, 140.05 ms/it, loss 0.452414
Finished training it 23552/76743 of epoch 1, 140.09 ms/it, loss 0.453123
Finished training it 23552/76743 of epoch 1, 140.06 ms/it, loss 0.456521
Finished training it 23552/76743 of epoch 1, 140.11 ms/it, loss 0.453339
Finished training it 24576/76743 of epoch 1, 139.73 ms/it, loss 0.456957
Finished training it 24576/76743 of epoch 1, 139.76 ms/it, loss 0.453208
Finished training it 24576/76743 of epoch 1, 139.72 ms/it, loss 0.455187
Finished training it 24576/76743 of epoch 1, 139.74 ms/it, loss 0.453470
Finished training it 25600/76743 of epoch 1, 139.51 ms/it, loss 0.452637
Finished training it 25600/76743 of epoch 1, 139.43 ms/it, loss 0.452452
Finished training it 25600/76743 of epoch 1, 139.50 ms/it, loss 0.457407
Finished training it 25600/76743 of epoch 1, 139.52 ms/it, loss 0.452297
Finished training it 26624/76743 of epoch 1, 139.60 ms/it, loss 0.451333
Finished training it 26624/76743 of epoch 1, 139.70 ms/it, loss 0.453029
Finished training it 26624/76743 of epoch 1, 139.66 ms/it, loss 0.453866
Finished training it 26624/76743 of epoch 1, 139.65 ms/it, loss 0.454563
Finished training it 27648/76743 of epoch 1, 138.20 ms/it, loss 0.453328
Finished training it 27648/76743 of epoch 1, 138.16 ms/it, loss 0.454616
Finished training it 27648/76743 of epoch 1, 138.22 ms/it, loss 0.455029
Finished training it 27648/76743 of epoch 1, 138.24 ms/it, loss 0.455258
Finished training it 28672/76743 of epoch 1, 139.53 ms/it, loss 0.451647
Finished training it 28672/76743 of epoch 1, 139.56 ms/it, loss 0.454695
Finished training it 28672/76743 of epoch 1, 139.55 ms/it, loss 0.454102
Finished training it 28672/76743 of epoch 1, 139.56 ms/it, loss 0.453692
Finished training it 29696/76743 of epoch 1, 138.51 ms/it, loss 0.454784
Finished training it 29696/76743 of epoch 1, 138.53 ms/it, loss 0.453803
Finished training it 29696/76743 of epoch 1, 138.51 ms/it, loss 0.458051
Finished training it 29696/76743 of epoch 1, 138.48 ms/it, loss 0.455778
Finished training it 30720/76743 of epoch 1, 138.39 ms/it, loss 0.454986
Finished training it 30720/76743 of epoch 1, 138.36 ms/it, loss 0.456495
Finished training it 30720/76743 of epoch 1, 138.41 ms/it, loss 0.455318
Finished training it 30720/76743 of epoch 1, 138.48 ms/it, loss 0.456342
Testing at - 30720/76743 of epoch 1,
steps testing: 0.0steps testing: 0.06253908692933083steps testing: 0.12507817385866166steps testing: 0.18761726078799248steps testing: 0.2501563477173233steps testing: 0.31269543464665417steps testing: 0.37523452157598497steps testing: 0.4377736085053158steps testing: 0.5003126954346466steps testing: 0.5628517823639775steps testing: 0.6253908692933083steps testing: 0.6879299562226392steps testing: 0.7504690431519699steps testing: 0.8130081300813008steps testing: 0.8755472170106317steps testing: 0.9380863039399625Warning: Skipping the batch 3197 with size 602
rank: 0 test_accu: 2569000.0
get out
0 has test check 2569000.0 and sample count 3273728
 accuracy 78.473 %, best 78.473 %, roc auc score 0.7939, best 0.7939
Testing at - 30720/76743 of epoch 1,
Warning: Skipping the batch 3197 with size 602
rank: 3 test_accu: 2569000.0
get out
3 has test check 2569000.0 and sample count 3273728
Finished training it 31744/76743 of epoch 1, 139.01 ms/it, loss 0.453046
Testing at - 30720/76743 of epoch 1,
Warning: Skipping the batch 3197 with size 602
rank: 1 test_accu: 2569000.0
get out
1 has test check 2569000.0 and sample count 3273728
Finished training it 31744/76743 of epoch 1, 139.05 ms/it, loss 0.453320
Testing at - 30720/76743 of epoch 1,
Warning: Skipping the batch 3197 with size 602
rank: 2 test_accu: 2569000.0
get out
2 has test check 2569000.0 and sample count 3273728
Finished training it 31744/76743 of epoch 1, 139.02 ms/it, loss 0.457005
Saving model to /home/yzhou/dlrm_criteo_kaggle/save_model_after_training_one1.0.pt
Finished training it 31744/76743 of epoch 1, 138.95 ms/it, loss 0.454510
Finished training it 32768/76743 of epoch 1, 140.07 ms/it, loss 0.455300
Finished training it 32768/76743 of epoch 1, 140.15 ms/it, loss 0.455303
Finished training it 32768/76743 of epoch 1, 140.04 ms/it, loss 0.452804
Finished training it 32768/76743 of epoch 1, 140.13 ms/it, loss 0.454362
Finished training it 33792/76743 of epoch 1, 139.59 ms/it, loss 0.450515
Finished training it 33792/76743 of epoch 1, 139.57 ms/it, loss 0.455391
Finished training it 33792/76743 of epoch 1, 139.61 ms/it, loss 0.454885
Finished training it 33792/76743 of epoch 1, 139.59 ms/it, loss 0.451416
Finished training it 34816/76743 of epoch 1, 139.52 ms/it, loss 0.455579
Finished training it 34816/76743 of epoch 1, 139.51 ms/it, loss 0.455737
Finished training it 34816/76743 of epoch 1, 139.44 ms/it, loss 0.455103
Finished training it 34816/76743 of epoch 1, 139.49 ms/it, loss 0.455583
Finished training it 35840/76743 of epoch 1, 139.75 ms/it, loss 0.453912
Finished training it 35840/76743 of epoch 1, 139.76 ms/it, loss 0.454831
Finished training it 35840/76743 of epoch 1, 139.77 ms/it, loss 0.454010
Finished training it 35840/76743 of epoch 1, 139.67 ms/it, loss 0.456134
Finished training it 36864/76743 of epoch 1, 138.23 ms/it, loss 0.453376
Finished training it 36864/76743 of epoch 1, 138.26 ms/it, loss 0.453760
Finished training it 36864/76743 of epoch 1, 138.17 ms/it, loss 0.450397
Finished training it 36864/76743 of epoch 1, 138.26 ms/it, loss 0.450563
Finished training it 37888/76743 of epoch 1, 139.55 ms/it, loss 0.450648
Finished training it 37888/76743 of epoch 1, 139.50 ms/it, loss 0.455126
Finished training it 37888/76743 of epoch 1, 139.51 ms/it, loss 0.453725
Finished training it 37888/76743 of epoch 1, 139.53 ms/it, loss 0.455186
Finished training it 38912/76743 of epoch 1, 138.97 ms/it, loss 0.453071
Finished training it 38912/76743 of epoch 1, 138.89 ms/it, loss 0.453684
Finished training it 38912/76743 of epoch 1, 138.97 ms/it, loss 0.451653
Finished training it 38912/76743 of epoch 1, 138.97 ms/it, loss 0.454604
Finished training it 39936/76743 of epoch 1, 138.56 ms/it, loss 0.453160
Finished training it 39936/76743 of epoch 1, 138.56 ms/it, loss 0.452031
Finished training it 39936/76743 of epoch 1, 138.52 ms/it, loss 0.454332
Finished training it 39936/76743 of epoch 1, 138.54 ms/it, loss 0.454211
Finished training it 40960/76743 of epoch 1, 140.98 ms/it, loss 0.453197
Finished training it 40960/76743 of epoch 1, 141.00 ms/it, loss 0.453745
Finished training it 40960/76743 of epoch 1, 140.90 ms/it, loss 0.452542
Finished training it 40960/76743 of epoch 1, 141.01 ms/it, loss 0.452929
Testing at - 40960/76743 of epoch 1,
steps testing: 0.0steps testing: 0.06253908692933083steps testing: 0.12507817385866166steps testing: 0.18761726078799248steps testing: 0.2501563477173233steps testing: 0.31269543464665417steps testing: 0.37523452157598497steps testing: 0.4377736085053158steps testing: 0.5003126954346466steps testing: 0.5628517823639775steps testing: 0.6253908692933083steps testing: 0.6879299562226392steps testing: 0.7504690431519699steps testing: 0.8130081300813008steps testing: 0.8755472170106317steps testing: 0.9380863039399625Warning: Skipping the batch 3197 with size 602
rank: 0 test_accu: 2562227.0
get out
0 has test check 2562227.0 and sample count 3273728
 accuracy 78.266 %, best 78.473 %, roc auc score 0.7945, best 0.7945
Saving model to /home/yzhou/dlrm_criteo_kaggle/save_model_after_training_one0.0.pt
Finished training it 41984/76743 of epoch 1, 139.03 ms/it, loss 0.454729
Testing at - 40960/76743 of epoch 1,
Warning: Skipping the batch 3197 with size 602
rank: 2 test_accu: 2562227.0
get out
2 has test check 2562227.0 and sample count 3273728
Finished training it 41984/76743 of epoch 1, 138.92 ms/it, loss 0.452908
Testing at - 40960/76743 of epoch 1,
Warning: Skipping the batch 3197 with size 602
rank: 3 test_accu: 2562227.0
get out
3 has test check 2562227.0 and sample count 3273728
Finished training it 41984/76743 of epoch 1, 139.05 ms/it, loss 0.453990
Testing at - 40960/76743 of epoch 1,
Warning: Skipping the batch 3197 with size 602
rank: 1 test_accu: 2562227.0
get out
1 has test check 2562227.0 and sample count 3273728
Finished training it 41984/76743 of epoch 1, 139.08 ms/it, loss 0.452682
Finished training it 43008/76743 of epoch 1, 139.03 ms/it, loss 0.454042
Finished training it 43008/76743 of epoch 1, 139.01 ms/it, loss 0.454326
Finished training it 43008/76743 of epoch 1, 139.09 ms/it, loss 0.451226
Finished training it 43008/76743 of epoch 1, 138.95 ms/it, loss 0.452137
Finished training it 44032/76743 of epoch 1, 140.08 ms/it, loss 0.452203
Finished training it 44032/76743 of epoch 1, 140.01 ms/it, loss 0.453669
Finished training it 44032/76743 of epoch 1, 139.98 ms/it, loss 0.454629
Finished training it 44032/76743 of epoch 1, 140.08 ms/it, loss 0.451970
Finished training it 45056/76743 of epoch 1, 139.57 ms/it, loss 0.454130
Finished training it 45056/76743 of epoch 1, 139.60 ms/it, loss 0.451741
Finished training it 45056/76743 of epoch 1, 139.56 ms/it, loss 0.451152
Finished training it 45056/76743 of epoch 1, 139.64 ms/it, loss 0.455278
Finished training it 46080/76743 of epoch 1, 139.67 ms/it, loss 0.454446
Finished training it 46080/76743 of epoch 1, 139.69 ms/it, loss 0.449465
Finished training it 46080/76743 of epoch 1, 139.68 ms/it, loss 0.450819
Finished training it 46080/76743 of epoch 1, 139.74 ms/it, loss 0.452290
Finished training it 47104/76743 of epoch 1, 138.95 ms/it, loss 0.454261
Finished training it 47104/76743 of epoch 1, 138.93 ms/it, loss 0.453926
Finished training it 47104/76743 of epoch 1, 138.94 ms/it, loss 0.452305
Finished training it 47104/76743 of epoch 1, 138.86 ms/it, loss 0.451100
Finished training it 48128/76743 of epoch 1, 138.57 ms/it, loss 0.451365
Finished training it 48128/76743 of epoch 1, 138.59 ms/it, loss 0.454472
Finished training it 48128/76743 of epoch 1, 138.67 ms/it, loss 0.452380
Finished training it 48128/76743 of epoch 1, 138.63 ms/it, loss 0.452266
Finished training it 49152/76743 of epoch 1, 139.23 ms/it, loss 0.453958
Finished training it 49152/76743 of epoch 1, 139.24 ms/it, loss 0.453202
Finished training it 49152/76743 of epoch 1, 139.32 ms/it, loss 0.451525
Finished training it 49152/76743 of epoch 1, 139.21 ms/it, loss 0.451964
Finished training it 50176/76743 of epoch 1, 139.22 ms/it, loss 0.454244
Finished training it 50176/76743 of epoch 1, 139.33 ms/it, loss 0.453467
Finished training it 50176/76743 of epoch 1, 139.25 ms/it, loss 0.453448
Finished training it 50176/76743 of epoch 1, 139.33 ms/it, loss 0.453747
Finished training it 51200/76743 of epoch 1, 138.11 ms/it, loss 0.452565
Finished training it 51200/76743 of epoch 1, 138.11 ms/it, loss 0.451396
Finished training it 51200/76743 of epoch 1, 138.14 ms/it, loss 0.454252
Finished training it 51200/76743 of epoch 1, 138.14 ms/it, loss 0.453363
Testing at - 51200/76743 of epoch 1,
steps testing: 0.0steps testing: 0.06253908692933083steps testing: 0.12507817385866166steps testing: 0.18761726078799248steps testing: 0.2501563477173233steps testing: 0.31269543464665417steps testing: 0.37523452157598497steps testing: 0.4377736085053158steps testing: 0.5003126954346466steps testing: 0.5628517823639775steps testing: 0.6253908692933083steps testing: 0.6879299562226392steps testing: 0.7504690431519699steps testing: 0.8130081300813008steps testing: 0.8755472170106317steps testing: 0.9380863039399625Warning: Skipping the batch 3197 with size 602
rank: 0 test_accu: 2570391.0
get out
0 has test check 2570391.0 and sample count 3273728
 accuracy 78.516 %, best 78.516 %, roc auc score 0.7947, best 0.7947
Testing at - 51200/76743 of epoch 1,
Warning: Skipping the batch 3197 with size 602
rank: 3 test_accu: 2570391.0
get out
3 has test check 2570391.0 and sample count 3273728
Finished training it 52224/76743 of epoch 1, 143.21 ms/it, loss 0.452702
Saving model to /home/yzhou/dlrm_criteo_kaggle/save_model_after_training_one1.0.pt
Finished training it 52224/76743 of epoch 1, 143.15 ms/it, loss 0.454216
Testing at - 51200/76743 of epoch 1,
Warning: Skipping the batch 3197 with size 602
rank: 1 test_accu: 2570391.0
get out
1 has test check 2570391.0 and sample count 3273728
Finished training it 52224/76743 of epoch 1, 143.14 ms/it, loss 0.454086
Testing at - 51200/76743 of epoch 1,
Warning: Skipping the batch 3197 with size 602
rank: 2 test_accu: 2570391.0
get out
2 has test check 2570391.0 and sample count 3273728
Finished training it 52224/76743 of epoch 1, 143.13 ms/it, loss 0.452917
Finished training it 53248/76743 of epoch 1, 138.65 ms/it, loss 0.453122
Finished training it 53248/76743 of epoch 1, 138.73 ms/it, loss 0.449845
Finished training it 53248/76743 of epoch 1, 138.65 ms/it, loss 0.456143
Finished training it 53248/76743 of epoch 1, 138.74 ms/it, loss 0.452871
Finished training it 54272/76743 of epoch 1, 139.25 ms/it, loss 0.451996
Finished training it 54272/76743 of epoch 1, 139.23 ms/it, loss 0.454379
Finished training it 54272/76743 of epoch 1, 139.23 ms/it, loss 0.450653
Finished training it 54272/76743 of epoch 1, 139.15 ms/it, loss 0.452727
Finished training it 55296/76743 of epoch 1, 138.82 ms/it, loss 0.453429
Finished training it 55296/76743 of epoch 1, 138.86 ms/it, loss 0.452956
Finished training it 55296/76743 of epoch 1, 138.88 ms/it, loss 0.452413
Finished training it 55296/76743 of epoch 1, 138.83 ms/it, loss 0.453522
Finished training it 56320/76743 of epoch 1, 138.92 ms/it, loss 0.453509
Finished training it 56320/76743 of epoch 1, 138.84 ms/it, loss 0.452057
Finished training it 56320/76743 of epoch 1, 138.92 ms/it, loss 0.450536
Finished training it 56320/76743 of epoch 1, 138.92 ms/it, loss 0.453354
Finished training it 57344/76743 of epoch 1, 139.57 ms/it, loss 0.453279
Finished training it 57344/76743 of epoch 1, 139.66 ms/it, loss 0.451106
Finished training it 57344/76743 of epoch 1, 139.59 ms/it, loss 0.453942
Finished training it 57344/76743 of epoch 1, 139.61 ms/it, loss 0.454749
Finished training it 58368/76743 of epoch 1, 139.04 ms/it, loss 0.452848
Finished training it 58368/76743 of epoch 1, 139.06 ms/it, loss 0.453856
Finished training it 58368/76743 of epoch 1, 139.05 ms/it, loss 0.452538
Finished training it 58368/76743 of epoch 1, 139.11 ms/it, loss 0.455391
Finished training it 59392/76743 of epoch 1, 140.59 ms/it, loss 0.451927
Finished training it 59392/76743 of epoch 1, 140.50 ms/it, loss 0.449166
Finished training it 59392/76743 of epoch 1, 140.53 ms/it, loss 0.449618
Finished training it 59392/76743 of epoch 1, 140.58 ms/it, loss 0.450148
Finished training it 60416/76743 of epoch 1, 139.79 ms/it, loss 0.451672
Finished training it 60416/76743 of epoch 1, 139.80 ms/it, loss 0.452371
Finished training it 60416/76743 of epoch 1, 139.84 ms/it, loss 0.452030
Finished training it 60416/76743 of epoch 1, 139.80 ms/it, loss 0.454609
Finished training it 61440/76743 of epoch 1, 139.76 ms/it, loss 0.449982
Finished training it 61440/76743 of epoch 1, 139.71 ms/it, loss 0.451134
Finished training it 61440/76743 of epoch 1, 139.71 ms/it, loss 0.454108
Finished training it 61440/76743 of epoch 1, 139.70 ms/it, loss 0.452178
Testing at - 61440/76743 of epoch 1,
steps testing: 0.0steps testing: 0.06253908692933083steps testing: 0.12507817385866166steps testing: 0.18761726078799248steps testing: 0.2501563477173233steps testing: 0.31269543464665417steps testing: 0.37523452157598497steps testing: 0.4377736085053158steps testing: 0.5003126954346466steps testing: 0.5628517823639775steps testing: 0.6253908692933083steps testing: 0.6879299562226392steps testing: 0.7504690431519699steps testing: 0.8130081300813008steps testing: 0.8755472170106317steps testing: 0.9380863039399625Warning: Skipping the batch 3197 with size 602
rank: 0 test_accu: 2572336.0
get out
0 has test check 2572336.0 and sample count 3273728
 accuracy 78.575 %, best 78.575 %, roc auc score 0.7961, best 0.7961
Saving model to /home/yzhou/dlrm_criteo_kaggle/save_model_after_training_one0.0.pt
Finished training it 62464/76743 of epoch 1, 139.90 ms/it, loss 0.448525
Testing at - 61440/76743 of epoch 1,
Warning: Skipping the batch 3197 with size 602
rank: 3 test_accu: 2572336.0
get out
3 has test check 2572336.0 and sample count 3273728
Finished training it 62464/76743 of epoch 1, 139.97 ms/it, loss 0.452890
Testing at - 61440/76743 of epoch 1,
Warning: Skipping the batch 3197 with size 602
rank: 2 test_accu: 2572336.0
get out
2 has test check 2572336.0 and sample count 3273728
Finished training it 62464/76743 of epoch 1, 139.89 ms/it, loss 0.451455
Testing at - 61440/76743 of epoch 1,
Warning: Skipping the batch 3197 with size 602
rank: 1 test_accu: 2572336.0
get out
1 has test check 2572336.0 and sample count 3273728
Finished training it 62464/76743 of epoch 1, 140.03 ms/it, loss 0.451159
Finished training it 63488/76743 of epoch 1, 138.76 ms/it, loss 0.450941
Finished training it 63488/76743 of epoch 1, 138.76 ms/it, loss 0.451563
Finished training it 63488/76743 of epoch 1, 138.80 ms/it, loss 0.452668
Finished training it 63488/76743 of epoch 1, 138.73 ms/it, loss 0.452154
Finished training it 64512/76743 of epoch 1, 139.59 ms/it, loss 0.449672
Finished training it 64512/76743 of epoch 1, 139.56 ms/it, loss 0.453709
Finished training it 64512/76743 of epoch 1, 139.63 ms/it, loss 0.452568
Finished training it 64512/76743 of epoch 1, 139.58 ms/it, loss 0.450693
Finished training it 65536/76743 of epoch 1, 138.77 ms/it, loss 0.453337
Finished training it 65536/76743 of epoch 1, 138.81 ms/it, loss 0.452117
Finished training it 65536/76743 of epoch 1, 138.83 ms/it, loss 0.454213
Finished training it 65536/76743 of epoch 1, 138.72 ms/it, loss 0.451228
Finished training it 66560/76743 of epoch 1, 140.11 ms/it, loss 0.450565
Finished training it 66560/76743 of epoch 1, 140.10 ms/it, loss 0.454122
Finished training it 66560/76743 of epoch 1, 140.09 ms/it, loss 0.450504
Finished training it 66560/76743 of epoch 1, 140.07 ms/it, loss 0.453440
Finished training it 67584/76743 of epoch 1, 137.73 ms/it, loss 0.449457
Finished training it 67584/76743 of epoch 1, 137.77 ms/it, loss 0.452311
Finished training it 67584/76743 of epoch 1, 137.83 ms/it, loss 0.455829
Finished training it 67584/76743 of epoch 1, 137.80 ms/it, loss 0.452309
Finished training it 68608/76743 of epoch 1, 138.30 ms/it, loss 0.449689
Finished training it 68608/76743 of epoch 1, 138.20 ms/it, loss 0.451989
Finished training it 68608/76743 of epoch 1, 138.19 ms/it, loss 0.452570
Finished training it 68608/76743 of epoch 1, 138.27 ms/it, loss 0.452849
Finished training it 69632/76743 of epoch 1, 140.12 ms/it, loss 0.452978
Finished training it 69632/76743 of epoch 1, 140.16 ms/it, loss 0.451352
Finished training it 69632/76743 of epoch 1, 140.18 ms/it, loss 0.455743
Finished training it 69632/76743 of epoch 1, 140.24 ms/it, loss 0.453318
Finished training it 70656/76743 of epoch 1, 139.01 ms/it, loss 0.450271
Finished training it 70656/76743 of epoch 1, 139.02 ms/it, loss 0.449969
Finished training it 70656/76743 of epoch 1, 138.94 ms/it, loss 0.454015
Finished training it 70656/76743 of epoch 1, 138.99 ms/it, loss 0.451469
Finished training it 71680/76743 of epoch 1, 139.39 ms/it, loss 0.450888
Finished training it 71680/76743 of epoch 1, 139.46 ms/it, loss 0.452612
Finished training it 71680/76743 of epoch 1, 139.45 ms/it, loss 0.452857
Finished training it 71680/76743 of epoch 1, 139.50 ms/it, loss 0.453000
Testing at - 71680/76743 of epoch 1,
steps testing: 0.0steps testing: 0.06253908692933083steps testing: 0.12507817385866166steps testing: 0.18761726078799248steps testing: 0.2501563477173233steps testing: 0.31269543464665417steps testing: 0.37523452157598497steps testing: 0.4377736085053158steps testing: 0.5003126954346466steps testing: 0.5628517823639775steps testing: 0.6253908692933083steps testing: 0.6879299562226392steps testing: 0.7504690431519699steps testing: 0.8130081300813008steps testing: 0.8755472170106317steps testing: 0.9380863039399625Warning: Skipping the batch 3197 with size 602
rank: 0 test_accu: 2570435.0
get out
0 has test check 2570435.0 and sample count 3273728
 accuracy 78.517 %, best 78.575 %, roc auc score 0.7959, best 0.7961
Testing at - 71680/76743 of epoch 1,
Warning: Skipping the batch 3197 with size 602
rank: 2 test_accu: 2570435.0
get out
2 has test check 2570435.0 and sample count 3273728
Finished training it 72704/76743 of epoch 1, 140.24 ms/it, loss 0.449729
Testing at - 71680/76743 of epoch 1,
Warning: Skipping the batch 3197 with size 602
rank: 3 test_accu: 2570435.0
get out
3 has test check 2570435.0 and sample count 3273728
Finished training it 72704/76743 of epoch 1, 140.22 ms/it, loss 0.450851
Saving model to /home/yzhou/dlrm_criteo_kaggle/save_model_after_training_one1.0.pt
Finished training it 72704/76743 of epoch 1, 140.13 ms/it, loss 0.452941
Testing at - 71680/76743 of epoch 1,
Warning: Skipping the batch 3197 with size 602
rank: 1 test_accu: 2570435.0
get out
1 has test check 2570435.0 and sample count 3273728
Finished training it 72704/76743 of epoch 1, 140.29 ms/it, loss 0.453158
Finished training it 73728/76743 of epoch 1, 140.63 ms/it, loss 0.452435
Finished training it 73728/76743 of epoch 1, 140.60 ms/it, loss 0.450256
Finished training it 73728/76743 of epoch 1, 140.64 ms/it, loss 0.449857
Finished training it 73728/76743 of epoch 1, 140.67 ms/it, loss 0.451993
Finished training it 74752/76743 of epoch 1, 141.02 ms/it, loss 0.451476
Finished training it 74752/76743 of epoch 1, 140.99 ms/it, loss 0.452564
Finished training it 74752/76743 of epoch 1, 141.02 ms/it, loss 0.451418
Finished training it 74752/76743 of epoch 1, 140.92 ms/it, loss 0.450708
Finished training it 75776/76743 of epoch 1, 140.28 ms/it, loss 0.449301
Finished training it 75776/76743 of epoch 1, 140.27 ms/it, loss 0.452749
Finished training it 75776/76743 of epoch 1, 140.25 ms/it, loss 0.452587
Finished training it 75776/76743 of epoch 1, 140.36 ms/it, loss 0.450858
Warning: Skipping the batch 76742 with size 14
Finished training it 1024/76743 of epoch 2, 140.80 ms/it, loss 0.452686
Warning: Skipping the batch 76742 with size 14
Finished training it 1024/76743 of epoch 2, 140.67 ms/it, loss 0.449806
Warning: Skipping the batch 76742 with size 14
Finished training it 1024/76743 of epoch 2, 141.04 ms/it, loss 0.452607
Warning: Skipping the batch 76742 with size 14
Finished training it 1024/76743 of epoch 2, 140.73 ms/it, loss 0.449746
Finished training it 2048/76743 of epoch 2, 140.15 ms/it, loss 0.452395
Finished training it 2048/76743 of epoch 2, 140.15 ms/it, loss 0.450798
Finished training it 2048/76743 of epoch 2, 140.12 ms/it, loss 0.448428
Finished training it 2048/76743 of epoch 2, 140.08 ms/it, loss 0.450613
Finished training it 3072/76743 of epoch 2, 140.14 ms/it, loss 0.452885
Finished training it 3072/76743 of epoch 2, 140.06 ms/it, loss 0.452280
Finished training it 3072/76743 of epoch 2, 140.07 ms/it, loss 0.450794
Finished training it 3072/76743 of epoch 2, 140.02 ms/it, loss 0.450783
Finished training it 4096/76743 of epoch 2, 138.17 ms/it, loss 0.452846
Finished training it 4096/76743 of epoch 2, 138.05 ms/it, loss 0.452963
Finished training it 4096/76743 of epoch 2, 138.06 ms/it, loss 0.450678
Finished training it 4096/76743 of epoch 2, 138.13 ms/it, loss 0.453516
Finished training it 5120/76743 of epoch 2, 138.40 ms/it, loss 0.453641
Finished training it 5120/76743 of epoch 2, 138.38 ms/it, loss 0.453724
Finished training it 5120/76743 of epoch 2, 138.37 ms/it, loss 0.450324
Finished training it 5120/76743 of epoch 2, 138.42 ms/it, loss 0.451124
Finished training it 6144/76743 of epoch 2, 138.18 ms/it, loss 0.451354
Finished training it 6144/76743 of epoch 2, 138.16 ms/it, loss 0.451638
Finished training it 6144/76743 of epoch 2, 138.27 ms/it, loss 0.449087
Finished training it 6144/76743 of epoch 2, 138.24 ms/it, loss 0.451696
Finished training it 7168/76743 of epoch 2, 140.03 ms/it, loss 0.449755
Finished training it 7168/76743 of epoch 2, 139.97 ms/it, loss 0.451733
Finished training it 7168/76743 of epoch 2, 140.07 ms/it, loss 0.451278
Finished training it 7168/76743 of epoch 2, 140.00 ms/it, loss 0.448300
Finished training it 8192/76743 of epoch 2, 139.00 ms/it, loss 0.450870
Finished training it 8192/76743 of epoch 2, 138.99 ms/it, loss 0.451359
Finished training it 8192/76743 of epoch 2, 139.00 ms/it, loss 0.452047
Finished training it 8192/76743 of epoch 2, 139.03 ms/it, loss 0.450734
Finished training it 9216/76743 of epoch 2, 139.36 ms/it, loss 0.450254
Finished training it 9216/76743 of epoch 2, 139.48 ms/it, loss 0.449748
Finished training it 9216/76743 of epoch 2, 139.42 ms/it, loss 0.450840
Finished training it 9216/76743 of epoch 2, 139.36 ms/it, loss 0.451074
Finished training it 10240/76743 of epoch 2, 139.57 ms/it, loss 0.452001
Finished training it 10240/76743 of epoch 2, 139.59 ms/it, loss 0.452540
Finished training it 10240/76743 of epoch 2, 139.58 ms/it, loss 0.450990
Finished training it 10240/76743 of epoch 2, 139.55 ms/it, loss 0.454381
Testing at - 10240/76743 of epoch 2,
steps testing: 0.0steps testing: 0.06253908692933083steps testing: 0.12507817385866166steps testing: 0.18761726078799248steps testing: 0.2501563477173233steps testing: 0.31269543464665417steps testing: 0.37523452157598497steps testing: 0.4377736085053158steps testing: 0.5003126954346466steps testing: 0.5628517823639775steps testing: 0.6253908692933083steps testing: 0.6879299562226392steps testing: 0.7504690431519699steps testing: 0.8130081300813008steps testing: 0.8755472170106317steps testing: 0.9380863039399625Warning: Skipping the batch 3197 with size 602
rank: 0 test_accu: 2574367.0
get out
0 has test check 2574367.0 and sample count 3273728
 accuracy 78.637 %, best 78.637 %, roc auc score 0.7971, best 0.7971
Testing at - 10240/76743 of epoch 2,
Warning: Skipping the batch 3197 with size 602
rank: 2 test_accu: 2574367.0
get out
2 has test check 2574367.0 and sample count 3273728
Finished training it 11264/76743 of epoch 2, 138.78 ms/it, loss 0.449817
Saving model to /home/yzhou/dlrm_criteo_kaggle/save_model_after_training_one1.0.pt
Finished training it 11264/76743 of epoch 2, 138.76 ms/it, loss 0.447821
Testing at - 10240/76743 of epoch 2,
Warning: Skipping the batch 3197 with size 602
rank: 3 test_accu: 2574367.0
get out
3 has test check 2574367.0 and sample count 3273728
Finished training it 11264/76743 of epoch 2, 138.79 ms/it, loss 0.448671
Testing at - 10240/76743 of epoch 2,
Warning: Skipping the batch 3197 with size 602
rank: 1 test_accu: 2574367.0
get out
1 has test check 2574367.0 and sample count 3273728
Finished training it 11264/76743 of epoch 2, 138.81 ms/it, loss 0.452094
Finished training it 12288/76743 of epoch 2, 139.09 ms/it, loss 0.448318
Finished training it 12288/76743 of epoch 2, 139.00 ms/it, loss 0.451344
Finished training it 12288/76743 of epoch 2, 139.09 ms/it, loss 0.451309
Finished training it 12288/76743 of epoch 2, 139.01 ms/it, loss 0.449573
Finished training it 13312/76743 of epoch 2, 139.44 ms/it, loss 0.450072
Finished training it 13312/76743 of epoch 2, 139.41 ms/it, loss 0.452717
Finished training it 13312/76743 of epoch 2, 139.31 ms/it, loss 0.452415
Finished training it 13312/76743 of epoch 2, 139.37 ms/it, loss 0.449597
Finished training it 14336/76743 of epoch 2, 139.77 ms/it, loss 0.450311
Finished training it 14336/76743 of epoch 2, 139.83 ms/it, loss 0.450443
Finished training it 14336/76743 of epoch 2, 139.90 ms/it, loss 0.451280
Finished training it 14336/76743 of epoch 2, 139.87 ms/it, loss 0.450716
Finished training it 15360/76743 of epoch 2, 139.27 ms/it, loss 0.450577
Finished training it 15360/76743 of epoch 2, 139.32 ms/it, loss 0.451894
Finished training it 15360/76743 of epoch 2, 139.27 ms/it, loss 0.451932
Finished training it 15360/76743 of epoch 2, 139.35 ms/it, loss 0.450777
Finished training it 16384/76743 of epoch 2, 139.98 ms/it, loss 0.450665
Finished training it 16384/76743 of epoch 2, 139.95 ms/it, loss 0.450554
Finished training it 16384/76743 of epoch 2, 139.99 ms/it, loss 0.447446
Finished training it 16384/76743 of epoch 2, 139.98 ms/it, loss 0.448394
Finished training it 17408/76743 of epoch 2, 139.54 ms/it, loss 0.448922
Finished training it 17408/76743 of epoch 2, 139.52 ms/it, loss 0.449848
Finished training it 17408/76743 of epoch 2, 139.52 ms/it, loss 0.453128
Finished training it 17408/76743 of epoch 2, 139.49 ms/it, loss 0.450656
Finished training it 18432/76743 of epoch 2, 142.69 ms/it, loss 0.448740
Finished training it 18432/76743 of epoch 2, 142.57 ms/it, loss 0.450043
Finished training it 18432/76743 of epoch 2, 142.61 ms/it, loss 0.451129
Finished training it 18432/76743 of epoch 2, 142.63 ms/it, loss 0.449573
Finished training it 19456/76743 of epoch 2, 139.74 ms/it, loss 0.448807
Finished training it 19456/76743 of epoch 2, 139.79 ms/it, loss 0.448815
Finished training it 19456/76743 of epoch 2, 139.80 ms/it, loss 0.449311
Finished training it 19456/76743 of epoch 2, 139.78 ms/it, loss 0.446361
Finished training it 20480/76743 of epoch 2, 139.51 ms/it, loss 0.447097
Finished training it 20480/76743 of epoch 2, 139.48 ms/it, loss 0.452244
Finished training it 20480/76743 of epoch 2, 139.50 ms/it, loss 0.447622
Finished training it 20480/76743 of epoch 2, 139.54 ms/it, loss 0.448281
Testing at - 20480/76743 of epoch 2,
steps testing: 0.0steps testing: 0.06253908692933083steps testing: 0.12507817385866166steps testing: 0.18761726078799248steps testing: 0.2501563477173233steps testing: 0.31269543464665417steps testing: 0.37523452157598497steps testing: 0.4377736085053158steps testing: 0.5003126954346466steps testing: 0.5628517823639775steps testing: 0.6253908692933083steps testing: 0.6879299562226392steps testing: 0.7504690431519699steps testing: 0.8130081300813008steps testing: 0.8755472170106317steps testing: 0.9380863039399625Warning: Skipping the batch 3197 with size 602
rank: 0 test_accu: 2573788.0
get out
0 has test check 2573788.0 and sample count 3273728
 accuracy 78.619 %, best 78.637 %, roc auc score 0.7974, best 0.7974
Testing at - 20480/76743 of epoch 2,
Warning: Skipping the batch 3197 with size 602
rank: 3 test_accu: 2573788.0
get out
3 has test check 2573788.0 and sample count 3273728
Finished training it 21504/76743 of epoch 2, 139.44 ms/it, loss 0.446119
Testing at - 20480/76743 of epoch 2,
Warning: Skipping the batch 3197 with size 602
rank: 2 test_accu: 2573788.0
get out
2 has test check 2573788.0 and sample count 3273728
Finished training it 21504/76743 of epoch 2, 139.45 ms/it, loss 0.454145
Saving model to /home/yzhou/dlrm_criteo_kaggle/save_model_after_training_one0.0.pt
Finished training it 21504/76743 of epoch 2, 139.37 ms/it, loss 0.449428
Testing at - 20480/76743 of epoch 2,
Warning: Skipping the batch 3197 with size 602
rank: 1 test_accu: 2573788.0
get out
1 has test check 2573788.0 and sample count 3273728
Finished training it 21504/76743 of epoch 2, 139.53 ms/it, loss 0.451597
Finished training it 22528/76743 of epoch 2, 139.75 ms/it, loss 0.451801
Finished training it 22528/76743 of epoch 2, 139.77 ms/it, loss 0.450667
Finished training it 22528/76743 of epoch 2, 139.73 ms/it, loss 0.451865
Finished training it 22528/76743 of epoch 2, 139.83 ms/it, loss 0.451013
Finished training it 23552/76743 of epoch 2, 139.45 ms/it, loss 0.448919
Finished training it 23552/76743 of epoch 2, 139.42 ms/it, loss 0.448867
Finished training it 23552/76743 of epoch 2, 139.34 ms/it, loss 0.447822
Finished training it 23552/76743 of epoch 2, 139.40 ms/it, loss 0.452357
Finished training it 24576/76743 of epoch 2, 138.76 ms/it, loss 0.448592
Finished training it 24576/76743 of epoch 2, 138.69 ms/it, loss 0.450650
Finished training it 24576/76743 of epoch 2, 138.70 ms/it, loss 0.452716
Finished training it 24576/76743 of epoch 2, 138.74 ms/it, loss 0.449266
Finished training it 25600/76743 of epoch 2, 140.23 ms/it, loss 0.448350
Finished training it 25600/76743 of epoch 2, 140.28 ms/it, loss 0.448459
Finished training it 25600/76743 of epoch 2, 140.33 ms/it, loss 0.448266
Finished training it 25600/76743 of epoch 2, 140.28 ms/it, loss 0.453018
Finished training it 26624/76743 of epoch 2, 137.89 ms/it, loss 0.446728
Finished training it 26624/76743 of epoch 2, 137.88 ms/it, loss 0.449807
Finished training it 26624/76743 of epoch 2, 137.90 ms/it, loss 0.449044
Finished training it 26624/76743 of epoch 2, 137.85 ms/it, loss 0.450637
Finished training it 27648/76743 of epoch 2, 139.30 ms/it, loss 0.448898
Finished training it 27648/76743 of epoch 2, 139.23 ms/it, loss 0.451359
Finished training it 27648/76743 of epoch 2, 139.21 ms/it, loss 0.451063
Finished training it 27648/76743 of epoch 2, 139.31 ms/it, loss 0.450528
Finished training it 28672/76743 of epoch 2, 139.49 ms/it, loss 0.447804
Finished training it 28672/76743 of epoch 2, 139.55 ms/it, loss 0.449949
Finished training it 28672/76743 of epoch 2, 139.53 ms/it, loss 0.449617
Finished training it 28672/76743 of epoch 2, 139.52 ms/it, loss 0.450653
Finished training it 29696/76743 of epoch 2, 138.65 ms/it, loss 0.453677
Finished training it 29696/76743 of epoch 2, 138.57 ms/it, loss 0.449463
Finished training it 29696/76743 of epoch 2, 138.58 ms/it, loss 0.450293
Finished training it 29696/76743 of epoch 2, 138.56 ms/it, loss 0.450854
Finished training it 30720/76743 of epoch 2, 140.31 ms/it, loss 0.451738
Finished training it 30720/76743 of epoch 2, 140.39 ms/it, loss 0.450988
Finished training it 30720/76743 of epoch 2, 140.35 ms/it, loss 0.452161
Finished training it 30720/76743 of epoch 2, 140.34 ms/it, loss 0.450519
Testing at - 30720/76743 of epoch 2,
steps testing: 0.0steps testing: 0.06253908692933083steps testing: 0.12507817385866166steps testing: 0.18761726078799248steps testing: 0.2501563477173233steps testing: 0.31269543464665417steps testing: 0.37523452157598497steps testing: 0.4377736085053158steps testing: 0.5003126954346466steps testing: 0.5628517823639775steps testing: 0.6253908692933083steps testing: 0.6879299562226392steps testing: 0.7504690431519699steps testing: 0.8130081300813008steps testing: 0.8755472170106317steps testing: 0.9380863039399625Warning: Skipping the batch 3197 with size 602
rank: 0 test_accu: 2574642.0
get out
0 has test check 2574642.0 and sample count 3273728
 accuracy 78.646 %, best 78.646 %, roc auc score 0.7979, best 0.7979
Testing at - 30720/76743 of epoch 2,
Warning: Skipping the batch 3197 with size 602
rank: 1 test_accu: 2574642.0
get out
1 has test check 2574642.0 and sample count 3273728
Finished training it 31744/76743 of epoch 2, 139.85 ms/it, loss 0.449101
Testing at - 30720/76743 of epoch 2,
Warning: Skipping the batch 3197 with size 602
rank: 2 test_accu: 2574642.0
get out
2 has test check 2574642.0 and sample count 3273728
Finished training it 31744/76743 of epoch 2, 139.92 ms/it, loss 0.452885
Testing at - 30720/76743 of epoch 2,
Warning: Skipping the batch 3197 with size 602
rank: 3 test_accu: 2574642.0
get out
3 has test check 2574642.0 and sample count 3273728
Finished training it 31744/76743 of epoch 2, 139.80 ms/it, loss 0.448644
Saving model to /home/yzhou/dlrm_criteo_kaggle/save_model_after_training_one1.0.pt
Finished training it 31744/76743 of epoch 2, 139.84 ms/it, loss 0.450321
Finished training it 32768/76743 of epoch 2, 138.90 ms/it, loss 0.448465
Finished training it 32768/76743 of epoch 2, 139.03 ms/it, loss 0.451159
Finished training it 32768/76743 of epoch 2, 138.92 ms/it, loss 0.449786
Finished training it 32768/76743 of epoch 2, 138.98 ms/it, loss 0.450168
Finished training it 33792/76743 of epoch 2, 138.95 ms/it, loss 0.450345
Finished training it 33792/76743 of epoch 2, 138.97 ms/it, loss 0.446045
Finished training it 33792/76743 of epoch 2, 138.92 ms/it, loss 0.450897
Finished training it 33792/76743 of epoch 2, 138.90 ms/it, loss 0.446613
Finished training it 34816/76743 of epoch 2, 139.40 ms/it, loss 0.451420
Finished training it 34816/76743 of epoch 2, 139.37 ms/it, loss 0.450337
Finished training it 34816/76743 of epoch 2, 139.41 ms/it, loss 0.451280
Finished training it 34816/76743 of epoch 2, 139.38 ms/it, loss 0.451240
Finished training it 35840/76743 of epoch 2, 139.60 ms/it, loss 0.450606
Finished training it 35840/76743 of epoch 2, 139.61 ms/it, loss 0.449421
Finished training it 35840/76743 of epoch 2, 139.65 ms/it, loss 0.451455
Finished training it 35840/76743 of epoch 2, 139.69 ms/it, loss 0.449369
Finished training it 36864/76743 of epoch 2, 139.86 ms/it, loss 0.445737
Finished training it 36864/76743 of epoch 2, 139.87 ms/it, loss 0.449302
Finished training it 36864/76743 of epoch 2, 139.84 ms/it, loss 0.449089
Finished training it 36864/76743 of epoch 2, 139.90 ms/it, loss 0.446240
Finished training it 37888/76743 of epoch 2, 139.45 ms/it, loss 0.450733
Finished training it 37888/76743 of epoch 2, 139.52 ms/it, loss 0.451062
Finished training it 37888/76743 of epoch 2, 139.55 ms/it, loss 0.449220
Finished training it 37888/76743 of epoch 2, 139.55 ms/it, loss 0.446149
Finished training it 38912/76743 of epoch 2, 140.37 ms/it, loss 0.448530
Finished training it 38912/76743 of epoch 2, 140.26 ms/it, loss 0.449749
Finished training it 38912/76743 of epoch 2, 140.33 ms/it, loss 0.450533
Finished training it 38912/76743 of epoch 2, 140.28 ms/it, loss 0.447204
Finished training it 39936/76743 of epoch 2, 140.38 ms/it, loss 0.450033
Finished training it 39936/76743 of epoch 2, 140.33 ms/it, loss 0.449832
Finished training it 39936/76743 of epoch 2, 140.39 ms/it, loss 0.449192
Finished training it 39936/76743 of epoch 2, 140.35 ms/it, loss 0.448600
Finished training it 40960/76743 of epoch 2, 140.41 ms/it, loss 0.449916
Finished training it 40960/76743 of epoch 2, 140.35 ms/it, loss 0.448956
Finished training it 40960/76743 of epoch 2, 140.39 ms/it, loss 0.448246
Finished training it 40960/76743 of epoch 2, 140.41 ms/it, loss 0.448700
Testing at - 40960/76743 of epoch 2,
steps testing: 0.0steps testing: 0.06253908692933083steps testing: 0.12507817385866166steps testing: 0.18761726078799248steps testing: 0.2501563477173233steps testing: 0.31269543464665417steps testing: 0.37523452157598497steps testing: 0.4377736085053158steps testing: 0.5003126954346466steps testing: 0.5628517823639775steps testing: 0.6253908692933083steps testing: 0.6879299562226392steps testing: 0.7504690431519699steps testing: 0.8130081300813008steps testing: 0.8755472170106317steps testing: 0.9380863039399625Warning: Skipping the batch 3197 with size 602
rank: 0 test_accu: 2567499.0
get out
0 has test check 2567499.0 and sample count 3273728
 accuracy 78.427 %, best 78.646 %, roc auc score 0.7984, best 0.7984
Testing at - 40960/76743 of epoch 2,
Warning: Skipping the batch 3197 with size 602
rank: 1 test_accu: 2567499.0
get out
1 has test check 2567499.0 and sample count 3273728
Finished training it 41984/76743 of epoch 2, 140.52 ms/it, loss 0.448608
Testing at - 40960/76743 of epoch 2,
Warning: Skipping the batch 3197 with size 602
rank: 2 test_accu: 2567499.0
get out
2 has test check 2567499.0 and sample count 3273728
Finished training it 41984/76743 of epoch 2, 140.45 ms/it, loss 0.449132
Saving model to /home/yzhou/dlrm_criteo_kaggle/save_model_after_training_one0.0.pt
Finished training it 41984/76743 of epoch 2, 140.41 ms/it, loss 0.450999
Testing at - 40960/76743 of epoch 2,
Warning: Skipping the batch 3197 with size 602
rank: 3 test_accu: 2567499.0
get out
3 has test check 2567499.0 and sample count 3273728
Finished training it 41984/76743 of epoch 2, 140.48 ms/it, loss 0.450261
Finished training it 43008/76743 of epoch 2, 139.73 ms/it, loss 0.450226
Finished training it 43008/76743 of epoch 2, 139.71 ms/it, loss 0.448478
Finished training it 43008/76743 of epoch 2, 139.69 ms/it, loss 0.450063
Finished training it 43008/76743 of epoch 2, 139.72 ms/it, loss 0.447100
Finished training it 44032/76743 of epoch 2, 139.36 ms/it, loss 0.447429
Finished training it 44032/76743 of epoch 2, 139.27 ms/it, loss 0.449673
Finished training it 44032/76743 of epoch 2, 139.40 ms/it, loss 0.448077
Finished training it 44032/76743 of epoch 2, 139.41 ms/it, loss 0.450596
Finished training it 45056/76743 of epoch 2, 138.93 ms/it, loss 0.447557
Finished training it 45056/76743 of epoch 2, 138.91 ms/it, loss 0.450358
Finished training it 45056/76743 of epoch 2, 138.89 ms/it, loss 0.447063
Finished training it 45056/76743 of epoch 2, 138.97 ms/it, loss 0.450950
Finished training it 46080/76743 of epoch 2, 139.18 ms/it, loss 0.445653
Finished training it 46080/76743 of epoch 2, 139.14 ms/it, loss 0.447053
Finished training it 46080/76743 of epoch 2, 139.24 ms/it, loss 0.448178
Finished training it 46080/76743 of epoch 2, 139.32 ms/it, loss 0.450634
Finished training it 47104/76743 of epoch 2, 140.00 ms/it, loss 0.448550
Finished training it 47104/76743 of epoch 2, 139.94 ms/it, loss 0.450197
Finished training it 47104/76743 of epoch 2, 139.96 ms/it, loss 0.447283
Finished training it 47104/76743 of epoch 2, 139.92 ms/it, loss 0.450054
Finished training it 48128/76743 of epoch 2, 138.71 ms/it, loss 0.447691
Finished training it 48128/76743 of epoch 2, 138.70 ms/it, loss 0.448616
Finished training it 48128/76743 of epoch 2, 138.72 ms/it, loss 0.451154
Finished training it 48128/76743 of epoch 2, 138.72 ms/it, loss 0.448356
Finished training it 49152/76743 of epoch 2, 139.98 ms/it, loss 0.450228
Finished training it 49152/76743 of epoch 2, 139.96 ms/it, loss 0.448142
Finished training it 49152/76743 of epoch 2, 139.96 ms/it, loss 0.449402
Finished training it 49152/76743 of epoch 2, 139.93 ms/it, loss 0.447504
Finished training it 50176/76743 of epoch 2, 138.99 ms/it, loss 0.450626
Finished training it 50176/76743 of epoch 2, 139.13 ms/it, loss 0.449943
Finished training it 50176/76743 of epoch 2, 139.08 ms/it, loss 0.449942
Finished training it 50176/76743 of epoch 2, 139.12 ms/it, loss 0.449793
Finished training it 51200/76743 of epoch 2, 139.08 ms/it, loss 0.448594
Finished training it 51200/76743 of epoch 2, 139.19 ms/it, loss 0.447400
Finished training it 51200/76743 of epoch 2, 139.16 ms/it, loss 0.450663
Finished training it 51200/76743 of epoch 2, 139.20 ms/it, loss 0.449811
Testing at - 51200/76743 of epoch 2,
steps testing: 0.0steps testing: 0.06253908692933083steps testing: 0.12507817385866166steps testing: 0.18761726078799248steps testing: 0.2501563477173233steps testing: 0.31269543464665417steps testing: 0.37523452157598497steps testing: 0.4377736085053158steps testing: 0.5003126954346466steps testing: 0.5628517823639775steps testing: 0.6253908692933083steps testing: 0.6879299562226392steps testing: 0.7504690431519699steps testing: 0.8130081300813008steps testing: 0.8755472170106317steps testing: 0.9380863039399625Warning: Skipping the batch 3197 with size 602
rank: 0 test_accu: 2576269.0
get out
0 has test check 2576269.0 and sample count 3273728
 accuracy 78.695 %, best 78.695 %, roc auc score 0.7984, best 0.7984
Saving model to /home/yzhou/dlrm_criteo_kaggle/save_model_after_training_one1.0.pt
Finished training it 52224/76743 of epoch 2, 140.18 ms/it, loss 0.450414
Testing at - 51200/76743 of epoch 2,
Warning: Skipping the batch 3197 with size 602
rank: 3 test_accu: 2576269.0
get out
3 has test check 2576269.0 and sample count 3273728
Finished training it 52224/76743 of epoch 2, 140.25 ms/it, loss 0.448643
Testing at - 51200/76743 of epoch 2,
Warning: Skipping the batch 3197 with size 602
rank: 2 test_accu: 2576269.0
get out
2 has test check 2576269.0 and sample count 3273728
Finished training it 52224/76743 of epoch 2, 140.22 ms/it, loss 0.449238
Testing at - 51200/76743 of epoch 2,
Warning: Skipping the batch 3197 with size 602
rank: 1 test_accu: 2576269.0
get out
1 has test check 2576269.0 and sample count 3273728
Finished training it 52224/76743 of epoch 2, 140.18 ms/it, loss 0.450215
Finished training it 53248/76743 of epoch 2, 138.07 ms/it, loss 0.449828
Finished training it 53248/76743 of epoch 2, 138.07 ms/it, loss 0.446560
Finished training it 53248/76743 of epoch 2, 138.11 ms/it, loss 0.452557
Finished training it 53248/76743 of epoch 2, 138.07 ms/it, loss 0.449012
Finished training it 54272/76743 of epoch 2, 138.98 ms/it, loss 0.448766
Finished training it 54272/76743 of epoch 2, 139.05 ms/it, loss 0.450691
Finished training it 54272/76743 of epoch 2, 139.00 ms/it, loss 0.446959
Finished training it 54272/76743 of epoch 2, 139.03 ms/it, loss 0.448210
Finished training it 55296/76743 of epoch 2, 142.65 ms/it, loss 0.448659
Finished training it 55296/76743 of epoch 2, 142.76 ms/it, loss 0.449771
Finished training it 55296/76743 of epoch 2, 142.74 ms/it, loss 0.449511
Finished training it 55296/76743 of epoch 2, 142.73 ms/it, loss 0.449047
Finished training it 56320/76743 of epoch 2, 139.48 ms/it, loss 0.449900
Finished training it 56320/76743 of epoch 2, 139.52 ms/it, loss 0.448830
Finished training it 56320/76743 of epoch 2, 139.50 ms/it, loss 0.446588
Finished training it 56320/76743 of epoch 2, 139.53 ms/it, loss 0.448291
Finished training it 57344/76743 of epoch 2, 140.11 ms/it, loss 0.449296
Finished training it 57344/76743 of epoch 2, 140.09 ms/it, loss 0.450333
Finished training it 57344/76743 of epoch 2, 140.13 ms/it, loss 0.446827
Finished training it 57344/76743 of epoch 2, 140.13 ms/it, loss 0.451213
Finished training it 58368/76743 of epoch 2, 139.55 ms/it, loss 0.449364
Finished training it 58368/76743 of epoch 2, 139.60 ms/it, loss 0.448491
Finished training it 58368/76743 of epoch 2, 139.65 ms/it, loss 0.450088
Finished training it 58368/76743 of epoch 2, 139.70 ms/it, loss 0.451598
Finished training it 59392/76743 of epoch 2, 140.15 ms/it, loss 0.445634
Finished training it 59392/76743 of epoch 2, 140.21 ms/it, loss 0.448332
Finished training it 59392/76743 of epoch 2, 140.21 ms/it, loss 0.444830
Finished training it 59392/76743 of epoch 2, 140.21 ms/it, loss 0.446548
Finished training it 60416/76743 of epoch 2, 144.28 ms/it, loss 0.448199
Finished training it 60416/76743 of epoch 2, 144.18 ms/it, loss 0.448711
Finished training it 60416/76743 of epoch 2, 144.14 ms/it, loss 0.447933
Finished training it 60416/76743 of epoch 2, 144.28 ms/it, loss 0.450709
Finished training it 61440/76743 of epoch 2, 139.09 ms/it, loss 0.447420
Finished training it 61440/76743 of epoch 2, 139.13 ms/it, loss 0.450997
Finished training it 61440/76743 of epoch 2, 139.06 ms/it, loss 0.446298
Finished training it 61440/76743 of epoch 2, 139.10 ms/it, loss 0.448772
Testing at - 61440/76743 of epoch 2,
steps testing: 0.0steps testing: 0.06253908692933083steps testing: 0.12507817385866166steps testing: 0.18761726078799248steps testing: 0.2501563477173233steps testing: 0.31269543464665417steps testing: 0.37523452157598497steps testing: 0.4377736085053158steps testing: 0.5003126954346466steps testing: 0.5628517823639775steps testing: 0.6253908692933083steps testing: 0.6879299562226392steps testing: 0.7504690431519699steps testing: 0.8130081300813008steps testing: 0.8755472170106317steps testing: 0.9380863039399625Warning: Skipping the batch 3197 with size 602
rank: 0 test_accu: 2577158.0
get out
0 has test check 2577158.0 and sample count 3273728
 accuracy 78.722 %, best 78.722 %, roc auc score 0.7994, best 0.7994
Testing at - 61440/76743 of epoch 2,
Warning: Skipping the batch 3197 with size 602
rank: 2 test_accu: 2577158.0
get out
2 has test check 2577158.0 and sample count 3273728
Finished training it 62464/76743 of epoch 2, 137.96 ms/it, loss 0.448189
Testing at - 61440/76743 of epoch 2,
Warning: Skipping the batch 3197 with size 602
rank: 3 test_accu: 2577158.0
get out
3 has test check 2577158.0 and sample count 3273728
Finished training it 62464/76743 of epoch 2, 137.90 ms/it, loss 0.449306
Saving model to /home/yzhou/dlrm_criteo_kaggle/save_model_after_training_one0.0.pt
Finished training it 62464/76743 of epoch 2, 137.84 ms/it, loss 0.444627
Testing at - 61440/76743 of epoch 2,
Warning: Skipping the batch 3197 with size 602
rank: 1 test_accu: 2577158.0
get out
1 has test check 2577158.0 and sample count 3273728
Finished training it 62464/76743 of epoch 2, 138.00 ms/it, loss 0.447132
Finished training it 63488/76743 of epoch 2, 139.19 ms/it, loss 0.448981
Finished training it 63488/76743 of epoch 2, 139.19 ms/it, loss 0.449304
Finished training it 63488/76743 of epoch 2, 139.16 ms/it, loss 0.447704
Finished training it 63488/76743 of epoch 2, 139.17 ms/it, loss 0.447310
Finished training it 64512/76743 of epoch 2, 139.77 ms/it, loss 0.450433
Finished training it 64512/76743 of epoch 2, 139.77 ms/it, loss 0.446407
Finished training it 64512/76743 of epoch 2, 139.81 ms/it, loss 0.448831
Finished training it 64512/76743 of epoch 2, 139.78 ms/it, loss 0.447182
Finished training it 65536/76743 of epoch 2, 139.96 ms/it, loss 0.448510
Finished training it 65536/76743 of epoch 2, 139.97 ms/it, loss 0.450022
Finished training it 65536/76743 of epoch 2, 139.99 ms/it, loss 0.447524
Finished training it 65536/76743 of epoch 2, 140.00 ms/it, loss 0.450496
Finished training it 66560/76743 of epoch 2, 139.11 ms/it, loss 0.447005
Finished training it 66560/76743 of epoch 2, 139.13 ms/it, loss 0.450225
Finished training it 66560/76743 of epoch 2, 139.15 ms/it, loss 0.446779
Finished training it 66560/76743 of epoch 2, 139.19 ms/it, loss 0.450184
Finished training it 67584/76743 of epoch 2, 139.76 ms/it, loss 0.452427
Finished training it 67584/76743 of epoch 2, 139.65 ms/it, loss 0.448928
Finished training it 67584/76743 of epoch 2, 139.67 ms/it, loss 0.448650
Finished training it 67584/76743 of epoch 2, 139.72 ms/it, loss 0.445710
Finished training it 68608/76743 of epoch 2, 138.65 ms/it, loss 0.449121
Finished training it 68608/76743 of epoch 2, 138.74 ms/it, loss 0.449267
Finished training it 68608/76743 of epoch 2, 138.70 ms/it, loss 0.448463
Finished training it 68608/76743 of epoch 2, 138.69 ms/it, loss 0.446315
Finished training it 69632/76743 of epoch 2, 139.20 ms/it, loss 0.449555
Finished training it 69632/76743 of epoch 2, 139.17 ms/it, loss 0.448073
Finished training it 69632/76743 of epoch 2, 139.24 ms/it, loss 0.452224
Finished training it 69632/76743 of epoch 2, 139.17 ms/it, loss 0.449927
Finished training it 70656/76743 of epoch 2, 139.50 ms/it, loss 0.450658
Finished training it 70656/76743 of epoch 2, 139.47 ms/it, loss 0.448504
Finished training it 70656/76743 of epoch 2, 139.46 ms/it, loss 0.446617
Finished training it 70656/76743 of epoch 2, 139.39 ms/it, loss 0.446772
Finished training it 71680/76743 of epoch 2, 138.59 ms/it, loss 0.449392
Finished training it 71680/76743 of epoch 2, 138.57 ms/it, loss 0.449974
Finished training it 71680/76743 of epoch 2, 138.55 ms/it, loss 0.447582
Finished training it 71680/76743 of epoch 2, 138.58 ms/it, loss 0.449559
Testing at - 71680/76743 of epoch 2,
steps testing: 0.0steps testing: 0.06253908692933083steps testing: 0.12507817385866166steps testing: 0.18761726078799248steps testing: 0.2501563477173233steps testing: 0.31269543464665417steps testing: 0.37523452157598497steps testing: 0.4377736085053158steps testing: 0.5003126954346466steps testing: 0.5628517823639775steps testing: 0.6253908692933083steps testing: 0.6879299562226392steps testing: 0.7504690431519699steps testing: 0.8130081300813008steps testing: 0.8755472170106317steps testing: 0.9380863039399625Warning: Skipping the batch 3197 with size 602
rank: 0 test_accu: 2573846.0
get out
0 has test check 2573846.0 and sample count 3273728
 accuracy 78.621 %, best 78.722 %, roc auc score 0.7992, best 0.7994
Testing at - 71680/76743 of epoch 2,
Warning: Skipping the batch 3197 with size 602
rank: 3 test_accu: 2573846.0
get out
3 has test check 2573846.0 and sample count 3273728
Finished training it 72704/76743 of epoch 2, 139.10 ms/it, loss 0.447404
Testing at - 71680/76743 of epoch 2,
Warning: Skipping the batch 3197 with size 602
rank: 2 test_accu: 2573846.0
get out
2 has test check 2573846.0 and sample count 3273728
Finished training it 72704/76743 of epoch 2, 139.10 ms/it, loss 0.446576
Testing at - 71680/76743 of epoch 2,
Warning: Skipping the batch 3197 with size 602
rank: 1 test_accu: 2573846.0
get out
1 has test check 2573846.0 and sample count 3273728
Finished training it 72704/76743 of epoch 2, 139.09 ms/it, loss 0.449639
Saving model to /home/yzhou/dlrm_criteo_kaggle/save_model_after_training_one1.0.pt
Finished training it 72704/76743 of epoch 2, 138.96 ms/it, loss 0.449291
Finished training it 73728/76743 of epoch 2, 139.49 ms/it, loss 0.448981
Finished training it 73728/76743 of epoch 2, 139.50 ms/it, loss 0.447328
Finished training it 73728/76743 of epoch 2, 139.56 ms/it, loss 0.446863
Finished training it 73728/76743 of epoch 2, 139.57 ms/it, loss 0.448814
Finished training it 74752/76743 of epoch 2, 139.45 ms/it, loss 0.448483
Finished training it 74752/76743 of epoch 2, 139.34 ms/it, loss 0.447469
Finished training it 74752/76743 of epoch 2, 139.35 ms/it, loss 0.449420
Finished training it 74752/76743 of epoch 2, 139.41 ms/it, loss 0.448145
Finished training it 75776/76743 of epoch 2, 138.55 ms/it, loss 0.447502
Finished training it 75776/76743 of epoch 2, 138.49 ms/it, loss 0.449545
Finished training it 75776/76743 of epoch 2, 138.43 ms/it, loss 0.445982
Finished training it 75776/76743 of epoch 2, 138.49 ms/it, loss 0.449019
Warning: Skipping the batch 76742 with size 14
Finished training it 1024/76743 of epoch 3, 141.11 ms/it, loss 0.449135
Warning: Skipping the batch 76742 with size 14
Finished training it 1024/76743 of epoch 3, 140.61 ms/it, loss 0.446265
Warning: Skipping the batch 76742 with size 14
Finished training it 1024/76743 of epoch 3, 141.11 ms/it, loss 0.449126
Warning: Skipping the batch 76742 with size 14
Finished training it 1024/76743 of epoch 3, 140.97 ms/it, loss 0.446321
Finished training it 2048/76743 of epoch 3, 139.86 ms/it, loss 0.447433
Finished training it 2048/76743 of epoch 3, 139.80 ms/it, loss 0.447137
Finished training it 2048/76743 of epoch 3, 139.90 ms/it, loss 0.444952
Finished training it 2048/76743 of epoch 3, 139.84 ms/it, loss 0.449198
Finished training it 3072/76743 of epoch 3, 140.05 ms/it, loss 0.448771
Finished training it 3072/76743 of epoch 3, 140.12 ms/it, loss 0.447473
Finished training it 3072/76743 of epoch 3, 140.07 ms/it, loss 0.447460
Finished training it 3072/76743 of epoch 3, 140.09 ms/it, loss 0.449578
Finished training it 4096/76743 of epoch 3, 140.22 ms/it, loss 0.449706
Finished training it 4096/76743 of epoch 3, 140.26 ms/it, loss 0.447536
Finished training it 4096/76743 of epoch 3, 140.16 ms/it, loss 0.449382
Finished training it 4096/76743 of epoch 3, 140.19 ms/it, loss 0.450612
Finished training it 5120/76743 of epoch 3, 138.83 ms/it, loss 0.450440
Finished training it 5120/76743 of epoch 3, 138.92 ms/it, loss 0.446882
Finished training it 5120/76743 of epoch 3, 138.89 ms/it, loss 0.447794
Finished training it 5120/76743 of epoch 3, 138.94 ms/it, loss 0.450357
Finished training it 6144/76743 of epoch 3, 140.52 ms/it, loss 0.448473
Finished training it 6144/76743 of epoch 3, 140.44 ms/it, loss 0.448796
Finished training it 6144/76743 of epoch 3, 140.62 ms/it, loss 0.446118
Finished training it 6144/76743 of epoch 3, 140.46 ms/it, loss 0.448160
Finished training it 7168/76743 of epoch 3, 139.92 ms/it, loss 0.445153
Finished training it 7168/76743 of epoch 3, 139.99 ms/it, loss 0.448389
Finished training it 7168/76743 of epoch 3, 139.83 ms/it, loss 0.448629
Finished training it 7168/76743 of epoch 3, 139.89 ms/it, loss 0.446611
Finished training it 8192/76743 of epoch 3, 140.55 ms/it, loss 0.447599
Finished training it 8192/76743 of epoch 3, 140.64 ms/it, loss 0.447747
Finished training it 8192/76743 of epoch 3, 140.59 ms/it, loss 0.447893
Finished training it 8192/76743 of epoch 3, 140.56 ms/it, loss 0.448784
Finished training it 9216/76743 of epoch 3, 139.18 ms/it, loss 0.446843
Finished training it 9216/76743 of epoch 3, 139.16 ms/it, loss 0.447110
Finished training it 9216/76743 of epoch 3, 139.16 ms/it, loss 0.447517
Finished training it 9216/76743 of epoch 3, 139.18 ms/it, loss 0.448319
Finished training it 10240/76743 of epoch 3, 139.10 ms/it, loss 0.447707
Finished training it 10240/76743 of epoch 3, 139.05 ms/it, loss 0.449549
Finished training it 10240/76743 of epoch 3, 139.01 ms/it, loss 0.449234
Finished training it 10240/76743 of epoch 3, 139.08 ms/it, loss 0.451166
Testing at - 10240/76743 of epoch 3,
steps testing: 0.0steps testing: 0.06253908692933083steps testing: 0.12507817385866166steps testing: 0.18761726078799248steps testing: 0.2501563477173233steps testing: 0.31269543464665417steps testing: 0.37523452157598497steps testing: 0.4377736085053158steps testing: 0.5003126954346466steps testing: 0.5628517823639775steps testing: 0.6253908692933083steps testing: 0.6879299562226392steps testing: 0.7504690431519699steps testing: 0.8130081300813008steps testing: 0.8755472170106317steps testing: 0.9380863039399625Warning: Skipping the batch 3197 with size 602
rank: 0 test_accu: 2577794.0
get out
0 has test check 2577794.0 and sample count 3273728
 accuracy 78.742 %, best 78.742 %, roc auc score 0.7997, best 0.7997
Saving model to /home/yzhou/dlrm_criteo_kaggle/save_model_after_training_one1.0.pt
Finished training it 11264/76743 of epoch 3, 140.17 ms/it, loss 0.444802
Testing at - 10240/76743 of epoch 3,
Warning: Skipping the batch 3197 with size 602
rank: 3 test_accu: 2577794.0
get out
3 has test check 2577794.0 and sample count 3273728
Finished training it 11264/76743 of epoch 3, 140.19 ms/it, loss 0.445734
Testing at - 10240/76743 of epoch 3,
Warning: Skipping the batch 3197 with size 602
rank: 2 test_accu: 2577794.0
get out
2 has test check 2577794.0 and sample count 3273728
Finished training it 11264/76743 of epoch 3, 140.19 ms/it, loss 0.446243
Testing at - 10240/76743 of epoch 3,
Warning: Skipping the batch 3197 with size 602
rank: 1 test_accu: 2577794.0
get out
1 has test check 2577794.0 and sample count 3273728
Finished training it 11264/76743 of epoch 3, 140.17 ms/it, loss 0.449147
Finished training it 12288/76743 of epoch 3, 139.18 ms/it, loss 0.448180
Finished training it 12288/76743 of epoch 3, 139.17 ms/it, loss 0.448452
Finished training it 12288/76743 of epoch 3, 139.14 ms/it, loss 0.446808
Finished training it 12288/76743 of epoch 3, 139.15 ms/it, loss 0.445508
Finished training it 13312/76743 of epoch 3, 139.42 ms/it, loss 0.449386
Finished training it 13312/76743 of epoch 3, 139.36 ms/it, loss 0.449470
Finished training it 13312/76743 of epoch 3, 139.43 ms/it, loss 0.447304
Finished training it 13312/76743 of epoch 3, 139.41 ms/it, loss 0.446711
Finished training it 14336/76743 of epoch 3, 139.66 ms/it, loss 0.448103
Finished training it 14336/76743 of epoch 3, 139.65 ms/it, loss 0.447452
Finished training it 14336/76743 of epoch 3, 139.67 ms/it, loss 0.447403
Finished training it 14336/76743 of epoch 3, 139.72 ms/it, loss 0.447478
Finished training it 15360/76743 of epoch 3, 139.37 ms/it, loss 0.449120
Finished training it 15360/76743 of epoch 3, 139.36 ms/it, loss 0.447743
Finished training it 15360/76743 of epoch 3, 139.44 ms/it, loss 0.447786
Finished training it 15360/76743 of epoch 3, 139.32 ms/it, loss 0.448896
Finished training it 16384/76743 of epoch 3, 139.48 ms/it, loss 0.447379
Finished training it 16384/76743 of epoch 3, 139.51 ms/it, loss 0.444870
Finished training it 16384/76743 of epoch 3, 139.52 ms/it, loss 0.444322
Finished training it 16384/76743 of epoch 3, 139.53 ms/it, loss 0.447422
Finished training it 17408/76743 of epoch 3, 139.25 ms/it, loss 0.446483
Finished training it 17408/76743 of epoch 3, 139.31 ms/it, loss 0.445911
Finished training it 17408/76743 of epoch 3, 139.28 ms/it, loss 0.449900
Finished training it 17408/76743 of epoch 3, 139.29 ms/it, loss 0.447620
Finished training it 18432/76743 of epoch 3, 138.95 ms/it, loss 0.448227
Finished training it 18432/76743 of epoch 3, 138.92 ms/it, loss 0.445793
Finished training it 18432/76743 of epoch 3, 138.99 ms/it, loss 0.447025
Finished training it 18432/76743 of epoch 3, 138.94 ms/it, loss 0.446281
Finished training it 19456/76743 of epoch 3, 139.76 ms/it, loss 0.443157
Finished training it 19456/76743 of epoch 3, 139.78 ms/it, loss 0.446634
Finished training it 19456/76743 of epoch 3, 139.77 ms/it, loss 0.445759
Finished training it 19456/76743 of epoch 3, 139.74 ms/it, loss 0.445792
Finished training it 20480/76743 of epoch 3, 139.04 ms/it, loss 0.444793
Finished training it 20480/76743 of epoch 3, 139.12 ms/it, loss 0.445646
Finished training it 20480/76743 of epoch 3, 139.07 ms/it, loss 0.448952
Finished training it 20480/76743 of epoch 3, 139.07 ms/it, loss 0.443996
Testing at - 20480/76743 of epoch 3,
steps testing: 0.0steps testing: 0.06253908692933083steps testing: 0.12507817385866166steps testing: 0.18761726078799248steps testing: 0.2501563477173233steps testing: 0.31269543464665417steps testing: 0.37523452157598497steps testing: 0.4377736085053158steps testing: 0.5003126954346466steps testing: 0.5628517823639775steps testing: 0.6253908692933083steps testing: 0.6879299562226392steps testing: 0.7504690431519699steps testing: 0.8130081300813008steps testing: 0.8755472170106317steps testing: 0.9380863039399625Warning: Skipping the batch 3197 with size 602
rank: 0 test_accu: 2576850.0
get out
0 has test check 2576850.0 and sample count 3273728
 accuracy 78.713 %, best 78.742 %, roc auc score 0.8001, best 0.8001
Testing at - 20480/76743 of epoch 3,
Warning: Skipping the batch 3197 with size 602
rank: 2 test_accu: 2576850.0
get out
2 has test check 2576850.0 and sample count 3273728
Finished training it 21504/76743 of epoch 3, 140.32 ms/it, loss 0.450941
Testing at - 20480/76743 of epoch 3,
Warning: Skipping the batch 3197 with size 602
rank: 3 test_accu: 2576850.0
get out
3 has test check 2576850.0 and sample count 3273728
Finished training it 21504/76743 of epoch 3, 140.37 ms/it, loss 0.442957
Saving model to /home/yzhou/dlrm_criteo_kaggle/save_model_after_training_one0.0.pt
Finished training it 21504/76743 of epoch 3, 140.22 ms/it, loss 0.446613
Testing at - 20480/76743 of epoch 3,
Warning: Skipping the batch 3197 with size 602
rank: 1 test_accu: 2576850.0
get out
1 has test check 2576850.0 and sample count 3273728
Finished training it 21504/76743 of epoch 3, 140.38 ms/it, loss 0.448615
Finished training it 22528/76743 of epoch 3, 139.21 ms/it, loss 0.448609
Finished training it 22528/76743 of epoch 3, 139.35 ms/it, loss 0.447557
Finished training it 22528/76743 of epoch 3, 139.27 ms/it, loss 0.447710
Finished training it 22528/76743 of epoch 3, 139.28 ms/it, loss 0.448848
Finished training it 23552/76743 of epoch 3, 139.35 ms/it, loss 0.449821
Finished training it 23552/76743 of epoch 3, 139.35 ms/it, loss 0.446302
Finished training it 23552/76743 of epoch 3, 139.43 ms/it, loss 0.446324
Finished training it 23552/76743 of epoch 3, 139.36 ms/it, loss 0.444917
Finished training it 24576/76743 of epoch 3, 139.38 ms/it, loss 0.449974
Finished training it 24576/76743 of epoch 3, 139.49 ms/it, loss 0.447727
Finished training it 24576/76743 of epoch 3, 139.45 ms/it, loss 0.446354
Finished training it 24576/76743 of epoch 3, 139.53 ms/it, loss 0.445408
Finished training it 25600/76743 of epoch 3, 139.72 ms/it, loss 0.445024
Finished training it 25600/76743 of epoch 3, 139.71 ms/it, loss 0.445638
Finished training it 25600/76743 of epoch 3, 139.72 ms/it, loss 0.450203
Finished training it 25600/76743 of epoch 3, 139.81 ms/it, loss 0.445400
Finished training it 26624/76743 of epoch 3, 141.04 ms/it, loss 0.443547
Finished training it 26624/76743 of epoch 3, 141.02 ms/it, loss 0.447681
Finished training it 26624/76743 of epoch 3, 141.08 ms/it, loss 0.446470
Finished training it 26624/76743 of epoch 3, 141.03 ms/it, loss 0.445849
Finished training it 27648/76743 of epoch 3, 139.09 ms/it, loss 0.446175
Finished training it 27648/76743 of epoch 3, 139.05 ms/it, loss 0.448036
Finished training it 27648/76743 of epoch 3, 139.10 ms/it, loss 0.447956
Finished training it 27648/76743 of epoch 3, 139.06 ms/it, loss 0.447747
Finished training it 28672/76743 of epoch 3, 139.86 ms/it, loss 0.446865
Finished training it 28672/76743 of epoch 3, 139.82 ms/it, loss 0.447464
Finished training it 28672/76743 of epoch 3, 139.80 ms/it, loss 0.445190
Finished training it 28672/76743 of epoch 3, 139.90 ms/it, loss 0.446488
Finished training it 29696/76743 of epoch 3, 138.33 ms/it, loss 0.447742
Finished training it 29696/76743 of epoch 3, 138.35 ms/it, loss 0.446497
Finished training it 29696/76743 of epoch 3, 138.36 ms/it, loss 0.447410
Finished training it 29696/76743 of epoch 3, 138.29 ms/it, loss 0.450439
Finished training it 30720/76743 of epoch 3, 137.67 ms/it, loss 0.448149
Finished training it 30720/76743 of epoch 3, 137.56 ms/it, loss 0.448844
Finished training it 30720/76743 of epoch 3, 137.62 ms/it, loss 0.447797
Finished training it 30720/76743 of epoch 3, 137.67 ms/it, loss 0.449363
Testing at - 30720/76743 of epoch 3,
steps testing: 0.0steps testing: 0.06253908692933083steps testing: 0.12507817385866166steps testing: 0.18761726078799248steps testing: 0.2501563477173233steps testing: 0.31269543464665417steps testing: 0.37523452157598497steps testing: 0.4377736085053158steps testing: 0.5003126954346466steps testing: 0.5628517823639775steps testing: 0.6253908692933083steps testing: 0.6879299562226392steps testing: 0.7504690431519699steps testing: 0.8130081300813008steps testing: 0.8755472170106317steps testing: 0.9380863039399625Warning: Skipping the batch 3197 with size 602
rank: 0 test_accu: 2577681.0
get out
0 has test check 2577681.0 and sample count 3273728
 accuracy 78.738 %, best 78.742 %, roc auc score 0.8000, best 0.8001
Testing at - 30720/76743 of epoch 3,
Warning: Skipping the batch 3197 with size 602
rank: 3 test_accu: 2577681.0
get out
3 has test check 2577681.0 and sample count 3273728
Finished training it 31744/76743 of epoch 3, 139.88 ms/it, loss 0.445661
Saving model to /home/yzhou/dlrm_criteo_kaggle/save_model_after_training_one1.0.pt
Finished training it 31744/76743 of epoch 3, 139.92 ms/it, loss 0.447238
Testing at - 30720/76743 of epoch 3,
Warning: Skipping the batch 3197 with size 602
rank: 2 test_accu: 2577681.0
get out
2 has test check 2577681.0 and sample count 3273728
Finished training it 31744/76743 of epoch 3, 139.97 ms/it, loss 0.449724
Testing at - 30720/76743 of epoch 3,
Warning: Skipping the batch 3197 with size 602
rank: 1 test_accu: 2577681.0
get out
1 has test check 2577681.0 and sample count 3273728
Finished training it 31744/76743 of epoch 3, 139.81 ms/it, loss 0.445945
Finished training it 32768/76743 of epoch 3, 139.71 ms/it, loss 0.446913
Finished training it 32768/76743 of epoch 3, 139.69 ms/it, loss 0.445877
Finished training it 32768/76743 of epoch 3, 139.61 ms/it, loss 0.447190
Finished training it 32768/76743 of epoch 3, 139.74 ms/it, loss 0.448296
Finished training it 33792/76743 of epoch 3, 140.54 ms/it, loss 0.447902
Finished training it 33792/76743 of epoch 3, 140.58 ms/it, loss 0.443208
Finished training it 33792/76743 of epoch 3, 140.63 ms/it, loss 0.447811
Finished training it 33792/76743 of epoch 3, 140.61 ms/it, loss 0.443831
Finished training it 34816/76743 of epoch 3, 139.20 ms/it, loss 0.448686
Finished training it 34816/76743 of epoch 3, 139.35 ms/it, loss 0.447473
Finished training it 34816/76743 of epoch 3, 139.24 ms/it, loss 0.448546
Finished training it 34816/76743 of epoch 3, 139.29 ms/it, loss 0.448265
Finished training it 35840/76743 of epoch 3, 140.15 ms/it, loss 0.447865
Finished training it 35840/76743 of epoch 3, 140.23 ms/it, loss 0.446885
Finished training it 35840/76743 of epoch 3, 140.21 ms/it, loss 0.446581
Finished training it 35840/76743 of epoch 3, 140.12 ms/it, loss 0.448528
Finished training it 36864/76743 of epoch 3, 140.40 ms/it, loss 0.443116
Finished training it 36864/76743 of epoch 3, 140.45 ms/it, loss 0.443219
Finished training it 36864/76743 of epoch 3, 140.38 ms/it, loss 0.446368
Finished training it 36864/76743 of epoch 3, 140.40 ms/it, loss 0.446245
Finished training it 37888/76743 of epoch 3, 139.71 ms/it, loss 0.443315
Finished training it 37888/76743 of epoch 3, 139.70 ms/it, loss 0.448272
Finished training it 37888/76743 of epoch 3, 139.70 ms/it, loss 0.448475
Finished training it 37888/76743 of epoch 3, 139.70 ms/it, loss 0.446523
Finished training it 38912/76743 of epoch 3, 138.46 ms/it, loss 0.444315
Finished training it 38912/76743 of epoch 3, 138.48 ms/it, loss 0.446062
Finished training it 38912/76743 of epoch 3, 138.39 ms/it, loss 0.448095
Finished training it 38912/76743 of epoch 3, 138.39 ms/it, loss 0.447237
Finished training it 39936/76743 of epoch 3, 139.39 ms/it, loss 0.446413
Finished training it 39936/76743 of epoch 3, 139.47 ms/it, loss 0.445782
Finished training it 39936/76743 of epoch 3, 139.41 ms/it, loss 0.447533
Finished training it 39936/76743 of epoch 3, 139.44 ms/it, loss 0.446894
Finished training it 40960/76743 of epoch 3, 138.64 ms/it, loss 0.446814
Finished training it 40960/76743 of epoch 3, 138.77 ms/it, loss 0.445918
Finished training it 40960/76743 of epoch 3, 138.71 ms/it, loss 0.445255
Finished training it 40960/76743 of epoch 3, 138.72 ms/it, loss 0.445972
Testing at - 40960/76743 of epoch 3,
steps testing: 0.0steps testing: 0.06253908692933083steps testing: 0.12507817385866166steps testing: 0.18761726078799248steps testing: 0.2501563477173233steps testing: 0.31269543464665417steps testing: 0.37523452157598497steps testing: 0.4377736085053158steps testing: 0.5003126954346466steps testing: 0.5628517823639775steps testing: 0.6253908692933083steps testing: 0.6879299562226392steps testing: 0.7504690431519699steps testing: 0.8130081300813008steps testing: 0.8755472170106317steps testing: 0.9380863039399625Warning: Skipping the batch 3197 with size 602
rank: 0 test_accu: 2570919.0
get out
0 has test check 2570919.0 and sample count 3273728
 accuracy 78.532 %, best 78.742 %, roc auc score 0.8005, best 0.8005
Testing at - 40960/76743 of epoch 3,
Warning: Skipping the batch 3197 with size 602
rank: 3 test_accu: 2570919.0
get out
3 has test check 2570919.0 and sample count 3273728
Finished training it 41984/76743 of epoch 3, 140.03 ms/it, loss 0.447611
Testing at - 40960/76743 of epoch 3,
Warning: Skipping the batch 3197 with size 602
rank: 1 test_accu: 2570919.0
get out
1 has test check 2570919.0 and sample count 3273728
Finished training it 41984/76743 of epoch 3, 140.07 ms/it, loss 0.445742
Testing at - 40960/76743 of epoch 3,
Warning: Skipping the batch 3197 with size 602
rank: 2 test_accu: 2570919.0
get out
2 has test check 2570919.0 and sample count 3273728
Finished training it 41984/76743 of epoch 3, 140.01 ms/it, loss 0.445903
Saving model to /home/yzhou/dlrm_criteo_kaggle/save_model_after_training_one0.0.pt
Finished training it 41984/76743 of epoch 3, 139.91 ms/it, loss 0.448011
Finished training it 43008/76743 of epoch 3, 139.27 ms/it, loss 0.447518
Finished training it 43008/76743 of epoch 3, 139.20 ms/it, loss 0.447409
Finished training it 43008/76743 of epoch 3, 139.26 ms/it, loss 0.444207
Finished training it 43008/76743 of epoch 3, 139.26 ms/it, loss 0.445303
Finished training it 44032/76743 of epoch 3, 139.65 ms/it, loss 0.445433
Finished training it 44032/76743 of epoch 3, 139.63 ms/it, loss 0.445035
Finished training it 44032/76743 of epoch 3, 139.64 ms/it, loss 0.446967
Finished training it 44032/76743 of epoch 3, 139.69 ms/it, loss 0.448072
Finished training it 45056/76743 of epoch 3, 140.02 ms/it, loss 0.448126
Finished training it 45056/76743 of epoch 3, 139.93 ms/it, loss 0.447470
Finished training it 45056/76743 of epoch 3, 139.96 ms/it, loss 0.444932
Finished training it 45056/76743 of epoch 3, 139.95 ms/it, loss 0.444840
Finished training it 46080/76743 of epoch 3, 140.92 ms/it, loss 0.444220
Finished training it 46080/76743 of epoch 3, 140.95 ms/it, loss 0.442865
Finished training it 46080/76743 of epoch 3, 141.02 ms/it, loss 0.445319
Finished training it 46080/76743 of epoch 3, 140.91 ms/it, loss 0.447458
Finished training it 47104/76743 of epoch 3, 140.30 ms/it, loss 0.445514
Finished training it 47104/76743 of epoch 3, 140.21 ms/it, loss 0.444326
Finished training it 47104/76743 of epoch 3, 140.18 ms/it, loss 0.447181
Finished training it 47104/76743 of epoch 3, 140.16 ms/it, loss 0.447342
Finished training it 48128/76743 of epoch 3, 139.59 ms/it, loss 0.444684
Finished training it 48128/76743 of epoch 3, 139.55 ms/it, loss 0.445946
Finished training it 48128/76743 of epoch 3, 139.61 ms/it, loss 0.448163
Finished training it 48128/76743 of epoch 3, 139.60 ms/it, loss 0.445831
Finished training it 49152/76743 of epoch 3, 139.64 ms/it, loss 0.445201
Finished training it 49152/76743 of epoch 3, 139.63 ms/it, loss 0.446330
Finished training it 49152/76743 of epoch 3, 139.70 ms/it, loss 0.444623
Finished training it 49152/76743 of epoch 3, 139.71 ms/it, loss 0.446801
Finished training it 50176/76743 of epoch 3, 139.49 ms/it, loss 0.447421
Finished training it 50176/76743 of epoch 3, 139.53 ms/it, loss 0.447120
Finished training it 50176/76743 of epoch 3, 139.57 ms/it, loss 0.447889
Finished training it 50176/76743 of epoch 3, 139.57 ms/it, loss 0.446626
Finished training it 51200/76743 of epoch 3, 140.06 ms/it, loss 0.445723
Finished training it 51200/76743 of epoch 3, 140.09 ms/it, loss 0.447833
Finished training it 51200/76743 of epoch 3, 140.09 ms/it, loss 0.447308
Finished training it 51200/76743 of epoch 3, 140.07 ms/it, loss 0.444354
Testing at - 51200/76743 of epoch 3,
steps testing: 0.0steps testing: 0.06253908692933083steps testing: 0.12507817385866166steps testing: 0.18761726078799248steps testing: 0.2501563477173233steps testing: 0.31269543464665417steps testing: 0.37523452157598497steps testing: 0.4377736085053158steps testing: 0.5003126954346466steps testing: 0.5628517823639775steps testing: 0.6253908692933083steps testing: 0.6879299562226392steps testing: 0.7504690431519699steps testing: 0.8130081300813008steps testing: 0.8755472170106317steps testing: 0.9380863039399625Warning: Skipping the batch 3197 with size 602
rank: 0 test_accu: 2578835.0
get out
0 has test check 2578835.0 and sample count 3273728
 accuracy 78.774 %, best 78.774 %, roc auc score 0.8005, best 0.8005
Saving model to /home/yzhou/dlrm_criteo_kaggle/save_model_after_training_one1.0.pt
Finished training it 52224/76743 of epoch 3, 140.05 ms/it, loss 0.447355
Testing at - 51200/76743 of epoch 3,
Warning: Skipping the batch 3197 with size 602
rank: 2 test_accu: 2578835.0
get out
2 has test check 2578835.0 and sample count 3273728
Finished training it 52224/76743 of epoch 3, 140.06 ms/it, loss 0.446526
Testing at - 51200/76743 of epoch 3,
Warning: Skipping the batch 3197 with size 602
rank: 1 test_accu: 2578835.0
get out
1 has test check 2578835.0 and sample count 3273728
Finished training it 52224/76743 of epoch 3, 140.14 ms/it, loss 0.447765
Testing at - 51200/76743 of epoch 3,
Warning: Skipping the batch 3197 with size 602
rank: 3 test_accu: 2578835.0
get out
3 has test check 2578835.0 and sample count 3273728
Finished training it 52224/76743 of epoch 3, 140.08 ms/it, loss 0.445472
Finished training it 53248/76743 of epoch 3, 140.01 ms/it, loss 0.447168
Finished training it 53248/76743 of epoch 3, 140.05 ms/it, loss 0.445871
Finished training it 53248/76743 of epoch 3, 140.01 ms/it, loss 0.443593
Finished training it 53248/76743 of epoch 3, 140.05 ms/it, loss 0.449318
Finished training it 54272/76743 of epoch 3, 140.34 ms/it, loss 0.445896
Finished training it 54272/76743 of epoch 3, 140.39 ms/it, loss 0.448050
Finished training it 54272/76743 of epoch 3, 140.39 ms/it, loss 0.444978
Finished training it 54272/76743 of epoch 3, 140.41 ms/it, loss 0.444095
Finished training it 55296/76743 of epoch 3, 139.39 ms/it, loss 0.445882
Finished training it 55296/76743 of epoch 3, 139.41 ms/it, loss 0.446962
Finished training it 55296/76743 of epoch 3, 139.39 ms/it, loss 0.447209
Finished training it 55296/76743 of epoch 3, 139.47 ms/it, loss 0.446465
Finished training it 56320/76743 of epoch 3, 139.70 ms/it, loss 0.446115
Finished training it 56320/76743 of epoch 3, 139.65 ms/it, loss 0.445887
Finished training it 56320/76743 of epoch 3, 139.66 ms/it, loss 0.446875
Finished training it 56320/76743 of epoch 3, 139.72 ms/it, loss 0.444091
Finished training it 57344/76743 of epoch 3, 140.60 ms/it, loss 0.444344
Finished training it 57344/76743 of epoch 3, 140.60 ms/it, loss 0.447944
Finished training it 57344/76743 of epoch 3, 140.59 ms/it, loss 0.448344
Finished training it 57344/76743 of epoch 3, 140.54 ms/it, loss 0.446649
Finished training it 58368/76743 of epoch 3, 139.93 ms/it, loss 0.446135
Finished training it 58368/76743 of epoch 3, 139.84 ms/it, loss 0.447606
Finished training it 58368/76743 of epoch 3, 139.84 ms/it, loss 0.446928
Finished training it 58368/76743 of epoch 3, 139.90 ms/it, loss 0.448815
Finished training it 59392/76743 of epoch 3, 139.40 ms/it, loss 0.443268
Finished training it 59392/76743 of epoch 3, 139.40 ms/it, loss 0.442067
Finished training it 59392/76743 of epoch 3, 139.47 ms/it, loss 0.443978
Finished training it 59392/76743 of epoch 3, 139.43 ms/it, loss 0.445703
Finished training it 60416/76743 of epoch 3, 139.94 ms/it, loss 0.445562
Finished training it 60416/76743 of epoch 3, 139.86 ms/it, loss 0.446113
Finished training it 60416/76743 of epoch 3, 139.94 ms/it, loss 0.448032
Finished training it 60416/76743 of epoch 3, 139.88 ms/it, loss 0.445382
Finished training it 61440/76743 of epoch 3, 143.55 ms/it, loss 0.446641
Finished training it 61440/76743 of epoch 3, 143.54 ms/it, loss 0.443857
Finished training it 61440/76743 of epoch 3, 143.65 ms/it, loss 0.444984
Finished training it 61440/76743 of epoch 3, 143.55 ms/it, loss 0.448333
Testing at - 61440/76743 of epoch 3,
steps testing: 0.0steps testing: 0.06253908692933083steps testing: 0.12507817385866166steps testing: 0.18761726078799248steps testing: 0.2501563477173233steps testing: 0.31269543464665417steps testing: 0.37523452157598497steps testing: 0.4377736085053158steps testing: 0.5003126954346466steps testing: 0.5628517823639775steps testing: 0.6253908692933083steps testing: 0.6879299562226392steps testing: 0.7504690431519699steps testing: 0.8130081300813008steps testing: 0.8755472170106317steps testing: 0.9380863039399625Warning: Skipping the batch 3197 with size 602
rank: 0 test_accu: 2579950.0
get out
0 has test check 2579950.0 and sample count 3273728
 accuracy 78.808 %, best 78.808 %, roc auc score 0.8013, best 0.8013
Testing at - 61440/76743 of epoch 3,
Warning: Skipping the batch 3197 with size 602
rank: 3 test_accu: 2579950.0
get out
3 has test check 2579950.0 and sample count 3273728
Finished training it 62464/76743 of epoch 3, 140.33 ms/it, loss 0.446969
Testing at - 61440/76743 of epoch 3,
Warning: Skipping the batch 3197 with size 602
rank: 2 test_accu: 2579950.0
get out
2 has test check 2579950.0 and sample count 3273728
Finished training it 62464/76743 of epoch 3, 140.27 ms/it, loss 0.445663
Testing at - 61440/76743 of epoch 3,
Warning: Skipping the batch 3197 with size 602
rank: 1 test_accu: 2579950.0
get out
1 has test check 2579950.0 and sample count 3273728
Finished training it 62464/76743 of epoch 3, 140.11 ms/it, loss 0.444364
Saving model to /home/yzhou/dlrm_criteo_kaggle/save_model_after_training_one0.0.pt
Finished training it 62464/76743 of epoch 3, 140.17 ms/it, loss 0.442182
Finished training it 63488/76743 of epoch 3, 139.30 ms/it, loss 0.444805
Finished training it 63488/76743 of epoch 3, 139.33 ms/it, loss 0.446310
Finished training it 63488/76743 of epoch 3, 139.34 ms/it, loss 0.445314
Finished training it 63488/76743 of epoch 3, 139.33 ms/it, loss 0.446798
Finished training it 64512/76743 of epoch 3, 139.41 ms/it, loss 0.447518
Finished training it 64512/76743 of epoch 3, 139.42 ms/it, loss 0.446208
Finished training it 64512/76743 of epoch 3, 139.43 ms/it, loss 0.443933
Finished training it 64512/76743 of epoch 3, 139.49 ms/it, loss 0.444754
Finished training it 65536/76743 of epoch 3, 138.66 ms/it, loss 0.448115
Finished training it 65536/76743 of epoch 3, 138.63 ms/it, loss 0.447628
Finished training it 65536/76743 of epoch 3, 138.55 ms/it, loss 0.444834
Finished training it 65536/76743 of epoch 3, 138.62 ms/it, loss 0.446083
Finished training it 66560/76743 of epoch 3, 139.32 ms/it, loss 0.444712
Finished training it 66560/76743 of epoch 3, 139.29 ms/it, loss 0.447747
Finished training it 66560/76743 of epoch 3, 139.35 ms/it, loss 0.444227
Finished training it 66560/76743 of epoch 3, 139.38 ms/it, loss 0.447622
Finished training it 67584/76743 of epoch 3, 140.12 ms/it, loss 0.446350
Finished training it 67584/76743 of epoch 3, 140.08 ms/it, loss 0.442853
Finished training it 67584/76743 of epoch 3, 140.13 ms/it, loss 0.449799
Finished training it 67584/76743 of epoch 3, 140.10 ms/it, loss 0.446497
Finished training it 68608/76743 of epoch 3, 139.94 ms/it, loss 0.446350
Finished training it 68608/76743 of epoch 3, 139.89 ms/it, loss 0.446477
Finished training it 68608/76743 of epoch 3, 139.98 ms/it, loss 0.444036
Finished training it 68608/76743 of epoch 3, 139.87 ms/it, loss 0.446401
Finished training it 69632/76743 of epoch 3, 139.35 ms/it, loss 0.445519
Finished training it 69632/76743 of epoch 3, 139.33 ms/it, loss 0.447203
Finished training it 69632/76743 of epoch 3, 139.34 ms/it, loss 0.449766
Finished training it 69632/76743 of epoch 3, 139.42 ms/it, loss 0.447103
Finished training it 70656/76743 of epoch 3, 139.66 ms/it, loss 0.444350
Finished training it 70656/76743 of epoch 3, 139.64 ms/it, loss 0.445970
Finished training it 70656/76743 of epoch 3, 139.65 ms/it, loss 0.448374
Finished training it 70656/76743 of epoch 3, 139.71 ms/it, loss 0.444280
Finished training it 71680/76743 of epoch 3, 139.38 ms/it, loss 0.446872
Finished training it 71680/76743 of epoch 3, 139.38 ms/it, loss 0.445361
Finished training it 71680/76743 of epoch 3, 139.37 ms/it, loss 0.447483
Finished training it 71680/76743 of epoch 3, 139.45 ms/it, loss 0.447633
Testing at - 71680/76743 of epoch 3,
steps testing: 0.0steps testing: 0.06253908692933083steps testing: 0.12507817385866166steps testing: 0.18761726078799248steps testing: 0.2501563477173233steps testing: 0.31269543464665417steps testing: 0.37523452157598497steps testing: 0.4377736085053158steps testing: 0.5003126954346466steps testing: 0.5628517823639775steps testing: 0.6253908692933083steps testing: 0.6879299562226392steps testing: 0.7504690431519699steps testing: 0.8130081300813008steps testing: 0.8755472170106317steps testing: 0.9380863039399625Warning: Skipping the batch 3197 with size 602
rank: 0 test_accu: 2576802.0
get out
0 has test check 2576802.0 and sample count 3273728
 accuracy 78.712 %, best 78.808 %, roc auc score 0.8012, best 0.8013
Saving model to /home/yzhou/dlrm_criteo_kaggle/save_model_after_training_one1.0.pt
Finished training it 72704/76743 of epoch 3, 139.11 ms/it, loss 0.446894
Testing at - 71680/76743 of epoch 3,
Warning: Skipping the batch 3197 with size 602
rank: 1 test_accu: 2576802.0
get out
1 has test check 2576802.0 and sample count 3273728
Finished training it 72704/76743 of epoch 3, 139.29 ms/it, loss 0.447444
Testing at - 71680/76743 of epoch 3,
Warning: Skipping the batch 3197 with size 602
rank: 3 test_accu: 2576802.0
get out
3 has test check 2576802.0 and sample count 3273728
Finished training it 72704/76743 of epoch 3, 139.22 ms/it, loss 0.445086
Testing at - 71680/76743 of epoch 3,
Warning: Skipping the batch 3197 with size 602
rank: 2 test_accu: 2576802.0
get out
2 has test check 2576802.0 and sample count 3273728
Finished training it 72704/76743 of epoch 3, 139.22 ms/it, loss 0.444299
Finished training it 73728/76743 of epoch 3, 139.44 ms/it, loss 0.446496
Finished training it 73728/76743 of epoch 3, 139.46 ms/it, loss 0.444633
Finished training it 73728/76743 of epoch 3, 139.49 ms/it, loss 0.446383
Finished training it 73728/76743 of epoch 3, 139.48 ms/it, loss 0.444792
Finished training it 74752/76743 of epoch 3, 140.03 ms/it, loss 0.446158
Finished training it 74752/76743 of epoch 3, 139.97 ms/it, loss 0.445715
Finished training it 74752/76743 of epoch 3, 140.04 ms/it, loss 0.447015
Finished training it 74752/76743 of epoch 3, 139.99 ms/it, loss 0.445140
Finished training it 75776/76743 of epoch 3, 139.86 ms/it, loss 0.447285
Finished training it 75776/76743 of epoch 3, 139.92 ms/it, loss 0.443706
Finished training it 75776/76743 of epoch 3, 139.99 ms/it, loss 0.446213
Finished training it 75776/76743 of epoch 3, 139.90 ms/it, loss 0.445225
Warning: Skipping the batch 76742 with size 14
Finished training it 1024/76743 of epoch 4, 140.84 ms/it, loss 0.444044
Warning: Skipping the batch 76742 with size 14
Finished training it 1024/76743 of epoch 4, 141.29 ms/it, loss 0.446896
Warning: Skipping the batch 76742 with size 14
Finished training it 1024/76743 of epoch 4, 141.29 ms/it, loss 0.446695
Warning: Skipping the batch 76742 with size 14
Finished training it 1024/76743 of epoch 4, 141.18 ms/it, loss 0.443971
Finished training it 2048/76743 of epoch 4, 140.17 ms/it, loss 0.444651
Finished training it 2048/76743 of epoch 4, 140.27 ms/it, loss 0.445068
Finished training it 2048/76743 of epoch 4, 140.29 ms/it, loss 0.442807
Finished training it 2048/76743 of epoch 4, 140.25 ms/it, loss 0.447022
Finished training it 3072/76743 of epoch 4, 139.73 ms/it, loss 0.445334
Finished training it 3072/76743 of epoch 4, 139.77 ms/it, loss 0.446882
Finished training it 3072/76743 of epoch 4, 139.79 ms/it, loss 0.445183
Finished training it 3072/76743 of epoch 4, 139.76 ms/it, loss 0.447335
Finished training it 4096/76743 of epoch 4, 139.66 ms/it, loss 0.447633
Finished training it 4096/76743 of epoch 4, 139.72 ms/it, loss 0.448560
Finished training it 4096/76743 of epoch 4, 139.69 ms/it, loss 0.447003
Finished training it 4096/76743 of epoch 4, 139.74 ms/it, loss 0.445193
Finished training it 5120/76743 of epoch 4, 139.23 ms/it, loss 0.448143
Finished training it 5120/76743 of epoch 4, 139.23 ms/it, loss 0.448230
Finished training it 5120/76743 of epoch 4, 139.24 ms/it, loss 0.445608
Finished training it 5120/76743 of epoch 4, 139.17 ms/it, loss 0.444601
Finished training it 6144/76743 of epoch 4, 139.87 ms/it, loss 0.446048
Finished training it 6144/76743 of epoch 4, 139.85 ms/it, loss 0.446591
Finished training it 6144/76743 of epoch 4, 139.81 ms/it, loss 0.445469
Finished training it 6144/76743 of epoch 4, 139.89 ms/it, loss 0.443711
Finished training it 7168/76743 of epoch 4, 139.39 ms/it, loss 0.446165
Finished training it 7168/76743 of epoch 4, 139.30 ms/it, loss 0.446086
Finished training it 7168/76743 of epoch 4, 139.41 ms/it, loss 0.444336
Finished training it 7168/76743 of epoch 4, 139.43 ms/it, loss 0.442766
Finished training it 8192/76743 of epoch 4, 139.41 ms/it, loss 0.445084
Finished training it 8192/76743 of epoch 4, 139.48 ms/it, loss 0.446551
Finished training it 8192/76743 of epoch 4, 139.43 ms/it, loss 0.444868
Finished training it 8192/76743 of epoch 4, 139.44 ms/it, loss 0.445257
Finished training it 9216/76743 of epoch 4, 138.61 ms/it, loss 0.444377
Finished training it 9216/76743 of epoch 4, 138.50 ms/it, loss 0.444819
Finished training it 9216/76743 of epoch 4, 138.56 ms/it, loss 0.445710
Finished training it 9216/76743 of epoch 4, 138.62 ms/it, loss 0.445285
Finished training it 10240/76743 of epoch 4, 140.85 ms/it, loss 0.448738
Finished training it 10240/76743 of epoch 4, 140.81 ms/it, loss 0.446789
Finished training it 10240/76743 of epoch 4, 140.78 ms/it, loss 0.445431
Finished training it 10240/76743 of epoch 4, 140.78 ms/it, loss 0.447054
Testing at - 10240/76743 of epoch 4,
steps testing: 0.0steps testing: 0.06253908692933083steps testing: 0.12507817385866166steps testing: 0.18761726078799248steps testing: 0.2501563477173233steps testing: 0.31269543464665417steps testing: 0.37523452157598497steps testing: 0.4377736085053158steps testing: 0.5003126954346466steps testing: 0.5628517823639775steps testing: 0.6253908692933083steps testing: 0.6879299562226392steps testing: 0.7504690431519699steps testing: 0.8130081300813008steps testing: 0.8755472170106317steps testing: 0.9380863039399625Warning: Skipping the batch 3197 with size 602
rank: 0 test_accu: 2580251.0
get out
0 has test check 2580251.0 and sample count 3273728
 accuracy 78.817 %, best 78.817 %, roc auc score 0.8015, best 0.8015
Testing at - 10240/76743 of epoch 4,
Warning: Skipping the batch 3197 with size 602
rank: 1 test_accu: 2580251.0
get out
1 has test check 2580251.0 and sample count 3273728
Finished training it 11264/76743 of epoch 4, 139.68 ms/it, loss 0.446954
Saving model to /home/yzhou/dlrm_criteo_kaggle/save_model_after_training_one1.0.pt
Finished training it 11264/76743 of epoch 4, 139.61 ms/it, loss 0.442733
Testing at - 10240/76743 of epoch 4,
Warning: Skipping the batch 3197 with size 602
rank: 2 test_accu: 2580251.0
get out
2 has test check 2580251.0 and sample count 3273728
Finished training it 11264/76743 of epoch 4, 139.53 ms/it, loss 0.443912
Testing at - 10240/76743 of epoch 4,
Warning: Skipping the batch 3197 with size 602
rank: 3 test_accu: 2580251.0
get out
3 has test check 2580251.0 and sample count 3273728
Finished training it 11264/76743 of epoch 4, 139.62 ms/it, loss 0.443210
Finished training it 12288/76743 of epoch 4, 139.66 ms/it, loss 0.446277
Finished training it 12288/76743 of epoch 4, 139.75 ms/it, loss 0.444180
Finished training it 12288/76743 of epoch 4, 139.69 ms/it, loss 0.446119
Finished training it 12288/76743 of epoch 4, 139.69 ms/it, loss 0.443347
Finished training it 13312/76743 of epoch 4, 139.13 ms/it, loss 0.444859
Finished training it 13312/76743 of epoch 4, 139.19 ms/it, loss 0.447076
Finished training it 13312/76743 of epoch 4, 139.23 ms/it, loss 0.444465
Finished training it 13312/76743 of epoch 4, 139.16 ms/it, loss 0.447296
Finished training it 14336/76743 of epoch 4, 138.68 ms/it, loss 0.445097
Finished training it 14336/76743 of epoch 4, 138.76 ms/it, loss 0.445875
Finished training it 14336/76743 of epoch 4, 138.68 ms/it, loss 0.445256
Finished training it 14336/76743 of epoch 4, 138.80 ms/it, loss 0.445246
Finished training it 15360/76743 of epoch 4, 140.65 ms/it, loss 0.446514
Finished training it 15360/76743 of epoch 4, 140.64 ms/it, loss 0.446870
Finished training it 15360/76743 of epoch 4, 140.68 ms/it, loss 0.445681
Finished training it 15360/76743 of epoch 4, 140.69 ms/it, loss 0.445309
Finished training it 16384/76743 of epoch 4, 139.71 ms/it, loss 0.441933
Finished training it 16384/76743 of epoch 4, 139.68 ms/it, loss 0.445457
Finished training it 16384/76743 of epoch 4, 139.70 ms/it, loss 0.442790
Finished training it 16384/76743 of epoch 4, 139.72 ms/it, loss 0.444831
Finished training it 17408/76743 of epoch 4, 140.12 ms/it, loss 0.444558
Finished training it 17408/76743 of epoch 4, 140.14 ms/it, loss 0.447725
Finished training it 17408/76743 of epoch 4, 140.12 ms/it, loss 0.445198
Finished training it 17408/76743 of epoch 4, 140.12 ms/it, loss 0.443873
Finished training it 18432/76743 of epoch 4, 140.25 ms/it, loss 0.443403
Finished training it 18432/76743 of epoch 4, 140.28 ms/it, loss 0.444214
Finished training it 18432/76743 of epoch 4, 140.18 ms/it, loss 0.444964
Finished training it 18432/76743 of epoch 4, 140.26 ms/it, loss 0.446200
Finished training it 19456/76743 of epoch 4, 139.05 ms/it, loss 0.443900
Finished training it 19456/76743 of epoch 4, 139.01 ms/it, loss 0.444292
Finished training it 19456/76743 of epoch 4, 138.95 ms/it, loss 0.440990
Finished training it 19456/76743 of epoch 4, 138.93 ms/it, loss 0.443421
Finished training it 20480/76743 of epoch 4, 139.83 ms/it, loss 0.446832
Finished training it 20480/76743 of epoch 4, 139.85 ms/it, loss 0.441635
Finished training it 20480/76743 of epoch 4, 139.88 ms/it, loss 0.443042
Finished training it 20480/76743 of epoch 4, 139.75 ms/it, loss 0.442698
Testing at - 20480/76743 of epoch 4,
steps testing: 0.0steps testing: 0.06253908692933083steps testing: 0.12507817385866166steps testing: 0.18761726078799248steps testing: 0.2501563477173233steps testing: 0.31269543464665417steps testing: 0.37523452157598497steps testing: 0.4377736085053158steps testing: 0.5003126954346466steps testing: 0.5628517823639775steps testing: 0.6253908692933083steps testing: 0.6879299562226392steps testing: 0.7504690431519699steps testing: 0.8130081300813008steps testing: 0.8755472170106317steps testing: 0.9380863039399625Warning: Skipping the batch 3197 with size 602
rank: 0 test_accu: 2580012.0
get out
0 has test check 2580012.0 and sample count 3273728
 accuracy 78.810 %, best 78.817 %, roc auc score 0.8019, best 0.8019
Testing at - 20480/76743 of epoch 4,
Warning: Skipping the batch 3197 with size 602
rank: 1 test_accu: 2580012.0
get out
1 has test check 2580012.0 and sample count 3273728
Finished training it 21504/76743 of epoch 4, 143.93 ms/it, loss 0.446757
Saving model to /home/yzhou/dlrm_criteo_kaggle/save_model_after_training_one0.0.pt
Finished training it 21504/76743 of epoch 4, 144.08 ms/it, loss 0.444708
Testing at - 20480/76743 of epoch 4,
Warning: Skipping the batch 3197 with size 602
rank: 2 test_accu: 2580012.0
get out
2 has test check 2580012.0 and sample count 3273728
Finished training it 21504/76743 of epoch 4, 143.95 ms/it, loss 0.448926
Testing at - 20480/76743 of epoch 4,
Warning: Skipping the batch 3197 with size 602
rank: 3 test_accu: 2580012.0
get out
3 has test check 2580012.0 and sample count 3273728
Finished training it 21504/76743 of epoch 4, 143.92 ms/it, loss 0.440543
Finished training it 22528/76743 of epoch 4, 140.37 ms/it, loss 0.445547
Finished training it 22528/76743 of epoch 4, 140.41 ms/it, loss 0.446514
Finished training it 22528/76743 of epoch 4, 140.35 ms/it, loss 0.446570
Finished training it 22528/76743 of epoch 4, 140.39 ms/it, loss 0.445543
Finished training it 23552/76743 of epoch 4, 139.21 ms/it, loss 0.444120
Finished training it 23552/76743 of epoch 4, 139.24 ms/it, loss 0.442556
Finished training it 23552/76743 of epoch 4, 139.28 ms/it, loss 0.444536
Finished training it 23552/76743 of epoch 4, 139.19 ms/it, loss 0.447358
Finished training it 24576/76743 of epoch 4, 138.93 ms/it, loss 0.443019
Finished training it 24576/76743 of epoch 4, 138.90 ms/it, loss 0.445614
Finished training it 24576/76743 of epoch 4, 138.95 ms/it, loss 0.443866
Finished training it 24576/76743 of epoch 4, 138.84 ms/it, loss 0.447828
Finished training it 25600/76743 of epoch 4, 138.93 ms/it, loss 0.443245
Finished training it 25600/76743 of epoch 4, 138.96 ms/it, loss 0.443551
Finished training it 25600/76743 of epoch 4, 138.92 ms/it, loss 0.447987
Finished training it 25600/76743 of epoch 4, 139.03 ms/it, loss 0.443363
Finished training it 26624/76743 of epoch 4, 140.94 ms/it, loss 0.444040
Finished training it 26624/76743 of epoch 4, 140.86 ms/it, loss 0.445271
Finished training it 26624/76743 of epoch 4, 140.95 ms/it, loss 0.441662
Finished training it 26624/76743 of epoch 4, 140.87 ms/it, loss 0.444006
Finished training it 27648/76743 of epoch 4, 139.82 ms/it, loss 0.445949
Finished training it 27648/76743 of epoch 4, 139.85 ms/it, loss 0.446318
Finished training it 27648/76743 of epoch 4, 139.93 ms/it, loss 0.445537
Finished training it 27648/76743 of epoch 4, 139.90 ms/it, loss 0.444183
Finished training it 28672/76743 of epoch 4, 138.75 ms/it, loss 0.442984
Finished training it 28672/76743 of epoch 4, 138.76 ms/it, loss 0.444609
Finished training it 28672/76743 of epoch 4, 138.86 ms/it, loss 0.444075
Finished training it 28672/76743 of epoch 4, 138.80 ms/it, loss 0.445213
Finished training it 29696/76743 of epoch 4, 139.77 ms/it, loss 0.444875
Finished training it 29696/76743 of epoch 4, 139.72 ms/it, loss 0.444578
Finished training it 29696/76743 of epoch 4, 139.82 ms/it, loss 0.445596
Finished training it 29696/76743 of epoch 4, 139.85 ms/it, loss 0.448242
Finished training it 30720/76743 of epoch 4, 139.30 ms/it, loss 0.446172
Finished training it 30720/76743 of epoch 4, 139.23 ms/it, loss 0.445658
Finished training it 30720/76743 of epoch 4, 139.30 ms/it, loss 0.446689
Finished training it 30720/76743 of epoch 4, 139.30 ms/it, loss 0.447087
Testing at - 30720/76743 of epoch 4,
steps testing: 0.0steps testing: 0.06253908692933083steps testing: 0.12507817385866166steps testing: 0.18761726078799248steps testing: 0.2501563477173233steps testing: 0.31269543464665417steps testing: 0.37523452157598497steps testing: 0.4377736085053158steps testing: 0.5003126954346466steps testing: 0.5628517823639775steps testing: 0.6253908692933083steps testing: 0.6879299562226392steps testing: 0.7504690431519699steps testing: 0.8130081300813008steps testing: 0.8755472170106317steps testing: 0.9380863039399625Warning: Skipping the batch 3197 with size 602
rank: 0 test_accu: 2581190.0
get out
0 has test check 2581190.0 and sample count 3273728
 accuracy 78.846 %, best 78.846 %, roc auc score 0.8021, best 0.8021
Saving model to /home/yzhou/dlrm_criteo_kaggle/save_model_after_training_one1.0.pt
Finished training it 31744/76743 of epoch 4, 139.29 ms/it, loss 0.445001
Testing at - 30720/76743 of epoch 4,
Warning: Skipping the batch 3197 with size 602
rank: 2 test_accu: 2581190.0
get out
2 has test check 2581190.0 and sample count 3273728
Finished training it 31744/76743 of epoch 4, 139.34 ms/it, loss 0.447649
Testing at - 30720/76743 of epoch 4,
Warning: Skipping the batch 3197 with size 602
rank: 3 test_accu: 2581190.0
get out
3 has test check 2581190.0 and sample count 3273728
Finished training it 31744/76743 of epoch 4, 139.34 ms/it, loss 0.443509
Testing at - 30720/76743 of epoch 4,
Warning: Skipping the batch 3197 with size 602
rank: 1 test_accu: 2581190.0
get out
1 has test check 2581190.0 and sample count 3273728
Finished training it 31744/76743 of epoch 4, 139.36 ms/it, loss 0.443585
Finished training it 32768/76743 of epoch 4, 138.63 ms/it, loss 0.444839
Finished training it 32768/76743 of epoch 4, 138.70 ms/it, loss 0.446201
Finished training it 32768/76743 of epoch 4, 138.53 ms/it, loss 0.445299
Finished training it 32768/76743 of epoch 4, 138.63 ms/it, loss 0.443636
Finished training it 33792/76743 of epoch 4, 139.99 ms/it, loss 0.445636
Finished training it 33792/76743 of epoch 4, 139.99 ms/it, loss 0.445659
Finished training it 33792/76743 of epoch 4, 139.92 ms/it, loss 0.441239
Finished training it 33792/76743 of epoch 4, 140.06 ms/it, loss 0.441554
Finished training it 34816/76743 of epoch 4, 139.59 ms/it, loss 0.445258
Finished training it 34816/76743 of epoch 4, 139.61 ms/it, loss 0.446581
Finished training it 34816/76743 of epoch 4, 139.66 ms/it, loss 0.446894
Finished training it 34816/76743 of epoch 4, 139.67 ms/it, loss 0.446726
Finished training it 35840/76743 of epoch 4, 140.65 ms/it, loss 0.444938
Finished training it 35840/76743 of epoch 4, 140.67 ms/it, loss 0.445626
Finished training it 35840/76743 of epoch 4, 140.65 ms/it, loss 0.446665
Finished training it 35840/76743 of epoch 4, 140.67 ms/it, loss 0.444834
Finished training it 36864/76743 of epoch 4, 138.97 ms/it, loss 0.444219
Finished training it 36864/76743 of epoch 4, 138.87 ms/it, loss 0.444464
Finished training it 36864/76743 of epoch 4, 138.91 ms/it, loss 0.440968
Finished training it 36864/76743 of epoch 4, 138.92 ms/it, loss 0.441067
Finished training it 37888/76743 of epoch 4, 139.18 ms/it, loss 0.444785
Finished training it 37888/76743 of epoch 4, 139.14 ms/it, loss 0.440992
Finished training it 37888/76743 of epoch 4, 139.12 ms/it, loss 0.446538
Finished training it 37888/76743 of epoch 4, 139.16 ms/it, loss 0.446110
Finished training it 38912/76743 of epoch 4, 139.26 ms/it, loss 0.444948
Finished training it 38912/76743 of epoch 4, 139.24 ms/it, loss 0.443947
Finished training it 38912/76743 of epoch 4, 139.25 ms/it, loss 0.442473
Finished training it 38912/76743 of epoch 4, 139.16 ms/it, loss 0.446014
Finished training it 39936/76743 of epoch 4, 139.01 ms/it, loss 0.445121
Finished training it 39936/76743 of epoch 4, 138.98 ms/it, loss 0.444570
Finished training it 39936/76743 of epoch 4, 138.96 ms/it, loss 0.443825
Finished training it 39936/76743 of epoch 4, 138.96 ms/it, loss 0.445181
Finished training it 40960/76743 of epoch 4, 139.49 ms/it, loss 0.445153
Finished training it 40960/76743 of epoch 4, 139.45 ms/it, loss 0.443025
Finished training it 40960/76743 of epoch 4, 139.46 ms/it, loss 0.443909
Finished training it 40960/76743 of epoch 4, 139.48 ms/it, loss 0.444021
Testing at - 40960/76743 of epoch 4,
steps testing: 0.0steps testing: 0.06253908692933083steps testing: 0.12507817385866166steps testing: 0.18761726078799248steps testing: 0.2501563477173233steps testing: 0.31269543464665417steps testing: 0.37523452157598497steps testing: 0.4377736085053158steps testing: 0.5003126954346466steps testing: 0.5628517823639775steps testing: 0.6253908692933083steps testing: 0.6879299562226392steps testing: 0.7504690431519699steps testing: 0.8130081300813008steps testing: 0.8755472170106317steps testing: 0.9380863039399625Warning: Skipping the batch 3197 with size 602
rank: 0 test_accu: 2571972.0
get out
0 has test check 2571972.0 and sample count 3273728
 accuracy 78.564 %, best 78.846 %, roc auc score 0.8018, best 0.8021
Testing at - 40960/76743 of epoch 4,
Warning: Skipping the batch 3197 with size 602
rank: 3 test_accu: 2571972.0
get out
3 has test check 2571972.0 and sample count 3273728
Finished training it 41984/76743 of epoch 4, 140.12 ms/it, loss 0.445632
Saving model to /home/yzhou/dlrm_criteo_kaggle/save_model_after_training_one0.0.pt
Finished training it 41984/76743 of epoch 4, 140.05 ms/it, loss 0.446105
Testing at - 40960/76743 of epoch 4,
Warning: Skipping the batch 3197 with size 602
rank: 2 test_accu: 2571972.0
get out
2 has test check 2571972.0 and sample count 3273728
Finished training it 41984/76743 of epoch 4, 140.10 ms/it, loss 0.443802
Testing at - 40960/76743 of epoch 4,
Warning: Skipping the batch 3197 with size 602
rank: 1 test_accu: 2571972.0
get out
1 has test check 2571972.0 and sample count 3273728
Finished training it 41984/76743 of epoch 4, 140.16 ms/it, loss 0.443701
Finished training it 43008/76743 of epoch 4, 140.35 ms/it, loss 0.445404
Finished training it 43008/76743 of epoch 4, 140.34 ms/it, loss 0.443522
Finished training it 43008/76743 of epoch 4, 140.36 ms/it, loss 0.445527
Finished training it 43008/76743 of epoch 4, 140.39 ms/it, loss 0.442112
Finished training it 44032/76743 of epoch 4, 140.18 ms/it, loss 0.442921
Finished training it 44032/76743 of epoch 4, 140.24 ms/it, loss 0.444966
Finished training it 44032/76743 of epoch 4, 140.28 ms/it, loss 0.443689
Finished training it 44032/76743 of epoch 4, 140.29 ms/it, loss 0.446099
Finished training it 45056/76743 of epoch 4, 140.28 ms/it, loss 0.443225
Finished training it 45056/76743 of epoch 4, 140.30 ms/it, loss 0.445477
Finished training it 45056/76743 of epoch 4, 140.26 ms/it, loss 0.442453
Finished training it 45056/76743 of epoch 4, 140.27 ms/it, loss 0.445654
Finished training it 46080/76743 of epoch 4, 140.08 ms/it, loss 0.442379
Finished training it 46080/76743 of epoch 4, 140.05 ms/it, loss 0.445268
Finished training it 46080/76743 of epoch 4, 140.13 ms/it, loss 0.443228
Finished training it 46080/76743 of epoch 4, 140.09 ms/it, loss 0.441003
Finished training it 47104/76743 of epoch 4, 140.87 ms/it, loss 0.444865
Finished training it 47104/76743 of epoch 4, 140.93 ms/it, loss 0.445047
Finished training it 47104/76743 of epoch 4, 140.90 ms/it, loss 0.443674
Finished training it 47104/76743 of epoch 4, 140.91 ms/it, loss 0.442438
Finished training it 48128/76743 of epoch 4, 140.31 ms/it, loss 0.442638
Finished training it 48128/76743 of epoch 4, 140.45 ms/it, loss 0.446245
Finished training it 48128/76743 of epoch 4, 140.42 ms/it, loss 0.444119
Finished training it 48128/76743 of epoch 4, 140.44 ms/it, loss 0.443812
Finished training it 49152/76743 of epoch 4, 140.27 ms/it, loss 0.442683
Finished training it 49152/76743 of epoch 4, 140.18 ms/it, loss 0.443472
Finished training it 49152/76743 of epoch 4, 140.18 ms/it, loss 0.444783
Finished training it 49152/76743 of epoch 4, 140.28 ms/it, loss 0.444390
Finished training it 50176/76743 of epoch 4, 139.76 ms/it, loss 0.444659
Finished training it 50176/76743 of epoch 4, 139.70 ms/it, loss 0.445856
Finished training it 50176/76743 of epoch 4, 139.80 ms/it, loss 0.445581
Finished training it 50176/76743 of epoch 4, 139.76 ms/it, loss 0.444929
Finished training it 51200/76743 of epoch 4, 139.31 ms/it, loss 0.442244
Finished training it 51200/76743 of epoch 4, 139.24 ms/it, loss 0.443728
Finished training it 51200/76743 of epoch 4, 139.21 ms/it, loss 0.445487
Finished training it 51200/76743 of epoch 4, 139.25 ms/it, loss 0.445129
Testing at - 51200/76743 of epoch 4,
steps testing: 0.0steps testing: 0.06253908692933083steps testing: 0.12507817385866166steps testing: 0.18761726078799248steps testing: 0.2501563477173233steps testing: 0.31269543464665417steps testing: 0.37523452157598497steps testing: 0.4377736085053158steps testing: 0.5003126954346466steps testing: 0.5628517823639775steps testing: 0.6253908692933083steps testing: 0.6879299562226392steps testing: 0.7504690431519699steps testing: 0.8130081300813008steps testing: 0.8755472170106317steps testing: 0.9380863039399625Warning: Skipping the batch 3197 with size 602
rank: 0 test_accu: 2579961.0
get out
0 has test check 2579961.0 and sample count 3273728
 accuracy 78.808 %, best 78.846 %, roc auc score 0.8016, best 0.8021
Testing at - 51200/76743 of epoch 4,
Warning: Skipping the batch 3197 with size 602
rank: 3 test_accu: 2579961.0
get out
3 has test check 2579961.0 and sample count 3273728
Finished training it 52224/76743 of epoch 4, 140.38 ms/it, loss 0.443501
Testing at - 51200/76743 of epoch 4,
Warning: Skipping the batch 3197 with size 602
rank: 1 test_accu: 2579961.0
get out
1 has test check 2579961.0 and sample count 3273728
Finished training it 52224/76743 of epoch 4, 140.38 ms/it, loss 0.446064
Saving model to /home/yzhou/dlrm_criteo_kaggle/save_model_after_training_one1.0.pt
Finished training it 52224/76743 of epoch 4, 140.26 ms/it, loss 0.445216
Testing at - 51200/76743 of epoch 4,
Warning: Skipping the batch 3197 with size 602
rank: 2 test_accu: 2579961.0
get out
2 has test check 2579961.0 and sample count 3273728
Finished training it 52224/76743 of epoch 4, 140.30 ms/it, loss 0.444361
Finished training it 53248/76743 of epoch 4, 139.67 ms/it, loss 0.447235
Finished training it 53248/76743 of epoch 4, 139.61 ms/it, loss 0.445107
Finished training it 53248/76743 of epoch 4, 139.69 ms/it, loss 0.441663
Finished training it 53248/76743 of epoch 4, 139.70 ms/it, loss 0.443489
Finished training it 54272/76743 of epoch 4, 140.69 ms/it, loss 0.444438
Finished training it 54272/76743 of epoch 4, 140.69 ms/it, loss 0.445986
Finished training it 54272/76743 of epoch 4, 140.69 ms/it, loss 0.443274
Finished training it 54272/76743 of epoch 4, 140.74 ms/it, loss 0.441830
Finished training it 55296/76743 of epoch 4, 141.07 ms/it, loss 0.444973
Finished training it 55296/76743 of epoch 4, 141.11 ms/it, loss 0.445025
Finished training it 55296/76743 of epoch 4, 141.13 ms/it, loss 0.444182
Finished training it 55296/76743 of epoch 4, 141.13 ms/it, loss 0.443987
Finished training it 56320/76743 of epoch 4, 139.99 ms/it, loss 0.442237
Finished training it 56320/76743 of epoch 4, 140.01 ms/it, loss 0.443617
Finished training it 56320/76743 of epoch 4, 140.11 ms/it, loss 0.444188
Finished training it 56320/76743 of epoch 4, 140.01 ms/it, loss 0.444996
Finished training it 57344/76743 of epoch 4, 139.85 ms/it, loss 0.445675
Finished training it 57344/76743 of epoch 4, 139.82 ms/it, loss 0.442218
Finished training it 57344/76743 of epoch 4, 139.91 ms/it, loss 0.446408
Finished training it 57344/76743 of epoch 4, 139.89 ms/it, loss 0.444427
Finished training it 58368/76743 of epoch 4, 139.47 ms/it, loss 0.444244
Finished training it 58368/76743 of epoch 4, 139.36 ms/it, loss 0.445867
Finished training it 58368/76743 of epoch 4, 139.40 ms/it, loss 0.445089
Finished training it 58368/76743 of epoch 4, 139.39 ms/it, loss 0.447134
Finished training it 59392/76743 of epoch 4, 139.58 ms/it, loss 0.440991
Finished training it 59392/76743 of epoch 4, 139.58 ms/it, loss 0.440136
Finished training it 59392/76743 of epoch 4, 139.54 ms/it, loss 0.441744
Finished training it 59392/76743 of epoch 4, 139.53 ms/it, loss 0.443572
Finished training it 60416/76743 of epoch 4, 140.43 ms/it, loss 0.443371
Finished training it 60416/76743 of epoch 4, 140.41 ms/it, loss 0.444146
Finished training it 60416/76743 of epoch 4, 140.34 ms/it, loss 0.443433
Finished training it 60416/76743 of epoch 4, 140.55 ms/it, loss 0.445746
Finished training it 61440/76743 of epoch 4, 138.92 ms/it, loss 0.442897
Finished training it 61440/76743 of epoch 4, 138.92 ms/it, loss 0.441909
Finished training it 61440/76743 of epoch 4, 138.95 ms/it, loss 0.446327
Finished training it 61440/76743 of epoch 4, 139.00 ms/it, loss 0.444712
Testing at - 61440/76743 of epoch 4,
steps testing: 0.0steps testing: 0.06253908692933083steps testing: 0.12507817385866166steps testing: 0.18761726078799248steps testing: 0.2501563477173233steps testing: 0.31269543464665417steps testing: 0.37523452157598497steps testing: 0.4377736085053158steps testing: 0.5003126954346466steps testing: 0.5628517823639775steps testing: 0.6253908692933083steps testing: 0.6879299562226392steps testing: 0.7504690431519699steps testing: 0.8130081300813008steps testing: 0.8755472170106317steps testing: 0.9380863039399625Warning: Skipping the batch 3197 with size 602
rank: 0 test_accu: 2581953.0
get out
0 has test check 2581953.0 and sample count 3273728
 accuracy 78.869 %, best 78.869 %, roc auc score 0.8026, best 0.8026
Saving model to /home/yzhou/dlrm_criteo_kaggle/save_model_after_training_one0.0.pt
Finished training it 62464/76743 of epoch 4, 139.09 ms/it, loss 0.440135
Testing at - 61440/76743 of epoch 4,
Warning: Skipping the batch 3197 with size 602
rank: 2 test_accu: 2581953.0
get out
2 has test check 2581953.0 and sample count 3273728
Finished training it 62464/76743 of epoch 4, 139.04 ms/it, loss 0.443985
Testing at - 61440/76743 of epoch 4,
Warning: Skipping the batch 3197 with size 602
rank: 3 test_accu: 2581953.0
get out
3 has test check 2581953.0 and sample count 3273728
Finished training it 62464/76743 of epoch 4, 139.00 ms/it, loss 0.444799
Testing at - 61440/76743 of epoch 4,
Warning: Skipping the batch 3197 with size 602
rank: 1 test_accu: 2581953.0
get out
1 has test check 2581953.0 and sample count 3273728
Finished training it 62464/76743 of epoch 4, 139.04 ms/it, loss 0.442318
Finished training it 63488/76743 of epoch 4, 139.83 ms/it, loss 0.444328
Finished training it 63488/76743 of epoch 4, 139.85 ms/it, loss 0.442838
Finished training it 63488/76743 of epoch 4, 139.84 ms/it, loss 0.443432
Finished training it 63488/76743 of epoch 4, 139.80 ms/it, loss 0.444564
Finished training it 64512/76743 of epoch 4, 139.28 ms/it, loss 0.442859
Finished training it 64512/76743 of epoch 4, 139.25 ms/it, loss 0.445195
Finished training it 64512/76743 of epoch 4, 139.34 ms/it, loss 0.443902
Finished training it 64512/76743 of epoch 4, 139.32 ms/it, loss 0.441662
Finished training it 65536/76743 of epoch 4, 139.21 ms/it, loss 0.445319
Finished training it 65536/76743 of epoch 4, 139.16 ms/it, loss 0.443300
Finished training it 65536/76743 of epoch 4, 139.20 ms/it, loss 0.444037
Finished training it 65536/76743 of epoch 4, 139.22 ms/it, loss 0.445964
Finished training it 66560/76743 of epoch 4, 139.21 ms/it, loss 0.442569
Finished training it 66560/76743 of epoch 4, 139.21 ms/it, loss 0.445465
Finished training it 66560/76743 of epoch 4, 139.20 ms/it, loss 0.442258
Finished training it 66560/76743 of epoch 4, 139.29 ms/it, loss 0.445939
Finished training it 67584/76743 of epoch 4, 140.16 ms/it, loss 0.444537
Finished training it 67584/76743 of epoch 4, 140.16 ms/it, loss 0.447880
Finished training it 67584/76743 of epoch 4, 140.07 ms/it, loss 0.444538
Finished training it 67584/76743 of epoch 4, 140.07 ms/it, loss 0.440867
Finished training it 68608/76743 of epoch 4, 139.00 ms/it, loss 0.444577
Finished training it 68608/76743 of epoch 4, 138.91 ms/it, loss 0.444407
Finished training it 68608/76743 of epoch 4, 138.98 ms/it, loss 0.442020
Finished training it 68608/76743 of epoch 4, 138.96 ms/it, loss 0.444495
Finished training it 69632/76743 of epoch 4, 139.56 ms/it, loss 0.447691
Finished training it 69632/76743 of epoch 4, 139.52 ms/it, loss 0.445442
Finished training it 69632/76743 of epoch 4, 139.51 ms/it, loss 0.443605
Finished training it 69632/76743 of epoch 4, 139.56 ms/it, loss 0.445166
Finished training it 70656/76743 of epoch 4, 139.86 ms/it, loss 0.443893
Finished training it 70656/76743 of epoch 4, 139.86 ms/it, loss 0.446316
Finished training it 70656/76743 of epoch 4, 139.81 ms/it, loss 0.442072
Finished training it 70656/76743 of epoch 4, 139.86 ms/it, loss 0.442247
Finished training it 71680/76743 of epoch 4, 143.00 ms/it, loss 0.443678
Finished training it 71680/76743 of epoch 4, 143.04 ms/it, loss 0.444790
Finished training it 71680/76743 of epoch 4, 143.01 ms/it, loss 0.445392
Finished training it 71680/76743 of epoch 4, 143.09 ms/it, loss 0.445302
Testing at - 71680/76743 of epoch 4,
steps testing: 0.0steps testing: 0.06253908692933083steps testing: 0.12507817385866166steps testing: 0.18761726078799248steps testing: 0.2501563477173233steps testing: 0.31269543464665417steps testing: 0.37523452157598497steps testing: 0.4377736085053158steps testing: 0.5003126954346466steps testing: 0.5628517823639775steps testing: 0.6253908692933083steps testing: 0.6879299562226392steps testing: 0.7504690431519699steps testing: 0.8130081300813008steps testing: 0.8755472170106317steps testing: 0.9380863039399625Warning: Skipping the batch 3197 with size 602
rank: 0 test_accu: 2579478.0
get out
0 has test check 2579478.0 and sample count 3273728
 accuracy 78.793 %, best 78.869 %, roc auc score 0.8024, best 0.8026
Testing at - 71680/76743 of epoch 4,
Warning: Skipping the batch 3197 with size 602
rank: 3 test_accu: 2579478.0
get out
3 has test check 2579478.0 and sample count 3273728
Finished training it 72704/76743 of epoch 4, 140.61 ms/it, loss 0.442569
Saving model to /home/yzhou/dlrm_criteo_kaggle/save_model_after_training_one1.0.pt
Finished training it 72704/76743 of epoch 4, 140.58 ms/it, loss 0.444897
Testing at - 71680/76743 of epoch 4,
Warning: Skipping the batch 3197 with size 602
rank: 1 test_accu: 2579478.0
get out
1 has test check 2579478.0 and sample count 3273728
Finished training it 72704/76743 of epoch 4, 140.66 ms/it, loss 0.445320
Testing at - 71680/76743 of epoch 4,
Warning: Skipping the batch 3197 with size 602
rank: 2 test_accu: 2579478.0
get out
2 has test check 2579478.0 and sample count 3273728
Finished training it 72704/76743 of epoch 4, 140.66 ms/it, loss 0.442355
Finished training it 73728/76743 of epoch 4, 139.48 ms/it, loss 0.444274
Finished training it 73728/76743 of epoch 4, 139.45 ms/it, loss 0.444640
Finished training it 73728/76743 of epoch 4, 139.48 ms/it, loss 0.442562
Finished training it 73728/76743 of epoch 4, 139.46 ms/it, loss 0.442628
Finished training it 74752/76743 of epoch 4, 139.60 ms/it, loss 0.442879
Finished training it 74752/76743 of epoch 4, 139.59 ms/it, loss 0.444929
Finished training it 74752/76743 of epoch 4, 139.63 ms/it, loss 0.444228
Finished training it 74752/76743 of epoch 4, 139.58 ms/it, loss 0.443708
Finished training it 75776/76743 of epoch 4, 139.63 ms/it, loss 0.442921
Finished training it 75776/76743 of epoch 4, 139.61 ms/it, loss 0.441893
Finished training it 75776/76743 of epoch 4, 139.63 ms/it, loss 0.445312
Finished training it 75776/76743 of epoch 4, 139.68 ms/it, loss 0.444536
Warning: Skipping the batch 76742 with size 14
Testing at - 76743/76743 of epoch 5,
steps testing: 0.0steps testing: 0.06253908692933083steps testing: 0.12507817385866166steps testing: 0.18761726078799248steps testing: 0.2501563477173233steps testing: 0.31269543464665417steps testing: 0.37523452157598497steps testing: 0.4377736085053158steps testing: 0.5003126954346466steps testing: 0.5628517823639775steps testing: 0.6253908692933083steps testing: 0.6879299562226392steps testing: 0.7504690431519699steps testing: 0.8130081300813008steps testing: 0.8755472170106317steps testing: 0.9380863039399625Warning: Skipping the batch 3197 with size 602
rank: 0 test_accu: 2580885.0
get out
0 has test check 2580885.0 and sample count 3273728
 accuracy 78.836 %, best 78.869 %, roc auc score 0.8027, best 0.8027
Warning: Skipping the batch 76742 with size 14
Testing at - 76743/76743 of epoch 5,
Warning: Skipping the batch 3197 with size 602
rank: 2 test_accu: 2580885.0
get out
2 has test check 2580885.0 and sample count 3273728
Warning: Skipping the batch 76742 with size 14
Testing at - 76743/76743 of epoch 5,
Warning: Skipping the batch 3197 with size 602
rank: 1 test_accu: 2580885.0
get out
1 has test check 2580885.0 and sample count 3273728
Warning: Skipping the batch 76742 with size 14
Testing at - 76743/76743 of epoch 5,
Warning: Skipping the batch 3197 with size 602
rank: 3 test_accu: 2580885.0
get out
3 has test check 2580885.0 and sample count 3273728
