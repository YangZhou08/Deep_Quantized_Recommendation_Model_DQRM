Unable to import mlperf_logging,  No module named 'mlperf_logging'
Unable to import mlperf_logging,  No module named 'mlperf_logging'
Warning: local_rank gpu mismatch
2 out of -1 (GPU)
Reading pre-processed data=/rscratch/data/dlrm_criteo/kaggleAdDisplayChallenge_processed.npz
Sparse fea = 26, Dense fea = 13
Defined train indices...
Randomized indices across days ...
Split data according to indices...
Reading pre-processed data=/rscratch/data/dlrm_criteo/kaggleAdDisplayChallenge_processed.npz
Sparse fea = 26, Dense fea = 13
Defined test indices...
Randomized indices across days ...
Split data according to indices...
number of devices 1
world size found is -1
---------- Embedding Table 0, quantization used, quantization bit set to 8
---------- Embedding Table 1, quantization used, quantization bit set to 8
---------- Embedding Table 2, quantization used, quantization bit set to 8
---------- Embedding Table 3, quantization used, quantization bit set to 8
---------- Embedding Table 4, quantization used, quantization bit set to 8
---------- Embedding Table 5, quantization used, quantization bit set to 8
---------- Embedding Table 6, quantization used, quantization bit set to 8
---------- Embedding Table 7, quantization used, quantization bit set to 8
---------- Embedding Table 8, quantization used, quantization bit set to 8
---------- Embedding Table 9, quantization used, quantization bit set to 8
---------- Embedding Table 10, quantization used, quantization bit set to 8
---------- Embedding Table 11, quantization used, quantization bit set to 8
---------- Embedding Table 12, quantization used, quantization bit set to 8
---------- Embedding Table 13, quantization used, quantization bit set to 8
---------- Embedding Table 14, quantization used, quantization bit set to 8
---------- Embedding Table 15, quantization used, quantization bit set to 8
---------- Embedding Table 16, quantization used, quantization bit set to 8
---------- Embedding Table 17, quantization used, quantization bit set to 8
---------- Embedding Table 18, quantization used, quantization bit set to 8
---------- Embedding Table 19, quantization used, quantization bit set to 8
---------- Embedding Table 20, quantization used, quantization bit set to 8
---------- Embedding Table 21, quantization used, quantization bit set to 8
---------- Embedding Table 22, quantization used, quantization bit set to 8
---------- Embedding Table 23, quantization used, quantization bit set to 8
---------- Embedding Table 24, quantization used, quantization bit set to 8
---------- Embedding Table 25, quantization used, quantization bit set to 8
optimizer selected is  sgd
Finished training it 1024/153485 of epoch 0, 55.31 ms/it, loss 0.520948
Unable to import mlperf_logging,  No module named 'mlperf_logging'
Warning: local_rank gpu mismatch
2 out of -1 (GPU)
Reading pre-processed data=/rscratch/data/dlrm_criteo/kaggleAdDisplayChallenge_processed.npz
Sparse fea = 26, Dense fea = 13
Defined train indices...
Randomized indices across days ...
Split data according to indices...
Reading pre-processed data=/rscratch/data/dlrm_criteo/kaggleAdDisplayChallenge_processed.npz
Sparse fea = 26, Dense fea = 13
Defined test indices...
Randomized indices across days ...
Split data according to indices...
number of devices 1
world size found is -1
---------- Embedding Table 0, quantization used, quantization bit set to 8
---------- Embedding Table 1, quantization used, quantization bit set to 8
---------- Embedding Table 2, quantization used, quantization bit set to 8
---------- Embedding Table 3, quantization used, quantization bit set to 8
---------- Embedding Table 4, quantization used, quantization bit set to 8
---------- Embedding Table 5, quantization used, quantization bit set to 8
---------- Embedding Table 6, quantization used, quantization bit set to 8
---------- Embedding Table 7, quantization used, quantization bit set to 8
---------- Embedding Table 8, quantization used, quantization bit set to 8
---------- Embedding Table 9, quantization used, quantization bit set to 8
---------- Embedding Table 10, quantization used, quantization bit set to 8
---------- Embedding Table 11, quantization used, quantization bit set to 8
---------- Embedding Table 12, quantization used, quantization bit set to 8
---------- Embedding Table 13, quantization used, quantization bit set to 8
---------- Embedding Table 14, quantization used, quantization bit set to 8
---------- Embedding Table 15, quantization used, quantization bit set to 8
---------- Embedding Table 16, quantization used, quantization bit set to 8
---------- Embedding Table 17, quantization used, quantization bit set to 8
---------- Embedding Table 18, quantization used, quantization bit set to 8
---------- Embedding Table 19, quantization used, quantization bit set to 8
---------- Embedding Table 20, quantization used, quantization bit set to 8
---------- Embedding Table 21, quantization used, quantization bit set to 8
---------- Embedding Table 22, quantization used, quantization bit set to 8
---------- Embedding Table 23, quantization used, quantization bit set to 8
---------- Embedding Table 24, quantization used, quantization bit set to 8
---------- Embedding Table 25, quantization used, quantization bit set to 8
optimizer selected is  sgd
Finished training it 1024/153485 of epoch 0, 53.68 ms/it, loss 0.524323
Finished training it 2048/153485 of epoch 0, 47.27 ms/it, loss 0.515466
Finished training it 2048/153485 of epoch 0, 46.92 ms/it, loss 0.513168
Finished training it 3072/153485 of epoch 0, 47.09 ms/it, loss 0.509819
Finished training it 3072/153485 of epoch 0, 46.80 ms/it, loss 0.512112
Finished training it 4096/153485 of epoch 0, 47.02 ms/it, loss 0.511166
Finished training it 4096/153485 of epoch 0, 46.83 ms/it, loss 0.509639
Finished training it 5120/153485 of epoch 0, 46.78 ms/it, loss 0.512966
Finished training it 5120/153485 of epoch 0, 46.91 ms/it, loss 0.511564
Finished training it 6144/153485 of epoch 0, 47.06 ms/it, loss 0.510157
Finished training it 6144/153485 of epoch 0, 47.15 ms/it, loss 0.512102
Finished training it 7168/153485 of epoch 0, 47.23 ms/it, loss 0.509629
Finished training it 7168/153485 of epoch 0, 47.39 ms/it, loss 0.510577
Finished training it 8192/153485 of epoch 0, 48.26 ms/it, loss 0.509402
Finished training it 8192/153485 of epoch 0, 48.30 ms/it, loss 0.507747
Finished training it 9216/153485 of epoch 0, 47.22 ms/it, loss 0.505640
Finished training it 9216/153485 of epoch 0, 47.28 ms/it, loss 0.508327
Finished training it 10240/153485 of epoch 0, 47.78 ms/it, loss 0.506823
Finished training it 10240/153485 of epoch 0, 48.20 ms/it, loss 0.508148
Testing at - 10240/153485 of epoch 0,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216rank: 0 test_accu: 2482891.0
get out
0 has test check 2482891.0 and sample count 3274330
 accuracy 75.829 %, best 75.829 %, roc auc score 0.7252, best 0.7252
Saving model to /rscratch/data/dlrm_criteo/save_model_after_training_one1.0.pt
Finished training it 11264/153485 of epoch 0, 48.16 ms/it, loss 0.505028
Testing at - 10240/153485 of epoch 0,
rank: 1 test_accu: 2482891.0
get out
1 has test check 2482891.0 and sample count 3274330
Finished training it 11264/153485 of epoch 0, 48.21 ms/it, loss 0.505241
Finished training it 12288/153485 of epoch 0, 48.10 ms/it, loss 0.503453
Finished training it 12288/153485 of epoch 0, 49.37 ms/it, loss 0.506324
Finished training it 13312/153485 of epoch 0, 47.94 ms/it, loss 0.503807
Finished training it 13312/153485 of epoch 0, 49.24 ms/it, loss 0.500708
Finished training it 14336/153485 of epoch 0, 49.76 ms/it, loss 0.503607
Finished training it 14336/153485 of epoch 0, 48.69 ms/it, loss 0.504397
Finished training it 15360/153485 of epoch 0, 60.23 ms/it, loss 0.505301
Finished training it 15360/153485 of epoch 0, 60.08 ms/it, loss 0.504666
Finished training it 16384/153485 of epoch 0, 47.47 ms/it, loss 0.500395
Finished training it 16384/153485 of epoch 0, 47.72 ms/it, loss 0.504168
Finished training it 17408/153485 of epoch 0, 48.66 ms/it, loss 0.498063
Finished training it 17408/153485 of epoch 0, 48.37 ms/it, loss 0.503468
Finished training it 18432/153485 of epoch 0, 52.37 ms/it, loss 0.499084
Finished training it 18432/153485 of epoch 0, 51.87 ms/it, loss 0.501762
Finished training it 19456/153485 of epoch 0, 51.18 ms/it, loss 0.500651
Finished training it 19456/153485 of epoch 0, 51.93 ms/it, loss 0.500405
Finished training it 20480/153485 of epoch 0, 51.65 ms/it, loss 0.501078
Finished training it 20480/153485 of epoch 0, 51.23 ms/it, loss 0.501095
Testing at - 20480/153485 of epoch 0,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216rank: 0 test_accu: 2492300.0
get out
0 has test check 2492300.0 and sample count 3274330
 accuracy 76.116 %, best 76.116 %, roc auc score 0.7344, best 0.7344
Testing at - 20480/153485 of epoch 0,
rank: 1 test_accu: 2492300.0
get out
1 has test check 2492300.0 and sample count 3274330
Finished training it 21504/153485 of epoch 0, 49.28 ms/it, loss 0.501732
Saving model to /rscratch/data/dlrm_criteo/save_model_after_training_one0.0.pt
Finished training it 21504/153485 of epoch 0, 47.85 ms/it, loss 0.499111
Finished training it 22528/153485 of epoch 0, 48.28 ms/it, loss 0.499386
Finished training it 22528/153485 of epoch 0, 48.62 ms/it, loss 0.499664
Finished training it 23552/153485 of epoch 0, 49.15 ms/it, loss 0.497202
Finished training it 23552/153485 of epoch 0, 49.16 ms/it, loss 0.501739
Finished training it 24576/153485 of epoch 0, 49.14 ms/it, loss 0.500029
Finished training it 24576/153485 of epoch 0, 49.26 ms/it, loss 0.500238
Finished training it 25600/153485 of epoch 0, 48.51 ms/it, loss 0.501385
Finished training it 25600/153485 of epoch 0, 48.34 ms/it, loss 0.500086
Finished training it 26624/153485 of epoch 0, 48.54 ms/it, loss 0.499088
Finished training it 26624/153485 of epoch 0, 48.68 ms/it, loss 0.498650
Finished training it 27648/153485 of epoch 0, 50.05 ms/it, loss 0.501750
Finished training it 27648/153485 of epoch 0, 50.07 ms/it, loss 0.495939
Finished training it 28672/153485 of epoch 0, 48.73 ms/it, loss 0.494524
Finished training it 28672/153485 of epoch 0, 48.72 ms/it, loss 0.497673
Finished training it 29696/153485 of epoch 0, 51.71 ms/it, loss 0.499304
Finished training it 29696/153485 of epoch 0, 50.97 ms/it, loss 0.495992
Finished training it 30720/153485 of epoch 0, 51.87 ms/it, loss 0.498691
Finished training it 30720/153485 of epoch 0, 51.22 ms/it, loss 0.496809
Testing at - 30720/153485 of epoch 0,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216rank: 0 test_accu: 2500768.0
get out
0 has test check 2500768.0 and sample count 3274330
 accuracy 76.375 %, best 76.375 %, roc auc score 0.7404, best 0.7404
Testing at - 30720/153485 of epoch 0,
rank: 1 test_accu: 2500768.0
get out
1 has test check 2500768.0 and sample count 3274330
Finished training it 31744/153485 of epoch 0, 50.31 ms/it, loss 0.495944
Saving model to /rscratch/data/dlrm_criteo/save_model_after_training_one1.0.pt
Finished training it 31744/153485 of epoch 0, 49.23 ms/it, loss 0.496522
Finished training it 32768/153485 of epoch 0, 50.56 ms/it, loss 0.496490
Finished training it 32768/153485 of epoch 0, 49.99 ms/it, loss 0.497409
Finished training it 33792/153485 of epoch 0, 48.94 ms/it, loss 0.498235
Finished training it 33792/153485 of epoch 0, 49.18 ms/it, loss 0.493633
Finished training it 34816/153485 of epoch 0, 54.90 ms/it, loss 0.497329
Finished training it 34816/153485 of epoch 0, 54.40 ms/it, loss 0.496175
Finished training it 35840/153485 of epoch 0, 54.90 ms/it, loss 0.496866
Finished training it 35840/153485 of epoch 0, 54.74 ms/it, loss 0.492577
Finished training it 36864/153485 of epoch 0, 50.95 ms/it, loss 0.494123
Finished training it 36864/153485 of epoch 0, 50.66 ms/it, loss 0.495868
Finished training it 37888/153485 of epoch 0, 51.91 ms/it, loss 0.496154
Finished training it 37888/153485 of epoch 0, 51.41 ms/it, loss 0.495706
Finished training it 38912/153485 of epoch 0, 51.19 ms/it, loss 0.493999
Finished training it 38912/153485 of epoch 0, 51.64 ms/it, loss 0.495747
Finished training it 39936/153485 of epoch 0, 51.49 ms/it, loss 0.495040
Finished training it 39936/153485 of epoch 0, 50.95 ms/it, loss 0.495834
Finished training it 40960/153485 of epoch 0, 48.38 ms/it, loss 0.494664
Finished training it 40960/153485 of epoch 0, 48.68 ms/it, loss 0.495899
Testing at - 40960/153485 of epoch 0,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216rank: 0 test_accu: 2505168.0
get out
0 has test check 2505168.0 and sample count 3274330
 accuracy 76.509 %, best 76.509 %, roc auc score 0.7438, best 0.7438
Testing at - 40960/153485 of epoch 0,
rank: 1 test_accu: 2505168.0
get out
1 has test check 2505168.0 and sample count 3274330
Finished training it 41984/153485 of epoch 0, 52.07 ms/it, loss 0.492381
Saving model to /rscratch/data/dlrm_criteo/save_model_after_training_one0.0.pt
Finished training it 41984/153485 of epoch 0, 50.06 ms/it, loss 0.492855
Finished training it 43008/153485 of epoch 0, 50.57 ms/it, loss 0.490761
Finished training it 43008/153485 of epoch 0, 52.42 ms/it, loss 0.492603
Finished training it 44032/153485 of epoch 0, 51.60 ms/it, loss 0.492802
Finished training it 44032/153485 of epoch 0, 52.36 ms/it, loss 0.493448
Finished training it 45056/153485 of epoch 0, 51.52 ms/it, loss 0.493863
Finished training it 45056/153485 of epoch 0, 52.02 ms/it, loss 0.494864
Finished training it 46080/153485 of epoch 0, 49.75 ms/it, loss 0.493719
Finished training it 46080/153485 of epoch 0, 49.43 ms/it, loss 0.493327
Finished training it 47104/153485 of epoch 0, 50.47 ms/it, loss 0.493439
Finished training it 47104/153485 of epoch 0, 50.58 ms/it, loss 0.492204
Finished training it 48128/153485 of epoch 0, 48.38 ms/it, loss 0.490547
Finished training it 48128/153485 of epoch 0, 47.94 ms/it, loss 0.491655
Finished training it 49152/153485 of epoch 0, 47.40 ms/it, loss 0.492074
Finished training it 49152/153485 of epoch 0, 47.16 ms/it, loss 0.492342
Finished training it 50176/153485 of epoch 0, 47.83 ms/it, loss 0.492460
Finished training it 50176/153485 of epoch 0, 47.34 ms/it, loss 0.494574
Finished training it 51200/153485 of epoch 0, 47.87 ms/it, loss 0.492849
Finished training it 51200/153485 of epoch 0, 47.60 ms/it, loss 0.490415
Testing at - 51200/153485 of epoch 0,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216rank: 0 test_accu: 2509150.0
get out
0 has test check 2509150.0 and sample count 3274330
 accuracy 76.631 %, best 76.631 %, roc auc score 0.7471, best 0.7471
Saving model to /rscratch/data/dlrm_criteo/save_model_after_training_one1.0.pt
Finished training it 52224/153485 of epoch 0, 48.25 ms/it, loss 0.492594
Testing at - 51200/153485 of epoch 0,
rank: 1 test_accu: 2509150.0
get out
1 has test check 2509150.0 and sample count 3274330
Finished training it 52224/153485 of epoch 0, 49.14 ms/it, loss 0.492280
Finished training it 53248/153485 of epoch 0, 47.54 ms/it, loss 0.493550
Finished training it 53248/153485 of epoch 0, 47.21 ms/it, loss 0.490984
Finished training it 54272/153485 of epoch 0, 48.78 ms/it, loss 0.490373
Finished training it 54272/153485 of epoch 0, 49.09 ms/it, loss 0.491060
Finished training it 55296/153485 of epoch 0, 58.65 ms/it, loss 0.489010
Finished training it 55296/153485 of epoch 0, 58.42 ms/it, loss 0.491612
Finished training it 56320/153485 of epoch 0, 48.26 ms/it, loss 0.493804
Finished training it 56320/153485 of epoch 0, 48.91 ms/it, loss 0.490414
Finished training it 57344/153485 of epoch 0, 47.51 ms/it, loss 0.492858
Finished training it 57344/153485 of epoch 0, 47.84 ms/it, loss 0.490844
Finished training it 58368/153485 of epoch 0, 48.27 ms/it, loss 0.491413
Finished training it 58368/153485 of epoch 0, 48.24 ms/it, loss 0.490038
Finished training it 59392/153485 of epoch 0, 47.81 ms/it, loss 0.489259
Finished training it 59392/153485 of epoch 0, 47.36 ms/it, loss 0.490765
Finished training it 60416/153485 of epoch 0, 48.67 ms/it, loss 0.491475
Finished training it 60416/153485 of epoch 0, 48.14 ms/it, loss 0.491343
Finished training it 61440/153485 of epoch 0, 48.14 ms/it, loss 0.491465
Finished training it 61440/153485 of epoch 0, 47.81 ms/it, loss 0.488804
Testing at - 61440/153485 of epoch 0,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216rank: 0 test_accu: 2511456.0
get out
0 has test check 2511456.0 and sample count 3274330
 accuracy 76.701 %, best 76.701 %, roc auc score 0.7490, best 0.7490
Testing at - 61440/153485 of epoch 0,
rank: 1 test_accu: 2511456.0
get out
1 has test check 2511456.0 and sample count 3274330
Finished training it 62464/153485 of epoch 0, 50.22 ms/it, loss 0.488666
Saving model to /rscratch/data/dlrm_criteo/save_model_after_training_one0.0.pt
Finished training it 62464/153485 of epoch 0, 48.92 ms/it, loss 0.488606
Finished training it 63488/153485 of epoch 0, 48.11 ms/it, loss 0.489074
Finished training it 63488/153485 of epoch 0, 48.08 ms/it, loss 0.487234
Finished training it 64512/153485 of epoch 0, 47.99 ms/it, loss 0.491981
Finished training it 64512/153485 of epoch 0, 47.85 ms/it, loss 0.490735
Finished training it 65536/153485 of epoch 0, 48.42 ms/it, loss 0.488060
Finished training it 65536/153485 of epoch 0, 47.90 ms/it, loss 0.487882
Finished training it 66560/153485 of epoch 0, 47.59 ms/it, loss 0.490275
Finished training it 66560/153485 of epoch 0, 48.13 ms/it, loss 0.489958
Finished training it 67584/153485 of epoch 0, 47.11 ms/it, loss 0.489820
Finished training it 67584/153485 of epoch 0, 47.26 ms/it, loss 0.490477
Finished training it 68608/153485 of epoch 0, 47.81 ms/it, loss 0.486818
Finished training it 68608/153485 of epoch 0, 47.37 ms/it, loss 0.487122
Finished training it 69632/153485 of epoch 0, 47.53 ms/it, loss 0.486942
Finished training it 69632/153485 of epoch 0, 47.99 ms/it, loss 0.487114
Finished training it 70656/153485 of epoch 0, 47.97 ms/it, loss 0.489108
Finished training it 70656/153485 of epoch 0, 47.65 ms/it, loss 0.487105
Finished training it 71680/153485 of epoch 0, 47.36 ms/it, loss 0.489679
Finished training it 71680/153485 of epoch 0, 47.88 ms/it, loss 0.485605
Testing at - 71680/153485 of epoch 0,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216rank: 0 test_accu: 2513855.0
get out
0 has test check 2513855.0 and sample count 3274330
 accuracy 76.775 %, best 76.775 %, roc auc score 0.7504, best 0.7504
Saving model to /rscratch/data/dlrm_criteo/save_model_after_training_one1.0.pt
Finished training it 72704/153485 of epoch 0, 49.09 ms/it, loss 0.485744
Testing at - 71680/153485 of epoch 0,
rank: 1 test_accu: 2513855.0
get out
1 has test check 2513855.0 and sample count 3274330
Finished training it 72704/153485 of epoch 0, 48.88 ms/it, loss 0.484810
Finished training it 73728/153485 of epoch 0, 50.53 ms/it, loss 0.488264
Finished training it 73728/153485 of epoch 0, 50.41 ms/it, loss 0.488824
Finished training it 74752/153485 of epoch 0, 51.30 ms/it, loss 0.487937
Finished training it 74752/153485 of epoch 0, 51.63 ms/it, loss 0.486359
Finished training it 75776/153485 of epoch 0, 54.50 ms/it, loss 0.484995
Finished training it 75776/153485 of epoch 0, 54.99 ms/it, loss 0.487547
Finished training it 76800/153485 of epoch 0, 57.36 ms/it, loss 0.484799
Finished training it 76800/153485 of epoch 0, 57.47 ms/it, loss 0.485169
Finished training it 77824/153485 of epoch 0, 50.23 ms/it, loss 0.484874
Finished training it 77824/153485 of epoch 0, 50.25 ms/it, loss 0.485233
Finished training it 78848/153485 of epoch 0, 49.45 ms/it, loss 0.485504
Finished training it 78848/153485 of epoch 0, 49.70 ms/it, loss 0.487938
Finished training it 79872/153485 of epoch 0, 50.37 ms/it, loss 0.486181
Finished training it 79872/153485 of epoch 0, 49.96 ms/it, loss 0.483171
Finished training it 80896/153485 of epoch 0, 49.31 ms/it, loss 0.485760
Finished training it 80896/153485 of epoch 0, 49.00 ms/it, loss 0.484791
Finished training it 81920/153485 of epoch 0, 48.20 ms/it, loss 0.486432
Finished training it 81920/153485 of epoch 0, 48.39 ms/it, loss 0.486987
Testing at - 81920/153485 of epoch 0,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216rank: 0 test_accu: 2515700.0
get out
0 has test check 2515700.0 and sample count 3274330
 accuracy 76.831 %, best 76.831 %, roc auc score 0.7522, best 0.7522
Testing at - 81920/153485 of epoch 0,
rank: 1 test_accu: 2515700.0
get out
1 has test check 2515700.0 and sample count 3274330
Finished training it 82944/153485 of epoch 0, 50.56 ms/it, loss 0.486479
Saving model to /rscratch/data/dlrm_criteo/save_model_after_training_one0.0.pt
Finished training it 82944/153485 of epoch 0, 49.17 ms/it, loss 0.488568
Finished training it 83968/153485 of epoch 0, 50.31 ms/it, loss 0.486219
Finished training it 83968/153485 of epoch 0, 49.53 ms/it, loss 0.485594
Finished training it 84992/153485 of epoch 0, 49.55 ms/it, loss 0.483798
Finished training it 84992/153485 of epoch 0, 49.64 ms/it, loss 0.485446
Finished training it 86016/153485 of epoch 0, 48.53 ms/it, loss 0.484802
Finished training it 86016/153485 of epoch 0, 49.01 ms/it, loss 0.484610
Finished training it 87040/153485 of epoch 0, 47.87 ms/it, loss 0.486294
Finished training it 87040/153485 of epoch 0, 47.64 ms/it, loss 0.484534
Finished training it 88064/153485 of epoch 0, 50.30 ms/it, loss 0.486226
Finished training it 88064/153485 of epoch 0, 50.43 ms/it, loss 0.485161
Finished training it 89088/153485 of epoch 0, 47.86 ms/it, loss 0.487213
Finished training it 89088/153485 of epoch 0, 47.66 ms/it, loss 0.486420
Finished training it 90112/153485 of epoch 0, 47.62 ms/it, loss 0.485943
Finished training it 90112/153485 of epoch 0, 47.41 ms/it, loss 0.486604
Finished training it 91136/153485 of epoch 0, 47.99 ms/it, loss 0.488762
Finished training it 91136/153485 of epoch 0, 48.37 ms/it, loss 0.483493
Finished training it 92160/153485 of epoch 0, 46.80 ms/it, loss 0.485180
Finished training it 92160/153485 of epoch 0, 46.70 ms/it, loss 0.485922
Testing at - 92160/153485 of epoch 0,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216rank: 0 test_accu: 2517734.0
get out
0 has test check 2517734.0 and sample count 3274330
 accuracy 76.893 %, best 76.893 %, roc auc score 0.7538, best 0.7538
Saving model to /rscratch/data/dlrm_criteo/save_model_after_training_one1.0.pt
Finished training it 93184/153485 of epoch 0, 48.99 ms/it, loss 0.486758
Testing at - 92160/153485 of epoch 0,
rank: 1 test_accu: 2517734.0
get out
1 has test check 2517734.0 and sample count 3274330
Finished training it 93184/153485 of epoch 0, 49.48 ms/it, loss 0.483324
Finished training it 94208/153485 of epoch 0, 49.89 ms/it, loss 0.486648
Finished training it 94208/153485 of epoch 0, 49.39 ms/it, loss 0.485079
Finished training it 95232/153485 of epoch 0, 49.99 ms/it, loss 0.485297
Finished training it 95232/153485 of epoch 0, 50.18 ms/it, loss 0.485017
Finished training it 96256/153485 of epoch 0, 62.30 ms/it, loss 0.482735
Finished training it 96256/153485 of epoch 0, 63.33 ms/it, loss 0.483661
Finished training it 97280/153485 of epoch 0, 49.35 ms/it, loss 0.482396
Finished training it 97280/153485 of epoch 0, 50.10 ms/it, loss 0.484307
Finished training it 98304/153485 of epoch 0, 48.98 ms/it, loss 0.482932
Finished training it 98304/153485 of epoch 0, 49.04 ms/it, loss 0.482715
Finished training it 99328/153485 of epoch 0, 48.65 ms/it, loss 0.484446
Finished training it 99328/153485 of epoch 0, 48.41 ms/it, loss 0.482771
Finished training it 100352/153485 of epoch 0, 48.86 ms/it, loss 0.482965
Finished training it 100352/153485 of epoch 0, 48.32 ms/it, loss 0.481315
Finished training it 101376/153485 of epoch 0, 48.16 ms/it, loss 0.482518
Finished training it 101376/153485 of epoch 0, 48.29 ms/it, loss 0.480911
Finished training it 102400/153485 of epoch 0, 48.33 ms/it, loss 0.484691
Finished training it 102400/153485 of epoch 0, 48.41 ms/it, loss 0.485279
Testing at - 102400/153485 of epoch 0,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216rank: 0 test_accu: 2519563.0
get out
0 has test check 2519563.0 and sample count 3274330
 accuracy 76.949 %, best 76.949 %, roc auc score 0.7553, best 0.7553
Testing at - 102400/153485 of epoch 0,
rank: 1 test_accu: 2519563.0
get out
1 has test check 2519563.0 and sample count 3274330
Finished training it 103424/153485 of epoch 0, 50.86 ms/it, loss 0.484470
Saving model to /rscratch/data/dlrm_criteo/save_model_after_training_one0.0.pt
Finished training it 103424/153485 of epoch 0, 49.55 ms/it, loss 0.479909
Finished training it 104448/153485 of epoch 0, 49.41 ms/it, loss 0.481155
Finished training it 104448/153485 of epoch 0, 48.67 ms/it, loss 0.481715
Finished training it 105472/153485 of epoch 0, 49.90 ms/it, loss 0.483643
Finished training it 105472/153485 of epoch 0, 49.93 ms/it, loss 0.481377
Finished training it 106496/153485 of epoch 0, 48.71 ms/it, loss 0.481682
Finished training it 106496/153485 of epoch 0, 48.83 ms/it, loss 0.481226
Finished training it 107520/153485 of epoch 0, 50.28 ms/it, loss 0.480793
Finished training it 107520/153485 of epoch 0, 50.36 ms/it, loss 0.483179
Finished training it 108544/153485 of epoch 0, 49.25 ms/it, loss 0.481230
Finished training it 108544/153485 of epoch 0, 49.14 ms/it, loss 0.482527
Finished training it 109568/153485 of epoch 0, 48.95 ms/it, loss 0.482744
Finished training it 109568/153485 of epoch 0, 49.73 ms/it, loss 0.480358
Finished training it 110592/153485 of epoch 0, 49.10 ms/it, loss 0.482569
Finished training it 110592/153485 of epoch 0, 49.09 ms/it, loss 0.480156
Finished training it 111616/153485 of epoch 0, 48.53 ms/it, loss 0.482521
Finished training it 111616/153485 of epoch 0, 48.38 ms/it, loss 0.479456
Finished training it 112640/153485 of epoch 0, 48.23 ms/it, loss 0.484839
Finished training it 112640/153485 of epoch 0, 48.83 ms/it, loss 0.484320
Testing at - 112640/153485 of epoch 0,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216rank: 0 test_accu: 2516625.0
get out
0 has test check 2516625.0 and sample count 3274330
 accuracy 76.859 %, best 76.859 %, roc auc score 0.7567, best 0.7567
Saving model to /rscratch/data/dlrm_criteo/save_model_after_training_one1.0.pt
Finished training it 113664/153485 of epoch 0, 49.97 ms/it, loss 0.479762
Testing at - 112640/153485 of epoch 0,
rank: 1 test_accu: 2516625.0
get out
1 has test check 2516625.0 and sample count 3274330
Finished training it 113664/153485 of epoch 0, 50.61 ms/it, loss 0.483662
Finished training it 114688/153485 of epoch 0, 49.60 ms/it, loss 0.485548
Finished training it 114688/153485 of epoch 0, 49.27 ms/it, loss 0.480504
Finished training it 115712/153485 of epoch 0, 49.06 ms/it, loss 0.481578
Finished training it 115712/153485 of epoch 0, 49.20 ms/it, loss 0.483943
Finished training it 116736/153485 of epoch 0, 54.86 ms/it, loss 0.480339
Finished training it 116736/153485 of epoch 0, 55.13 ms/it, loss 0.480234
Finished training it 117760/153485 of epoch 0, 54.14 ms/it, loss 0.482360
Finished training it 117760/153485 of epoch 0, 54.22 ms/it, loss 0.482532
Finished training it 118784/153485 of epoch 0, 48.75 ms/it, loss 0.482499
Finished training it 118784/153485 of epoch 0, 48.92 ms/it, loss 0.482303
Finished training it 119808/153485 of epoch 0, 48.33 ms/it, loss 0.480308
Finished training it 119808/153485 of epoch 0, 48.38 ms/it, loss 0.479855
Finished training it 120832/153485 of epoch 0, 47.39 ms/it, loss 0.480180
Finished training it 120832/153485 of epoch 0, 47.62 ms/it, loss 0.482600
Finished training it 121856/153485 of epoch 0, 47.30 ms/it, loss 0.480792
Finished training it 121856/153485 of epoch 0, 47.08 ms/it, loss 0.476997
Finished training it 122880/153485 of epoch 0, 47.93 ms/it, loss 0.480733
Finished training it 122880/153485 of epoch 0, 47.42 ms/it, loss 0.481506
Testing at - 122880/153485 of epoch 0,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216rank: 0 test_accu: 2523897.0
get out
0 has test check 2523897.0 and sample count 3274330
 accuracy 77.081 %, best 77.081 %, roc auc score 0.7593, best 0.7593
Saving model to /rscratch/data/dlrm_criteo/save_model_after_training_one0.0.pt
Finished training it 123904/153485 of epoch 0, 48.79 ms/it, loss 0.481492
Testing at - 122880/153485 of epoch 0,
rank: 1 test_accu: 2523897.0
get out
1 has test check 2523897.0 and sample count 3274330
Finished training it 123904/153485 of epoch 0, 50.25 ms/it, loss 0.481229
Finished training it 124928/153485 of epoch 0, 49.45 ms/it, loss 0.483081
Finished training it 124928/153485 of epoch 0, 49.00 ms/it, loss 0.481379
Finished training it 125952/153485 of epoch 0, 48.75 ms/it, loss 0.480158
Finished training it 125952/153485 of epoch 0, 48.87 ms/it, loss 0.481086
Finished training it 126976/153485 of epoch 0, 49.68 ms/it, loss 0.479232
Finished training it 126976/153485 of epoch 0, 49.66 ms/it, loss 0.480286
Finished training it 128000/153485 of epoch 0, 48.10 ms/it, loss 0.481432
Finished training it 128000/153485 of epoch 0, 48.37 ms/it, loss 0.477554
Finished training it 129024/153485 of epoch 0, 47.66 ms/it, loss 0.481248
Finished training it 129024/153485 of epoch 0, 47.85 ms/it, loss 0.479950
Finished training it 130048/153485 of epoch 0, 47.48 ms/it, loss 0.477672
Finished training it 130048/153485 of epoch 0, 47.29 ms/it, loss 0.479484
Finished training it 131072/153485 of epoch 0, 47.54 ms/it, loss 0.478293
Finished training it 131072/153485 of epoch 0, 47.96 ms/it, loss 0.481574
Finished training it 132096/153485 of epoch 0, 47.68 ms/it, loss 0.481366
Finished training it 132096/153485 of epoch 0, 47.45 ms/it, loss 0.478383
Finished training it 133120/153485 of epoch 0, 49.81 ms/it, loss 0.481229
Finished training it 133120/153485 of epoch 0, 50.16 ms/it, loss 0.480832
Testing at - 133120/153485 of epoch 0,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216rank: 0 test_accu: 2525042.0
get out
0 has test check 2525042.0 and sample count 3274330
 accuracy 77.116 %, best 77.116 %, roc auc score 0.7608, best 0.7608
Saving model to /rscratch/data/dlrm_criteo/save_model_after_training_one1.0.pt
Finished training it 134144/153485 of epoch 0, 49.33 ms/it, loss 0.481475
Testing at - 133120/153485 of epoch 0,
rank: 1 test_accu: 2525042.0
get out
1 has test check 2525042.0 and sample count 3274330
Finished training it 134144/153485 of epoch 0, 49.78 ms/it, loss 0.478214
Finished training it 135168/153485 of epoch 0, 48.78 ms/it, loss 0.479624
Finished training it 135168/153485 of epoch 0, 49.03 ms/it, loss 0.476674
Finished training it 136192/153485 of epoch 0, 49.09 ms/it, loss 0.478770
Finished training it 136192/153485 of epoch 0, 48.90 ms/it, loss 0.480263
Finished training it 137216/153485 of epoch 0, 53.91 ms/it, loss 0.479364
Finished training it 137216/153485 of epoch 0, 54.65 ms/it, loss 0.481904
Finished training it 138240/153485 of epoch 0, 55.25 ms/it, loss 0.478380
Finished training it 138240/153485 of epoch 0, 55.05 ms/it, loss 0.481761
Finished training it 139264/153485 of epoch 0, 53.33 ms/it, loss 0.478444
Finished training it 139264/153485 of epoch 0, 51.61 ms/it, loss 0.479973
Finished training it 140288/153485 of epoch 0, 51.24 ms/it, loss 0.480498
Finished training it 140288/153485 of epoch 0, 53.67 ms/it, loss 0.478432
Finished training it 141312/153485 of epoch 0, 50.47 ms/it, loss 0.480365
Finished training it 141312/153485 of epoch 0, 52.82 ms/it, loss 0.481531
Finished training it 142336/153485 of epoch 0, 47.85 ms/it, loss 0.478422
Finished training it 142336/153485 of epoch 0, 48.65 ms/it, loss 0.476977
Finished training it 143360/153485 of epoch 0, 50.75 ms/it, loss 0.475778
Finished training it 143360/153485 of epoch 0, 51.95 ms/it, loss 0.478722
Testing at - 143360/153485 of epoch 0,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216rank: 0 test_accu: 2523399.0
get out
0 has test check 2523399.0 and sample count 3274330
 accuracy 77.066 %, best 77.066 %, roc auc score 0.7601, best 0.7601
Saving model to /rscratch/data/dlrm_criteo/save_model_after_training_one0.0.pt
Finished training it 144384/153485 of epoch 0, 48.51 ms/it, loss 0.477573
Testing at - 143360/153485 of epoch 0,
rank: 1 test_accu: 2523399.0
get out
1 has test check 2523399.0 and sample count 3274330
Finished training it 144384/153485 of epoch 0, 50.58 ms/it, loss 0.479225
Finished training it 145408/153485 of epoch 0, 48.42 ms/it, loss 0.477546
Finished training it 145408/153485 of epoch 0, 47.26 ms/it, loss 0.479767
Finished training it 146432/153485 of epoch 0, 47.62 ms/it, loss 0.480286
Finished training it 146432/153485 of epoch 0, 49.10 ms/it, loss 0.478123
Finished training it 147456/153485 of epoch 0, 47.22 ms/it, loss 0.478918
Finished training it 147456/153485 of epoch 0, 47.50 ms/it, loss 0.479710
Finished training it 148480/153485 of epoch 0, 46.73 ms/it, loss 0.479173
Finished training it 148480/153485 of epoch 0, 46.86 ms/it, loss 0.480151
Finished training it 149504/153485 of epoch 0, 47.80 ms/it, loss 0.477571
Finished training it 149504/153485 of epoch 0, 48.04 ms/it, loss 0.479528
Finished training it 150528/153485 of epoch 0, 46.89 ms/it, loss 0.481860
Finished training it 150528/153485 of epoch 0, 46.98 ms/it, loss 0.478417
Finished training it 151552/153485 of epoch 0, 47.79 ms/it, loss 0.480031
Finished training it 151552/153485 of epoch 0, 48.02 ms/it, loss 0.477880
Finished training it 152576/153485 of epoch 0, 46.63 ms/it, loss 0.479867
Finished training it 152576/153485 of epoch 0, 46.50 ms/it, loss 0.479597
Warning: Skipping the batch 153484 with size 27
Warning: Skipping the batch 153484 with size 27
