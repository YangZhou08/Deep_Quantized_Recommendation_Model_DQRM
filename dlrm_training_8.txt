Unable to import mlperf_logging,  No module named 'mlperf_logging'
Unable to import mlperf_logging,  No module named 'mlperf_logging'
Warning: local_rank gpu mismatch
2 out of -1 (GPU)
Reading pre-processed data=/rscratch/data/dlrm_criteo/kaggleAdDisplayChallenge_processed.npz
Sparse fea = 26, Dense fea = 13
Defined train indices...
Randomized indices across days ...
Split data according to indices...
Reading pre-processed data=/rscratch/data/dlrm_criteo/kaggleAdDisplayChallenge_processed.npz
Sparse fea = 26, Dense fea = 13
Defined test indices...
Randomized indices across days ...
Split data according to indices...
number of devices 1
world size found is -1
---------- Embedding Table 0, quantization used, quantization bit set to 8
---------- Embedding Table 1, quantization used, quantization bit set to 8
---------- Embedding Table 2, quantization used, quantization bit set to 8
---------- Embedding Table 3, quantization used, quantization bit set to 8
---------- Embedding Table 4, quantization used, quantization bit set to 8
---------- Embedding Table 5, quantization used, quantization bit set to 8
---------- Embedding Table 6, quantization used, quantization bit set to 8
---------- Embedding Table 7, quantization used, quantization bit set to 8
---------- Embedding Table 8, quantization used, quantization bit set to 8
---------- Embedding Table 9, quantization used, quantization bit set to 8
---------- Embedding Table 10, quantization used, quantization bit set to 8
---------- Embedding Table 11, quantization used, quantization bit set to 8
---------- Embedding Table 12, quantization used, quantization bit set to 8
---------- Embedding Table 13, quantization used, quantization bit set to 8
---------- Embedding Table 14, quantization used, quantization bit set to 8
---------- Embedding Table 15, quantization used, quantization bit set to 8
---------- Embedding Table 16, quantization used, quantization bit set to 8
---------- Embedding Table 17, quantization used, quantization bit set to 8
---------- Embedding Table 18, quantization used, quantization bit set to 8
---------- Embedding Table 19, quantization used, quantization bit set to 8
---------- Embedding Table 20, quantization used, quantization bit set to 8
---------- Embedding Table 21, quantization used, quantization bit set to 8
---------- Embedding Table 22, quantization used, quantization bit set to 8
---------- Embedding Table 23, quantization used, quantization bit set to 8
---------- Embedding Table 24, quantization used, quantization bit set to 8
---------- Embedding Table 25, quantization used, quantization bit set to 8
optimizer selected is  sgd
Finished training it 1024/153485 of epoch 0, 54.38 ms/it, loss 0.524996
Unable to import mlperf_logging,  No module named 'mlperf_logging'
Warning: local_rank gpu mismatch
2 out of -1 (GPU)
Reading pre-processed data=/rscratch/data/dlrm_criteo/kaggleAdDisplayChallenge_processed.npz
Sparse fea = 26, Dense fea = 13
Defined train indices...
Randomized indices across days ...
Split data according to indices...
Reading pre-processed data=/rscratch/data/dlrm_criteo/kaggleAdDisplayChallenge_processed.npz
Sparse fea = 26, Dense fea = 13
Defined test indices...
Randomized indices across days ...
Split data according to indices...
number of devices 1
world size found is -1
---------- Embedding Table 0, quantization used, quantization bit set to 8
---------- Embedding Table 1, quantization used, quantization bit set to 8
---------- Embedding Table 2, quantization used, quantization bit set to 8
---------- Embedding Table 3, quantization used, quantization bit set to 8
---------- Embedding Table 4, quantization used, quantization bit set to 8
---------- Embedding Table 5, quantization used, quantization bit set to 8
---------- Embedding Table 6, quantization used, quantization bit set to 8
---------- Embedding Table 7, quantization used, quantization bit set to 8
---------- Embedding Table 8, quantization used, quantization bit set to 8
---------- Embedding Table 9, quantization used, quantization bit set to 8
---------- Embedding Table 10, quantization used, quantization bit set to 8
---------- Embedding Table 11, quantization used, quantization bit set to 8
---------- Embedding Table 12, quantization used, quantization bit set to 8
---------- Embedding Table 13, quantization used, quantization bit set to 8
---------- Embedding Table 14, quantization used, quantization bit set to 8
---------- Embedding Table 15, quantization used, quantization bit set to 8
---------- Embedding Table 16, quantization used, quantization bit set to 8
---------- Embedding Table 17, quantization used, quantization bit set to 8
---------- Embedding Table 18, quantization used, quantization bit set to 8
---------- Embedding Table 19, quantization used, quantization bit set to 8
---------- Embedding Table 20, quantization used, quantization bit set to 8
---------- Embedding Table 21, quantization used, quantization bit set to 8
---------- Embedding Table 22, quantization used, quantization bit set to 8
---------- Embedding Table 23, quantization used, quantization bit set to 8
---------- Embedding Table 24, quantization used, quantization bit set to 8
---------- Embedding Table 25, quantization used, quantization bit set to 8
optimizer selected is  sgd
Finished training it 1024/153485 of epoch 0, 53.41 ms/it, loss 0.523736
Finished training it 2048/153485 of epoch 0, 47.39 ms/it, loss 0.515062
Finished training it 2048/153485 of epoch 0, 47.57 ms/it, loss 0.514618
Finished training it 3072/153485 of epoch 0, 46.95 ms/it, loss 0.516253
Finished training it 3072/153485 of epoch 0, 47.05 ms/it, loss 0.511009
Finished training it 4096/153485 of epoch 0, 46.98 ms/it, loss 0.512111
Finished training it 4096/153485 of epoch 0, 47.08 ms/it, loss 0.512652
Finished training it 5120/153485 of epoch 0, 47.03 ms/it, loss 0.506952
Finished training it 5120/153485 of epoch 0, 47.13 ms/it, loss 0.509615
Finished training it 6144/153485 of epoch 0, 47.42 ms/it, loss 0.507371
Finished training it 6144/153485 of epoch 0, 47.59 ms/it, loss 0.508426
Finished training it 7168/153485 of epoch 0, 46.68 ms/it, loss 0.506302
Finished training it 7168/153485 of epoch 0, 46.78 ms/it, loss 0.508156
Finished training it 8192/153485 of epoch 0, 46.75 ms/it, loss 0.505058
Finished training it 8192/153485 of epoch 0, 46.81 ms/it, loss 0.507157
Finished training it 9216/153485 of epoch 0, 46.43 ms/it, loss 0.508525
Finished training it 9216/153485 of epoch 0, 46.44 ms/it, loss 0.509285
Finished training it 10240/153485 of epoch 0, 46.60 ms/it, loss 0.506030
Finished training it 10240/153485 of epoch 0, 46.52 ms/it, loss 0.507534
Testing at - 10240/153485 of epoch 0,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216rank: 0 test_accu: 2482548.0
get out
0 has test check 2482548.0 and sample count 3274330
 accuracy 75.819 %, best 75.819 %, roc auc score 0.7282, best 0.7282
Testing at - 10240/153485 of epoch 0,
rank: 1 test_accu: 2482548.0
get out
1 has test check 2482548.0 and sample count 3274330
Finished training it 11264/153485 of epoch 0, 48.10 ms/it, loss 0.505011
Saving model to /rscratch/data/dlrm_criteo/save_model_after_training_one1.0.pt
Finished training it 11264/153485 of epoch 0, 48.08 ms/it, loss 0.504365
Finished training it 12288/153485 of epoch 0, 47.88 ms/it, loss 0.503814
Finished training it 12288/153485 of epoch 0, 48.16 ms/it, loss 0.501863
Finished training it 13312/153485 of epoch 0, 48.02 ms/it, loss 0.505736
Finished training it 13312/153485 of epoch 0, 48.14 ms/it, loss 0.501923
Finished training it 14336/153485 of epoch 0, 47.90 ms/it, loss 0.503782
Finished training it 14336/153485 of epoch 0, 47.91 ms/it, loss 0.503106
Finished training it 15360/153485 of epoch 0, 57.78 ms/it, loss 0.502054
Finished training it 15360/153485 of epoch 0, 57.36 ms/it, loss 0.500443
Finished training it 16384/153485 of epoch 0, 48.01 ms/it, loss 0.502600
Finished training it 16384/153485 of epoch 0, 47.81 ms/it, loss 0.501636
Finished training it 17408/153485 of epoch 0, 47.70 ms/it, loss 0.504290
Finished training it 17408/153485 of epoch 0, 47.84 ms/it, loss 0.501611
Finished training it 18432/153485 of epoch 0, 47.23 ms/it, loss 0.501641
Finished training it 18432/153485 of epoch 0, 47.32 ms/it, loss 0.502353
Finished training it 19456/153485 of epoch 0, 46.73 ms/it, loss 0.500781
Finished training it 19456/153485 of epoch 0, 46.63 ms/it, loss 0.501793
Finished training it 20480/153485 of epoch 0, 47.61 ms/it, loss 0.501791
Finished training it 20480/153485 of epoch 0, 47.57 ms/it, loss 0.501736
Testing at - 20480/153485 of epoch 0,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216rank: 0 test_accu: 2478496.0
get out
0 has test check 2478496.0 and sample count 3274330
 accuracy 75.695 %, best 75.819 %, roc auc score 0.7287, best 0.7287
Finished training it 21504/153485 of epoch 0, 47.61 ms/it, loss 0.499845
Testing at - 20480/153485 of epoch 0,
rank: 1 test_accu: 2478496.0
get out
1 has test check 2478496.0 and sample count 3274330
Finished training it 21504/153485 of epoch 0, 47.61 ms/it, loss 0.499717
Finished training it 22528/153485 of epoch 0, 47.35 ms/it, loss 0.501599
Finished training it 22528/153485 of epoch 0, 47.28 ms/it, loss 0.501774
Finished training it 23552/153485 of epoch 0, 47.65 ms/it, loss 0.498912
Finished training it 23552/153485 of epoch 0, 47.78 ms/it, loss 0.499387
Finished training it 24576/153485 of epoch 0, 48.43 ms/it, loss 0.501635
Finished training it 24576/153485 of epoch 0, 48.32 ms/it, loss 0.501366
Finished training it 25600/153485 of epoch 0, 48.19 ms/it, loss 0.500981
Finished training it 25600/153485 of epoch 0, 48.19 ms/it, loss 0.495482
Finished training it 26624/153485 of epoch 0, 47.65 ms/it, loss 0.501310
Finished training it 26624/153485 of epoch 0, 47.67 ms/it, loss 0.502861
Finished training it 27648/153485 of epoch 0, 47.77 ms/it, loss 0.500556
Finished training it 27648/153485 of epoch 0, 47.63 ms/it, loss 0.499448
Finished training it 28672/153485 of epoch 0, 47.72 ms/it, loss 0.499852
Finished training it 28672/153485 of epoch 0, 47.65 ms/it, loss 0.501798
Finished training it 29696/153485 of epoch 0, 46.98 ms/it, loss 0.499157
Finished training it 29696/153485 of epoch 0, 47.15 ms/it, loss 0.500679
Finished training it 30720/153485 of epoch 0, 46.93 ms/it, loss 0.499107
Finished training it 30720/153485 of epoch 0, 47.05 ms/it, loss 0.500762
Testing at - 30720/153485 of epoch 0,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216rank: 0 test_accu: 2492933.0
get out
0 has test check 2492933.0 and sample count 3274330
 accuracy 76.136 %, best 76.136 %, roc auc score 0.7358, best 0.7358
Testing at - 30720/153485 of epoch 0,
rank: 1 test_accu: 2492933.0
get out
1 has test check 2492933.0 and sample count 3274330
Finished training it 31744/153485 of epoch 0, 48.79 ms/it, loss 0.498106
Saving model to /rscratch/data/dlrm_criteo/save_model_after_training_one1.0.pt
Finished training it 31744/153485 of epoch 0, 48.51 ms/it, loss 0.499051
Finished training it 32768/153485 of epoch 0, 48.04 ms/it, loss 0.500625
Finished training it 32768/153485 of epoch 0, 47.89 ms/it, loss 0.496198
Finished training it 33792/153485 of epoch 0, 47.81 ms/it, loss 0.497498
Finished training it 33792/153485 of epoch 0, 47.92 ms/it, loss 0.496378
Finished training it 34816/153485 of epoch 0, 47.96 ms/it, loss 0.496872
Finished training it 34816/153485 of epoch 0, 47.93 ms/it, loss 0.498432
Finished training it 35840/153485 of epoch 0, 57.40 ms/it, loss 0.494528
Finished training it 35840/153485 of epoch 0, 57.67 ms/it, loss 0.496414
Finished training it 36864/153485 of epoch 0, 48.88 ms/it, loss 0.497427
Finished training it 36864/153485 of epoch 0, 48.89 ms/it, loss 0.496976
Finished training it 37888/153485 of epoch 0, 47.44 ms/it, loss 0.496852
Finished training it 37888/153485 of epoch 0, 47.23 ms/it, loss 0.495854
Finished training it 38912/153485 of epoch 0, 47.59 ms/it, loss 0.494874
Finished training it 38912/153485 of epoch 0, 47.66 ms/it, loss 0.493877
Finished training it 39936/153485 of epoch 0, 49.34 ms/it, loss 0.495708
Finished training it 39936/153485 of epoch 0, 49.41 ms/it, loss 0.497150
Finished training it 40960/153485 of epoch 0, 49.11 ms/it, loss 0.495455
Finished training it 40960/153485 of epoch 0, 49.37 ms/it, loss 0.494971
Testing at - 40960/153485 of epoch 0,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216rank: 0 test_accu: 2500806.0
get out
0 has test check 2500806.0 and sample count 3274330
 accuracy 76.376 %, best 76.376 %, roc auc score 0.7424, best 0.7424
Testing at - 40960/153485 of epoch 0,
rank: 1 test_accu: 2500806.0
get out
1 has test check 2500806.0 and sample count 3274330
Finished training it 41984/153485 of epoch 0, 48.50 ms/it, loss 0.493333
Saving model to /rscratch/data/dlrm_criteo/save_model_after_training_one0.0.pt
Finished training it 41984/153485 of epoch 0, 48.58 ms/it, loss 0.494337
Finished training it 43008/153485 of epoch 0, 49.49 ms/it, loss 0.496408
Finished training it 43008/153485 of epoch 0, 49.74 ms/it, loss 0.496263
Finished training it 44032/153485 of epoch 0, 49.03 ms/it, loss 0.496049
Finished training it 44032/153485 of epoch 0, 49.05 ms/it, loss 0.492847
Finished training it 45056/153485 of epoch 0, 49.44 ms/it, loss 0.494740
Finished training it 45056/153485 of epoch 0, 49.48 ms/it, loss 0.498586
Finished training it 46080/153485 of epoch 0, 48.54 ms/it, loss 0.494444
Finished training it 46080/153485 of epoch 0, 48.52 ms/it, loss 0.494135
Finished training it 47104/153485 of epoch 0, 48.61 ms/it, loss 0.492933
Finished training it 47104/153485 of epoch 0, 48.51 ms/it, loss 0.493527
Finished training it 48128/153485 of epoch 0, 48.78 ms/it, loss 0.494109
Finished training it 48128/153485 of epoch 0, 48.82 ms/it, loss 0.495363
Finished training it 49152/153485 of epoch 0, 47.85 ms/it, loss 0.492432
Finished training it 49152/153485 of epoch 0, 47.87 ms/it, loss 0.494405
Finished training it 50176/153485 of epoch 0, 48.96 ms/it, loss 0.490906
Finished training it 50176/153485 of epoch 0, 48.94 ms/it, loss 0.491632
Finished training it 51200/153485 of epoch 0, 48.50 ms/it, loss 0.496593
Finished training it 51200/153485 of epoch 0, 48.25 ms/it, loss 0.492003
Testing at - 51200/153485 of epoch 0,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216rank: 0 test_accu: 2500762.0
get out
0 has test check 2500762.0 and sample count 3274330
 accuracy 76.375 %, best 76.376 %, roc auc score 0.7441, best 0.7441
Testing at - 51200/153485 of epoch 0,
rank: 1 test_accu: 2500762.0
get out
1 has test check 2500762.0 and sample count 3274330
Finished training it 52224/153485 of epoch 0, 48.70 ms/it, loss 0.493244
Finished training it 52224/153485 of epoch 0, 48.58 ms/it, loss 0.492509
Finished training it 53248/153485 of epoch 0, 48.39 ms/it, loss 0.487319
Finished training it 53248/153485 of epoch 0, 48.53 ms/it, loss 0.488709
Finished training it 54272/153485 of epoch 0, 49.03 ms/it, loss 0.490696
Finished training it 54272/153485 of epoch 0, 49.19 ms/it, loss 0.492632
Finished training it 55296/153485 of epoch 0, 58.67 ms/it, loss 0.490061
Finished training it 55296/153485 of epoch 0, 58.08 ms/it, loss 0.491649
Finished training it 56320/153485 of epoch 0, 48.96 ms/it, loss 0.494080
Finished training it 56320/153485 of epoch 0, 48.76 ms/it, loss 0.493493
Finished training it 57344/153485 of epoch 0, 47.79 ms/it, loss 0.492944
Finished training it 57344/153485 of epoch 0, 47.99 ms/it, loss 0.489784
Finished training it 58368/153485 of epoch 0, 49.15 ms/it, loss 0.492757
Finished training it 58368/153485 of epoch 0, 49.18 ms/it, loss 0.488965
Finished training it 59392/153485 of epoch 0, 48.96 ms/it, loss 0.489832
Finished training it 59392/153485 of epoch 0, 48.93 ms/it, loss 0.488808
Finished training it 60416/153485 of epoch 0, 48.18 ms/it, loss 0.492208
Finished training it 60416/153485 of epoch 0, 47.95 ms/it, loss 0.491983
Finished training it 61440/153485 of epoch 0, 49.65 ms/it, loss 0.487915
Finished training it 61440/153485 of epoch 0, 49.68 ms/it, loss 0.490788
Testing at - 61440/153485 of epoch 0,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216rank: 0 test_accu: 2506496.0
get out
0 has test check 2506496.0 and sample count 3274330
 accuracy 76.550 %, best 76.550 %, roc auc score 0.7464, best 0.7464
Testing at - 61440/153485 of epoch 0,
rank: 1 test_accu: 2506496.0
get out
1 has test check 2506496.0 and sample count 3274330
Finished training it 62464/153485 of epoch 0, 48.90 ms/it, loss 0.490979
Saving model to /rscratch/data/dlrm_criteo/save_model_after_training_one0.0.pt
Finished training it 62464/153485 of epoch 0, 48.69 ms/it, loss 0.490876
Finished training it 63488/153485 of epoch 0, 48.81 ms/it, loss 0.492023
Finished training it 63488/153485 of epoch 0, 48.86 ms/it, loss 0.487422
Finished training it 64512/153485 of epoch 0, 49.05 ms/it, loss 0.488812
Finished training it 64512/153485 of epoch 0, 49.02 ms/it, loss 0.490424
Finished training it 65536/153485 of epoch 0, 49.54 ms/it, loss 0.491617
Finished training it 65536/153485 of epoch 0, 49.51 ms/it, loss 0.490766
Finished training it 66560/153485 of epoch 0, 49.62 ms/it, loss 0.487813
Finished training it 66560/153485 of epoch 0, 49.45 ms/it, loss 0.487941
Finished training it 67584/153485 of epoch 0, 48.90 ms/it, loss 0.491847
Finished training it 67584/153485 of epoch 0, 49.09 ms/it, loss 0.487972
Finished training it 68608/153485 of epoch 0, 49.18 ms/it, loss 0.490810
Finished training it 68608/153485 of epoch 0, 49.34 ms/it, loss 0.489583
Finished training it 69632/153485 of epoch 0, 48.81 ms/it, loss 0.487115
Finished training it 69632/153485 of epoch 0, 49.05 ms/it, loss 0.489943
Finished training it 70656/153485 of epoch 0, 49.44 ms/it, loss 0.488552
Finished training it 70656/153485 of epoch 0, 49.34 ms/it, loss 0.489292
Finished training it 71680/153485 of epoch 0, 49.46 ms/it, loss 0.488588
Finished training it 71680/153485 of epoch 0, 49.40 ms/it, loss 0.489395
Testing at - 71680/153485 of epoch 0,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216rank: 0 test_accu: 2510130.0
get out
0 has test check 2510130.0 and sample count 3274330
 accuracy 76.661 %, best 76.661 %, roc auc score 0.7505, best 0.7505
Testing at - 71680/153485 of epoch 0,
rank: 1 test_accu: 2510130.0
get out
1 has test check 2510130.0 and sample count 3274330
Finished training it 72704/153485 of epoch 0, 49.19 ms/it, loss 0.486287
Saving model to /rscratch/data/dlrm_criteo/save_model_after_training_one1.0.pt
Finished training it 72704/153485 of epoch 0, 49.16 ms/it, loss 0.488308
Finished training it 73728/153485 of epoch 0, 48.83 ms/it, loss 0.487839
Finished training it 73728/153485 of epoch 0, 48.87 ms/it, loss 0.489253
Finished training it 74752/153485 of epoch 0, 48.64 ms/it, loss 0.488935
Finished training it 74752/153485 of epoch 0, 48.62 ms/it, loss 0.489892
Finished training it 75776/153485 of epoch 0, 60.41 ms/it, loss 0.485482
Finished training it 75776/153485 of epoch 0, 60.68 ms/it, loss 0.488695
Finished training it 76800/153485 of epoch 0, 48.96 ms/it, loss 0.489843
Finished training it 76800/153485 of epoch 0, 48.92 ms/it, loss 0.487510
Finished training it 77824/153485 of epoch 0, 49.81 ms/it, loss 0.489418
Finished training it 77824/153485 of epoch 0, 49.90 ms/it, loss 0.487134
Finished training it 78848/153485 of epoch 0, 49.68 ms/it, loss 0.489814
Finished training it 78848/153485 of epoch 0, 49.73 ms/it, loss 0.488435
Finished training it 79872/153485 of epoch 0, 49.22 ms/it, loss 0.486284
Finished training it 79872/153485 of epoch 0, 49.20 ms/it, loss 0.486063
Finished training it 80896/153485 of epoch 0, 49.53 ms/it, loss 0.487314
Finished training it 80896/153485 of epoch 0, 49.38 ms/it, loss 0.488824
Finished training it 81920/153485 of epoch 0, 48.95 ms/it, loss 0.484584
Finished training it 81920/153485 of epoch 0, 48.80 ms/it, loss 0.486920
Testing at - 81920/153485 of epoch 0,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216rank: 0 test_accu: 2511553.0
get out
0 has test check 2511553.0 and sample count 3274330
 accuracy 76.704 %, best 76.704 %, roc auc score 0.7517, best 0.7517
Saving model to /rscratch/data/dlrm_criteo/save_model_after_training_one0.0.pt
Finished training it 82944/153485 of epoch 0, 49.16 ms/it, loss 0.487367
Testing at - 81920/153485 of epoch 0,
rank: 1 test_accu: 2511553.0
get out
1 has test check 2511553.0 and sample count 3274330
Finished training it 82944/153485 of epoch 0, 49.36 ms/it, loss 0.487518
Finished training it 83968/153485 of epoch 0, 49.64 ms/it, loss 0.488801
Finished training it 83968/153485 of epoch 0, 49.40 ms/it, loss 0.485521
Finished training it 84992/153485 of epoch 0, 49.14 ms/it, loss 0.485280
Finished training it 84992/153485 of epoch 0, 49.20 ms/it, loss 0.487177
Finished training it 86016/153485 of epoch 0, 48.83 ms/it, loss 0.484462
Finished training it 86016/153485 of epoch 0, 49.08 ms/it, loss 0.486212
Finished training it 87040/153485 of epoch 0, 49.11 ms/it, loss 0.483133
Finished training it 87040/153485 of epoch 0, 49.04 ms/it, loss 0.483643
Finished training it 88064/153485 of epoch 0, 48.71 ms/it, loss 0.485333
Finished training it 88064/153485 of epoch 0, 48.76 ms/it, loss 0.486500
Finished training it 89088/153485 of epoch 0, 48.67 ms/it, loss 0.484342
Finished training it 89088/153485 of epoch 0, 48.86 ms/it, loss 0.485691
Finished training it 90112/153485 of epoch 0, 48.61 ms/it, loss 0.486325
Finished training it 90112/153485 of epoch 0, 48.56 ms/it, loss 0.487779
Finished training it 91136/153485 of epoch 0, 49.11 ms/it, loss 0.487713
Finished training it 91136/153485 of epoch 0, 48.85 ms/it, loss 0.485721
Finished training it 92160/153485 of epoch 0, 48.63 ms/it, loss 0.486320
Finished training it 92160/153485 of epoch 0, 48.40 ms/it, loss 0.486836
Testing at - 92160/153485 of epoch 0,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216rank: 0 test_accu: 2514883.0
get out
0 has test check 2514883.0 and sample count 3274330
 accuracy 76.806 %, best 76.806 %, roc auc score 0.7537, best 0.7537
Saving model to /rscratch/data/dlrm_criteo/save_model_after_training_one1.0.pt
Finished training it 93184/153485 of epoch 0, 49.42 ms/it, loss 0.486659
Testing at - 92160/153485 of epoch 0,
rank: 1 test_accu: 2514883.0
get out
1 has test check 2514883.0 and sample count 3274330
Finished training it 93184/153485 of epoch 0, 49.44 ms/it, loss 0.485694
Finished training it 94208/153485 of epoch 0, 48.53 ms/it, loss 0.485002
Finished training it 94208/153485 of epoch 0, 48.61 ms/it, loss 0.484941
Finished training it 95232/153485 of epoch 0, 48.86 ms/it, loss 0.485276
Finished training it 95232/153485 of epoch 0, 48.77 ms/it, loss 0.486187
Finished training it 96256/153485 of epoch 0, 55.25 ms/it, loss 0.488429
Finished training it 96256/153485 of epoch 0, 54.50 ms/it, loss 0.483221
Finished training it 97280/153485 of epoch 0, 57.25 ms/it, loss 0.482785
Finished training it 97280/153485 of epoch 0, 57.78 ms/it, loss 0.483987
Finished training it 98304/153485 of epoch 0, 48.24 ms/it, loss 0.484187
Finished training it 98304/153485 of epoch 0, 48.55 ms/it, loss 0.484304
Finished training it 99328/153485 of epoch 0, 48.72 ms/it, loss 0.484432
Finished training it 99328/153485 of epoch 0, 48.61 ms/it, loss 0.483902
Finished training it 100352/153485 of epoch 0, 49.13 ms/it, loss 0.484538
Finished training it 100352/153485 of epoch 0, 49.08 ms/it, loss 0.484365
Finished training it 101376/153485 of epoch 0, 48.74 ms/it, loss 0.484227
Finished training it 101376/153485 of epoch 0, 48.82 ms/it, loss 0.486132
Finished training it 102400/153485 of epoch 0, 49.53 ms/it, loss 0.482611
Finished training it 102400/153485 of epoch 0, 49.53 ms/it, loss 0.481118
Testing at - 102400/153485 of epoch 0,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216rank: 0 test_accu: 2517783.0
get out
0 has test check 2517783.0 and sample count 3274330
 accuracy 76.895 %, best 76.895 %, roc auc score 0.7553, best 0.7553
Saving model to /rscratch/data/dlrm_criteo/save_model_after_training_one0.0.pt
Finished training it 103424/153485 of epoch 0, 49.52 ms/it, loss 0.484365
Testing at - 102400/153485 of epoch 0,
rank: 1 test_accu: 2517783.0
get out
1 has test check 2517783.0 and sample count 3274330
Finished training it 103424/153485 of epoch 0, 49.61 ms/it, loss 0.481952
Finished training it 104448/153485 of epoch 0, 49.93 ms/it, loss 0.481880
Finished training it 104448/153485 of epoch 0, 49.59 ms/it, loss 0.487404
Finished training it 105472/153485 of epoch 0, 48.40 ms/it, loss 0.482416
Finished training it 105472/153485 of epoch 0, 48.48 ms/it, loss 0.486817
Finished training it 106496/153485 of epoch 0, 49.18 ms/it, loss 0.486249
Finished training it 106496/153485 of epoch 0, 49.23 ms/it, loss 0.485423
Finished training it 107520/153485 of epoch 0, 49.07 ms/it, loss 0.482229
Finished training it 107520/153485 of epoch 0, 48.99 ms/it, loss 0.484749
Finished training it 108544/153485 of epoch 0, 49.85 ms/it, loss 0.485309
Finished training it 108544/153485 of epoch 0, 49.71 ms/it, loss 0.481935
Finished training it 109568/153485 of epoch 0, 48.90 ms/it, loss 0.483127
Finished training it 109568/153485 of epoch 0, 48.91 ms/it, loss 0.483167
Finished training it 110592/153485 of epoch 0, 49.29 ms/it, loss 0.482898
Finished training it 110592/153485 of epoch 0, 49.27 ms/it, loss 0.482961
Finished training it 111616/153485 of epoch 0, 48.61 ms/it, loss 0.479900
Finished training it 111616/153485 of epoch 0, 48.60 ms/it, loss 0.481590
Finished training it 112640/153485 of epoch 0, 48.96 ms/it, loss 0.484973
Finished training it 112640/153485 of epoch 0, 48.95 ms/it, loss 0.481500
Testing at - 112640/153485 of epoch 0,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216rank: 0 test_accu: 2519489.0
get out
0 has test check 2519489.0 and sample count 3274330
 accuracy 76.947 %, best 76.947 %, roc auc score 0.7570, best 0.7570
Saving model to /rscratch/data/dlrm_criteo/save_model_after_training_one1.0.pt
Finished training it 113664/153485 of epoch 0, 49.00 ms/it, loss 0.480414
Testing at - 112640/153485 of epoch 0,
rank: 1 test_accu: 2519489.0
get out
1 has test check 2519489.0 and sample count 3274330
Finished training it 113664/153485 of epoch 0, 49.19 ms/it, loss 0.484124
Finished training it 114688/153485 of epoch 0, 49.25 ms/it, loss 0.481034
Finished training it 114688/153485 of epoch 0, 49.14 ms/it, loss 0.482221
Finished training it 115712/153485 of epoch 0, 49.27 ms/it, loss 0.479292
Finished training it 115712/153485 of epoch 0, 49.18 ms/it, loss 0.483711
Finished training it 116736/153485 of epoch 0, 54.13 ms/it, loss 0.482859
Finished training it 116736/153485 of epoch 0, 54.55 ms/it, loss 0.483444
Finished training it 117760/153485 of epoch 0, 55.71 ms/it, loss 0.483679
Finished training it 117760/153485 of epoch 0, 55.28 ms/it, loss 0.482502
Finished training it 118784/153485 of epoch 0, 48.60 ms/it, loss 0.478938
Finished training it 118784/153485 of epoch 0, 48.66 ms/it, loss 0.481391
Finished training it 119808/153485 of epoch 0, 49.21 ms/it, loss 0.479622
Finished training it 119808/153485 of epoch 0, 49.13 ms/it, loss 0.480877
Finished training it 120832/153485 of epoch 0, 49.43 ms/it, loss 0.479924
Finished training it 120832/153485 of epoch 0, 49.29 ms/it, loss 0.483089
Finished training it 121856/153485 of epoch 0, 49.27 ms/it, loss 0.483087
Finished training it 121856/153485 of epoch 0, 49.35 ms/it, loss 0.482016
Finished training it 122880/153485 of epoch 0, 48.96 ms/it, loss 0.480385
Finished training it 122880/153485 of epoch 0, 48.92 ms/it, loss 0.481904
Testing at - 122880/153485 of epoch 0,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216rank: 0 test_accu: 2520634.0
get out
0 has test check 2520634.0 and sample count 3274330
 accuracy 76.982 %, best 76.982 %, roc auc score 0.7581, best 0.7581
Testing at - 122880/153485 of epoch 0,
rank: 1 test_accu: 2520634.0
get out
1 has test check 2520634.0 and sample count 3274330
Finished training it 123904/153485 of epoch 0, 49.21 ms/it, loss 0.480409
Saving model to /rscratch/data/dlrm_criteo/save_model_after_training_one0.0.pt
Finished training it 123904/153485 of epoch 0, 49.38 ms/it, loss 0.481713
Finished training it 124928/153485 of epoch 0, 48.71 ms/it, loss 0.481331
Finished training it 124928/153485 of epoch 0, 48.80 ms/it, loss 0.483151
Finished training it 125952/153485 of epoch 0, 49.09 ms/it, loss 0.482394
Finished training it 125952/153485 of epoch 0, 49.20 ms/it, loss 0.482480
Finished training it 126976/153485 of epoch 0, 49.16 ms/it, loss 0.482263
Finished training it 126976/153485 of epoch 0, 49.17 ms/it, loss 0.481788
Finished training it 128000/153485 of epoch 0, 49.39 ms/it, loss 0.482140
Finished training it 128000/153485 of epoch 0, 49.19 ms/it, loss 0.480796
Finished training it 129024/153485 of epoch 0, 50.30 ms/it, loss 0.485116
Finished training it 129024/153485 of epoch 0, 50.07 ms/it, loss 0.483849
Finished training it 130048/153485 of epoch 0, 48.49 ms/it, loss 0.480768
Finished training it 130048/153485 of epoch 0, 48.52 ms/it, loss 0.480595
Finished training it 131072/153485 of epoch 0, 48.83 ms/it, loss 0.482070
Finished training it 131072/153485 of epoch 0, 48.67 ms/it, loss 0.482702
Finished training it 132096/153485 of epoch 0, 48.24 ms/it, loss 0.483955
Finished training it 132096/153485 of epoch 0, 48.29 ms/it, loss 0.483351
Finished training it 133120/153485 of epoch 0, 49.22 ms/it, loss 0.482119
Finished training it 133120/153485 of epoch 0, 49.17 ms/it, loss 0.479896
Testing at - 133120/153485 of epoch 0,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216rank: 0 test_accu: 2521710.0
get out
0 has test check 2521710.0 and sample count 3274330
 accuracy 77.015 %, best 77.015 %, roc auc score 0.7580, best 0.7581
Saving model to /rscratch/data/dlrm_criteo/save_model_after_training_one1.0.pt
Finished training it 134144/153485 of epoch 0, 47.75 ms/it, loss 0.481905
Testing at - 133120/153485 of epoch 0,
rank: 1 test_accu: 2521710.0
get out
1 has test check 2521710.0 and sample count 3274330
Finished training it 134144/153485 of epoch 0, 48.00 ms/it, loss 0.480746
Finished training it 135168/153485 of epoch 0, 48.95 ms/it, loss 0.481164
Finished training it 135168/153485 of epoch 0, 49.02 ms/it, loss 0.481061
Finished training it 136192/153485 of epoch 0, 48.82 ms/it, loss 0.480443
Finished training it 136192/153485 of epoch 0, 49.00 ms/it, loss 0.481014
Finished training it 137216/153485 of epoch 0, 59.86 ms/it, loss 0.481656
Finished training it 137216/153485 of epoch 0, 59.69 ms/it, loss 0.482508
Finished training it 138240/153485 of epoch 0, 48.91 ms/it, loss 0.480811
Finished training it 138240/153485 of epoch 0, 48.88 ms/it, loss 0.481414
Finished training it 139264/153485 of epoch 0, 49.11 ms/it, loss 0.481638
Finished training it 139264/153485 of epoch 0, 49.28 ms/it, loss 0.479587
Finished training it 140288/153485 of epoch 0, 49.15 ms/it, loss 0.483068
Finished training it 140288/153485 of epoch 0, 49.08 ms/it, loss 0.479469
Finished training it 141312/153485 of epoch 0, 49.07 ms/it, loss 0.482523
Finished training it 141312/153485 of epoch 0, 49.07 ms/it, loss 0.478231
Finished training it 142336/153485 of epoch 0, 48.77 ms/it, loss 0.479864
Finished training it 142336/153485 of epoch 0, 48.77 ms/it, loss 0.480729
Finished training it 143360/153485 of epoch 0, 49.56 ms/it, loss 0.482299
Finished training it 143360/153485 of epoch 0, 49.55 ms/it, loss 0.479857
Testing at - 143360/153485 of epoch 0,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216rank: 0 test_accu: 2522407.0
get out
0 has test check 2522407.0 and sample count 3274330
 accuracy 77.036 %, best 77.036 %, roc auc score 0.7589, best 0.7589
Saving model to /rscratch/data/dlrm_criteo/save_model_after_training_one0.0.pt
Finished training it 144384/153485 of epoch 0, 48.38 ms/it, loss 0.478884
Testing at - 143360/153485 of epoch 0,
rank: 1 test_accu: 2522407.0
get out
1 has test check 2522407.0 and sample count 3274330
Finished training it 144384/153485 of epoch 0, 48.27 ms/it, loss 0.480017
Finished training it 145408/153485 of epoch 0, 49.41 ms/it, loss 0.482909
Finished training it 145408/153485 of epoch 0, 49.43 ms/it, loss 0.482064
Finished training it 146432/153485 of epoch 0, 49.22 ms/it, loss 0.481321
Finished training it 146432/153485 of epoch 0, 49.25 ms/it, loss 0.482621
Finished training it 147456/153485 of epoch 0, 49.83 ms/it, loss 0.481071
Finished training it 147456/153485 of epoch 0, 49.74 ms/it, loss 0.481241
Finished training it 148480/153485 of epoch 0, 49.18 ms/it, loss 0.483334
Finished training it 148480/153485 of epoch 0, 49.05 ms/it, loss 0.478733
Finished training it 149504/153485 of epoch 0, 50.08 ms/it, loss 0.482033
Finished training it 149504/153485 of epoch 0, 49.97 ms/it, loss 0.480753
Finished training it 150528/153485 of epoch 0, 48.78 ms/it, loss 0.480119
Finished training it 150528/153485 of epoch 0, 49.05 ms/it, loss 0.476664
Finished training it 151552/153485 of epoch 0, 49.91 ms/it, loss 0.480675
Finished training it 151552/153485 of epoch 0, 49.88 ms/it, loss 0.481421
Finished training it 152576/153485 of epoch 0, 48.84 ms/it, loss 0.482786
Finished training it 152576/153485 of epoch 0, 48.81 ms/it, loss 0.481040
Warning: Skipping the batch 153484 with size 27
Finished training it 1024/153485 of epoch 1, 50.39 ms/it, loss 0.481954
Warning: Skipping the batch 153484 with size 27
Finished training it 1024/153485 of epoch 1, 51.14 ms/it, loss 0.481193
Finished training it 2048/153485 of epoch 1, 49.46 ms/it, loss 0.480946
Finished training it 2048/153485 of epoch 1, 49.33 ms/it, loss 0.480974
Finished training it 3072/153485 of epoch 1, 49.39 ms/it, loss 0.483610
Finished training it 3072/153485 of epoch 1, 49.26 ms/it, loss 0.478543
Finished training it 4096/153485 of epoch 1, 49.36 ms/it, loss 0.480356
Finished training it 4096/153485 of epoch 1, 49.41 ms/it, loss 0.479931
Finished training it 5120/153485 of epoch 1, 54.30 ms/it, loss 0.480642
Finished training it 5120/153485 of epoch 1, 54.73 ms/it, loss 0.478328
Finished training it 6144/153485 of epoch 1, 49.12 ms/it, loss 0.479271
Finished training it 6144/153485 of epoch 1, 48.94 ms/it, loss 0.480279
Finished training it 7168/153485 of epoch 1, 49.07 ms/it, loss 0.480986
Finished training it 7168/153485 of epoch 1, 48.98 ms/it, loss 0.479315
Finished training it 8192/153485 of epoch 1, 48.96 ms/it, loss 0.480187
Finished training it 8192/153485 of epoch 1, 48.90 ms/it, loss 0.477043
Finished training it 9216/153485 of epoch 1, 48.60 ms/it, loss 0.481828
Finished training it 9216/153485 of epoch 1, 48.50 ms/it, loss 0.482792
Finished training it 10240/153485 of epoch 1, 48.57 ms/it, loss 0.480313
Finished training it 10240/153485 of epoch 1, 48.50 ms/it, loss 0.481782
Testing at - 10240/153485 of epoch 1,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216rank: 0 test_accu: 2525685.0
get out
0 has test check 2525685.0 and sample count 3274330
 accuracy 77.136 %, best 77.136 %, roc auc score 0.7619, best 0.7619
Saving model to /rscratch/data/dlrm_criteo/save_model_after_training_one1.0.pt
Finished training it 11264/153485 of epoch 1, 49.18 ms/it, loss 0.479139
Testing at - 10240/153485 of epoch 1,
rank: 1 test_accu: 2525685.0
get out
1 has test check 2525685.0 and sample count 3274330
Finished training it 11264/153485 of epoch 1, 49.24 ms/it, loss 0.478689
Finished training it 12288/153485 of epoch 1, 49.10 ms/it, loss 0.479384
Finished training it 12288/153485 of epoch 1, 49.17 ms/it, loss 0.477443
Finished training it 13312/153485 of epoch 1, 49.74 ms/it, loss 0.478613
Finished training it 13312/153485 of epoch 1, 49.78 ms/it, loss 0.482372
Finished training it 14336/153485 of epoch 1, 56.45 ms/it, loss 0.479523
Finished training it 14336/153485 of epoch 1, 56.74 ms/it, loss 0.479231
Finished training it 15360/153485 of epoch 1, 49.78 ms/it, loss 0.479534
Finished training it 15360/153485 of epoch 1, 49.60 ms/it, loss 0.477279
Finished training it 16384/153485 of epoch 1, 49.72 ms/it, loss 0.478398
Finished training it 16384/153485 of epoch 1, 49.47 ms/it, loss 0.478466
Finished training it 17408/153485 of epoch 1, 49.19 ms/it, loss 0.478855
Finished training it 17408/153485 of epoch 1, 49.07 ms/it, loss 0.481146
Finished training it 18432/153485 of epoch 1, 49.43 ms/it, loss 0.478770
Finished training it 18432/153485 of epoch 1, 49.28 ms/it, loss 0.479018
Finished training it 19456/153485 of epoch 1, 49.15 ms/it, loss 0.476829
Finished training it 19456/153485 of epoch 1, 49.05 ms/it, loss 0.478923
Finished training it 20480/153485 of epoch 1, 48.53 ms/it, loss 0.478122
Finished training it 20480/153485 of epoch 1, 48.52 ms/it, loss 0.478986
Testing at - 20480/153485 of epoch 1,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216rank: 0 test_accu: 2527832.0
get out
0 has test check 2527832.0 and sample count 3274330
 accuracy 77.202 %, best 77.202 %, roc auc score 0.7620, best 0.7620
Testing at - 20480/153485 of epoch 1,
rank: 1 test_accu: 2527832.0
get out
1 has test check 2527832.0 and sample count 3274330
Finished training it 21504/153485 of epoch 1, 49.00 ms/it, loss 0.476059
Saving model to /rscratch/data/dlrm_criteo/save_model_after_training_one0.0.pt
Finished training it 21504/153485 of epoch 1, 49.00 ms/it, loss 0.477258
Finished training it 22528/153485 of epoch 1, 48.88 ms/it, loss 0.479900
Finished training it 22528/153485 of epoch 1, 48.80 ms/it, loss 0.479045
Finished training it 23552/153485 of epoch 1, 49.14 ms/it, loss 0.479003
Finished training it 23552/153485 of epoch 1, 49.00 ms/it, loss 0.476803
Finished training it 24576/153485 of epoch 1, 48.75 ms/it, loss 0.478197
Finished training it 24576/153485 of epoch 1, 48.66 ms/it, loss 0.478877
Finished training it 25600/153485 of epoch 1, 54.56 ms/it, loss 0.473388
Finished training it 25600/153485 of epoch 1, 53.94 ms/it, loss 0.478441
Finished training it 26624/153485 of epoch 1, 47.98 ms/it, loss 0.480796
Finished training it 26624/153485 of epoch 1, 47.89 ms/it, loss 0.478563
Finished training it 27648/153485 of epoch 1, 49.03 ms/it, loss 0.478440
Finished training it 27648/153485 of epoch 1, 49.11 ms/it, loss 0.477006
Finished training it 28672/153485 of epoch 1, 49.39 ms/it, loss 0.478119
Finished training it 28672/153485 of epoch 1, 49.47 ms/it, loss 0.479518
Finished training it 29696/153485 of epoch 1, 48.70 ms/it, loss 0.477191
Finished training it 29696/153485 of epoch 1, 48.78 ms/it, loss 0.478786
Finished training it 30720/153485 of epoch 1, 49.52 ms/it, loss 0.479043
Finished training it 30720/153485 of epoch 1, 49.48 ms/it, loss 0.477889
Testing at - 30720/153485 of epoch 1,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216rank: 0 test_accu: 2528121.0
get out
0 has test check 2528121.0 and sample count 3274330
 accuracy 77.210 %, best 77.210 %, roc auc score 0.7624, best 0.7624
Saving model to /rscratch/data/dlrm_criteo/save_model_after_training_one1.0.pt
Finished training it 31744/153485 of epoch 1, 49.08 ms/it, loss 0.478576
Testing at - 30720/153485 of epoch 1,
rank: 1 test_accu: 2528121.0
get out
1 has test check 2528121.0 and sample count 3274330
Finished training it 31744/153485 of epoch 1, 48.97 ms/it, loss 0.477129
Finished training it 32768/153485 of epoch 1, 48.31 ms/it, loss 0.479360
Finished training it 32768/153485 of epoch 1, 48.27 ms/it, loss 0.475245
Finished training it 33792/153485 of epoch 1, 48.33 ms/it, loss 0.476739
Finished training it 33792/153485 of epoch 1, 48.24 ms/it, loss 0.478297
Finished training it 34816/153485 of epoch 1, 54.21 ms/it, loss 0.477094
Finished training it 34816/153485 of epoch 1, 54.71 ms/it, loss 0.478287
Finished training it 35840/153485 of epoch 1, 47.96 ms/it, loss 0.475765
Finished training it 35840/153485 of epoch 1, 48.07 ms/it, loss 0.476130
Finished training it 36864/153485 of epoch 1, 50.03 ms/it, loss 0.478428
Finished training it 36864/153485 of epoch 1, 49.85 ms/it, loss 0.479726
Finished training it 37888/153485 of epoch 1, 49.40 ms/it, loss 0.475858
Finished training it 37888/153485 of epoch 1, 49.29 ms/it, loss 0.478424
Finished training it 38912/153485 of epoch 1, 49.33 ms/it, loss 0.475396
Finished training it 38912/153485 of epoch 1, 49.42 ms/it, loss 0.477375
Finished training it 39936/153485 of epoch 1, 49.33 ms/it, loss 0.479184
Finished training it 39936/153485 of epoch 1, 49.17 ms/it, loss 0.477908
Finished training it 40960/153485 of epoch 1, 48.83 ms/it, loss 0.476839
Finished training it 40960/153485 of epoch 1, 48.86 ms/it, loss 0.477399
Testing at - 40960/153485 of epoch 1,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216rank: 0 test_accu: 2529409.0
get out
0 has test check 2529409.0 and sample count 3274330
 accuracy 77.250 %, best 77.250 %, roc auc score 0.7631, best 0.7631
Testing at - 40960/153485 of epoch 1,
rank: 1 test_accu: 2529409.0
get out
1 has test check 2529409.0 and sample count 3274330
Finished training it 41984/153485 of epoch 1, 48.86 ms/it, loss 0.476443
Saving model to /rscratch/data/dlrm_criteo/save_model_after_training_one0.0.pt
Finished training it 41984/153485 of epoch 1, 48.73 ms/it, loss 0.475432
Finished training it 43008/153485 of epoch 1, 49.61 ms/it, loss 0.477969
Finished training it 43008/153485 of epoch 1, 49.53 ms/it, loss 0.478430
Finished training it 44032/153485 of epoch 1, 49.43 ms/it, loss 0.475775
Finished training it 44032/153485 of epoch 1, 49.22 ms/it, loss 0.478583
Finished training it 45056/153485 of epoch 1, 49.90 ms/it, loss 0.480340
Finished training it 45056/153485 of epoch 1, 50.11 ms/it, loss 0.477157
Finished training it 46080/153485 of epoch 1, 54.75 ms/it, loss 0.478283
Finished training it 46080/153485 of epoch 1, 54.65 ms/it, loss 0.477082
Finished training it 47104/153485 of epoch 1, 49.11 ms/it, loss 0.475981
Finished training it 47104/153485 of epoch 1, 49.05 ms/it, loss 0.476866
Finished training it 48128/153485 of epoch 1, 49.69 ms/it, loss 0.477699
Finished training it 48128/153485 of epoch 1, 49.75 ms/it, loss 0.478339
Finished training it 49152/153485 of epoch 1, 49.47 ms/it, loss 0.478463
Finished training it 49152/153485 of epoch 1, 49.48 ms/it, loss 0.475786
Finished training it 50176/153485 of epoch 1, 49.50 ms/it, loss 0.475374
Finished training it 50176/153485 of epoch 1, 49.59 ms/it, loss 0.474547
Finished training it 51200/153485 of epoch 1, 49.37 ms/it, loss 0.481174
Finished training it 51200/153485 of epoch 1, 49.61 ms/it, loss 0.476425
Testing at - 51200/153485 of epoch 1,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216rank: 0 test_accu: 2530093.0
get out
0 has test check 2530093.0 and sample count 3274330
 accuracy 77.271 %, best 77.271 %, roc auc score 0.7640, best 0.7640
Testing at - 51200/153485 of epoch 1,
rank: 1 test_accu: 2530093.0
get out
1 has test check 2530093.0 and sample count 3274330
Finished training it 52224/153485 of epoch 1, 47.99 ms/it, loss 0.476788
Saving model to /rscratch/data/dlrm_criteo/save_model_after_training_one1.0.pt
Finished training it 52224/153485 of epoch 1, 47.83 ms/it, loss 0.476151
Finished training it 53248/153485 of epoch 1, 48.34 ms/it, loss 0.472490
Finished training it 53248/153485 of epoch 1, 48.29 ms/it, loss 0.472681
Finished training it 54272/153485 of epoch 1, 48.33 ms/it, loss 0.475188
Finished training it 54272/153485 of epoch 1, 48.26 ms/it, loss 0.477269
Finished training it 55296/153485 of epoch 1, 48.47 ms/it, loss 0.475069
Finished training it 55296/153485 of epoch 1, 48.37 ms/it, loss 0.476949
Finished training it 56320/153485 of epoch 1, 52.57 ms/it, loss 0.478082
Finished training it 56320/153485 of epoch 1, 53.29 ms/it, loss 0.478839
Finished training it 57344/153485 of epoch 1, 47.99 ms/it, loss 0.478120
Finished training it 57344/153485 of epoch 1, 48.29 ms/it, loss 0.474729
Finished training it 58368/153485 of epoch 1, 49.15 ms/it, loss 0.477202
Finished training it 58368/153485 of epoch 1, 49.11 ms/it, loss 0.474000
Finished training it 59392/153485 of epoch 1, 50.33 ms/it, loss 0.475168
Finished training it 59392/153485 of epoch 1, 50.05 ms/it, loss 0.473528
Finished training it 60416/153485 of epoch 1, 49.37 ms/it, loss 0.477377
Finished training it 60416/153485 of epoch 1, 49.37 ms/it, loss 0.477114
Finished training it 61440/153485 of epoch 1, 48.98 ms/it, loss 0.476036
Finished training it 61440/153485 of epoch 1, 48.84 ms/it, loss 0.474466
Testing at - 61440/153485 of epoch 1,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216rank: 0 test_accu: 2528060.0
get out
0 has test check 2528060.0 and sample count 3274330
 accuracy 77.208 %, best 77.271 %, roc auc score 0.7623, best 0.7640
Testing at - 61440/153485 of epoch 1,
rank: 1 test_accu: 2528060.0
get out
1 has test check 2528060.0 and sample count 3274330
Finished training it 62464/153485 of epoch 1, 48.32 ms/it, loss 0.476855
Finished training it 62464/153485 of epoch 1, 48.55 ms/it, loss 0.476737
Finished training it 63488/153485 of epoch 1, 49.08 ms/it, loss 0.477346
Finished training it 63488/153485 of epoch 1, 49.31 ms/it, loss 0.472596
Finished training it 64512/153485 of epoch 1, 49.50 ms/it, loss 0.474739
Finished training it 64512/153485 of epoch 1, 49.13 ms/it, loss 0.476011
Finished training it 65536/153485 of epoch 1, 56.65 ms/it, loss 0.477898
Finished training it 65536/153485 of epoch 1, 57.34 ms/it, loss 0.477612
Finished training it 66560/153485 of epoch 1, 48.71 ms/it, loss 0.475176
Finished training it 66560/153485 of epoch 1, 48.76 ms/it, loss 0.475513
Finished training it 67584/153485 of epoch 1, 49.07 ms/it, loss 0.473744
Finished training it 67584/153485 of epoch 1, 48.84 ms/it, loss 0.477765
Finished training it 68608/153485 of epoch 1, 48.98 ms/it, loss 0.477257
Finished training it 68608/153485 of epoch 1, 48.86 ms/it, loss 0.476162
Finished training it 69632/153485 of epoch 1, 48.91 ms/it, loss 0.476554
Finished training it 69632/153485 of epoch 1, 48.76 ms/it, loss 0.473974
Finished training it 70656/153485 of epoch 1, 48.88 ms/it, loss 0.477457
Finished training it 70656/153485 of epoch 1, 48.80 ms/it, loss 0.476417
Finished training it 71680/153485 of epoch 1, 48.72 ms/it, loss 0.476647
Finished training it 71680/153485 of epoch 1, 48.77 ms/it, loss 0.476847
Testing at - 71680/153485 of epoch 1,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216rank: 0 test_accu: 2531647.0
get out
0 has test check 2531647.0 and sample count 3274330
 accuracy 77.318 %, best 77.318 %, roc auc score 0.7658, best 0.7658
Saving model to /rscratch/data/dlrm_criteo/save_model_after_training_one1.0.pt
Finished training it 72704/153485 of epoch 1, 48.38 ms/it, loss 0.476133
Testing at - 71680/153485 of epoch 1,
rank: 1 test_accu: 2531647.0
get out
1 has test check 2531647.0 and sample count 3274330
Finished training it 72704/153485 of epoch 1, 48.48 ms/it, loss 0.474361
Finished training it 73728/153485 of epoch 1, 49.47 ms/it, loss 0.477202
Finished training it 73728/153485 of epoch 1, 49.44 ms/it, loss 0.475685
Finished training it 74752/153485 of epoch 1, 49.11 ms/it, loss 0.476804
Finished training it 74752/153485 of epoch 1, 49.02 ms/it, loss 0.477330
Finished training it 75776/153485 of epoch 1, 54.57 ms/it, loss 0.477359
Finished training it 75776/153485 of epoch 1, 54.54 ms/it, loss 0.474198
Finished training it 76800/153485 of epoch 1, 49.35 ms/it, loss 0.475420
Finished training it 76800/153485 of epoch 1, 49.16 ms/it, loss 0.478470
Finished training it 77824/153485 of epoch 1, 49.37 ms/it, loss 0.476741
Finished training it 77824/153485 of epoch 1, 49.34 ms/it, loss 0.475292
Finished training it 78848/153485 of epoch 1, 49.49 ms/it, loss 0.475896
Finished training it 78848/153485 of epoch 1, 49.28 ms/it, loss 0.477674
Finished training it 79872/153485 of epoch 1, 48.87 ms/it, loss 0.474205
Finished training it 79872/153485 of epoch 1, 49.14 ms/it, loss 0.473848
Finished training it 80896/153485 of epoch 1, 50.59 ms/it, loss 0.475777
Finished training it 80896/153485 of epoch 1, 50.72 ms/it, loss 0.476868
Finished training it 81920/153485 of epoch 1, 49.32 ms/it, loss 0.473385
Finished training it 81920/153485 of epoch 1, 49.41 ms/it, loss 0.475408
Testing at - 81920/153485 of epoch 1,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216rank: 0 test_accu: 2531706.0
get out
0 has test check 2531706.0 and sample count 3274330
 accuracy 77.320 %, best 77.320 %, roc auc score 0.7653, best 0.7658
Testing at - 81920/153485 of epoch 1,
rank: 1 test_accu: 2531706.0
get out
1 has test check 2531706.0 and sample count 3274330
Finished training it 82944/153485 of epoch 1, 49.03 ms/it, loss 0.476876
Saving model to /rscratch/data/dlrm_criteo/save_model_after_training_one0.0.pt
Finished training it 82944/153485 of epoch 1, 48.99 ms/it, loss 0.476005
Finished training it 83968/153485 of epoch 1, 49.64 ms/it, loss 0.477800
Finished training it 83968/153485 of epoch 1, 49.49 ms/it, loss 0.475236
Finished training it 84992/153485 of epoch 1, 49.59 ms/it, loss 0.474327
Finished training it 84992/153485 of epoch 1, 49.59 ms/it, loss 0.475697
Finished training it 86016/153485 of epoch 1, 56.04 ms/it, loss 0.474581
Finished training it 86016/153485 of epoch 1, 56.16 ms/it, loss 0.474701
Finished training it 87040/153485 of epoch 1, 49.12 ms/it, loss 0.472301
Finished training it 87040/153485 of epoch 1, 49.08 ms/it, loss 0.472853
Finished training it 88064/153485 of epoch 1, 49.11 ms/it, loss 0.475667
Finished training it 88064/153485 of epoch 1, 49.02 ms/it, loss 0.474542
Finished training it 89088/153485 of epoch 1, 49.76 ms/it, loss 0.475825
Finished training it 89088/153485 of epoch 1, 49.75 ms/it, loss 0.473263
Finished training it 90112/153485 of epoch 1, 50.61 ms/it, loss 0.477309
Finished training it 90112/153485 of epoch 1, 50.66 ms/it, loss 0.476020
Finished training it 91136/153485 of epoch 1, 49.27 ms/it, loss 0.477004
Finished training it 91136/153485 of epoch 1, 49.17 ms/it, loss 0.475393
Finished training it 92160/153485 of epoch 1, 49.68 ms/it, loss 0.475542
Finished training it 92160/153485 of epoch 1, 49.66 ms/it, loss 0.476005
Testing at - 92160/153485 of epoch 1,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216rank: 0 test_accu: 2532206.0
get out
0 has test check 2532206.0 and sample count 3274330
 accuracy 77.335 %, best 77.335 %, roc auc score 0.7667, best 0.7667
Testing at - 92160/153485 of epoch 1,
rank: 1 test_accu: 2532206.0
get out
1 has test check 2532206.0 and sample count 3274330
Finished training it 93184/153485 of epoch 1, 48.51 ms/it, loss 0.474867
Saving model to /rscratch/data/dlrm_criteo/save_model_after_training_one1.0.pt
Finished training it 93184/153485 of epoch 1, 48.41 ms/it, loss 0.475374
Finished training it 94208/153485 of epoch 1, 49.25 ms/it, loss 0.474817
Finished training it 94208/153485 of epoch 1, 49.16 ms/it, loss 0.475110
Finished training it 95232/153485 of epoch 1, 48.78 ms/it, loss 0.475447
Finished training it 95232/153485 of epoch 1, 48.58 ms/it, loss 0.475167
Finished training it 96256/153485 of epoch 1, 56.14 ms/it, loss 0.478202
Finished training it 96256/153485 of epoch 1, 56.57 ms/it, loss 0.472818
Finished training it 97280/153485 of epoch 1, 49.09 ms/it, loss 0.473063
Finished training it 97280/153485 of epoch 1, 49.01 ms/it, loss 0.474576
Finished training it 98304/153485 of epoch 1, 49.30 ms/it, loss 0.473849
Finished training it 98304/153485 of epoch 1, 49.29 ms/it, loss 0.474542
Finished training it 99328/153485 of epoch 1, 49.38 ms/it, loss 0.473196
Finished training it 99328/153485 of epoch 1, 49.35 ms/it, loss 0.474490
Finished training it 100352/153485 of epoch 1, 49.88 ms/it, loss 0.474216
Finished training it 100352/153485 of epoch 1, 49.81 ms/it, loss 0.474490
Finished training it 101376/153485 of epoch 1, 49.53 ms/it, loss 0.474675
Finished training it 101376/153485 of epoch 1, 49.25 ms/it, loss 0.477481
Finished training it 102400/153485 of epoch 1, 49.59 ms/it, loss 0.472283
Finished training it 102400/153485 of epoch 1, 49.42 ms/it, loss 0.472390
Testing at - 102400/153485 of epoch 1,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216rank: 0 test_accu: 2534973.0
get out
0 has test check 2534973.0 and sample count 3274330
 accuracy 77.420 %, best 77.420 %, roc auc score 0.7682, best 0.7682
Testing at - 102400/153485 of epoch 1,
rank: 1 test_accu: 2534973.0
get out
1 has test check 2534973.0 and sample count 3274330
Finished training it 103424/153485 of epoch 1, 49.59 ms/it, loss 0.472910
Saving model to /rscratch/data/dlrm_criteo/save_model_after_training_one0.0.pt
Finished training it 103424/153485 of epoch 1, 49.44 ms/it, loss 0.474829
Finished training it 104448/153485 of epoch 1, 49.43 ms/it, loss 0.477415
Finished training it 104448/153485 of epoch 1, 49.43 ms/it, loss 0.472024
Finished training it 105472/153485 of epoch 1, 49.11 ms/it, loss 0.472880
Finished training it 105472/153485 of epoch 1, 49.13 ms/it, loss 0.477252
Finished training it 106496/153485 of epoch 1, 57.35 ms/it, loss 0.475761
Finished training it 106496/153485 of epoch 1, 56.78 ms/it, loss 0.476483
Finished training it 107520/153485 of epoch 1, 48.11 ms/it, loss 0.475692
Finished training it 107520/153485 of epoch 1, 48.23 ms/it, loss 0.472852
Finished training it 108544/153485 of epoch 1, 49.21 ms/it, loss 0.472139
Finished training it 108544/153485 of epoch 1, 49.33 ms/it, loss 0.475474
Finished training it 109568/153485 of epoch 1, 49.45 ms/it, loss 0.474606
Finished training it 109568/153485 of epoch 1, 49.40 ms/it, loss 0.474319
Finished training it 110592/153485 of epoch 1, 49.16 ms/it, loss 0.473541
Finished training it 110592/153485 of epoch 1, 48.88 ms/it, loss 0.473521
Finished training it 111616/153485 of epoch 1, 49.64 ms/it, loss 0.470234
Finished training it 111616/153485 of epoch 1, 49.51 ms/it, loss 0.472512
Finished training it 112640/153485 of epoch 1, 49.23 ms/it, loss 0.475299
Finished training it 112640/153485 of epoch 1, 49.32 ms/it, loss 0.472462
Testing at - 112640/153485 of epoch 1,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216rank: 0 test_accu: 2535000.0
get out
0 has test check 2535000.0 and sample count 3274330
 accuracy 77.420 %, best 77.420 %, roc auc score 0.7678, best 0.7682
Testing at - 112640/153485 of epoch 1,
rank: 1 test_accu: 2535000.0
get out
1 has test check 2535000.0 and sample count 3274330
Finished training it 113664/153485 of epoch 1, 48.99 ms/it, loss 0.475123
Saving model to /rscratch/data/dlrm_criteo/save_model_after_training_one1.0.pt
Finished training it 113664/153485 of epoch 1, 49.05 ms/it, loss 0.471787
Finished training it 114688/153485 of epoch 1, 48.59 ms/it, loss 0.473343
Finished training it 114688/153485 of epoch 1, 48.58 ms/it, loss 0.471244
Finished training it 115712/153485 of epoch 1, 49.40 ms/it, loss 0.474767
Finished training it 115712/153485 of epoch 1, 49.43 ms/it, loss 0.470701
Finished training it 116736/153485 of epoch 1, 49.12 ms/it, loss 0.473324
Finished training it 116736/153485 of epoch 1, 49.23 ms/it, loss 0.473633
Finished training it 117760/153485 of epoch 1, 54.33 ms/it, loss 0.473590
Finished training it 117760/153485 of epoch 1, 54.01 ms/it, loss 0.474789
Finished training it 118784/153485 of epoch 1, 49.33 ms/it, loss 0.472433
Finished training it 118784/153485 of epoch 1, 49.31 ms/it, loss 0.469789
Finished training it 119808/153485 of epoch 1, 49.41 ms/it, loss 0.472414
Finished training it 119808/153485 of epoch 1, 49.52 ms/it, loss 0.471021
Finished training it 120832/153485 of epoch 1, 49.89 ms/it, loss 0.470634
Finished training it 120832/153485 of epoch 1, 49.77 ms/it, loss 0.473758
Finished training it 121856/153485 of epoch 1, 49.46 ms/it, loss 0.473461
Finished training it 121856/153485 of epoch 1, 49.43 ms/it, loss 0.474515
Finished training it 122880/153485 of epoch 1, 48.34 ms/it, loss 0.473026
Finished training it 122880/153485 of epoch 1, 48.27 ms/it, loss 0.471124
Testing at - 122880/153485 of epoch 1,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216rank: 0 test_accu: 2533413.0
get out
0 has test check 2533413.0 and sample count 3274330
 accuracy 77.372 %, best 77.420 %, roc auc score 0.7677, best 0.7682
Finished training it 123904/153485 of epoch 1, 48.08 ms/it, loss 0.472882
Testing at - 122880/153485 of epoch 1,
rank: 1 test_accu: 2533413.0
get out
1 has test check 2533413.0 and sample count 3274330
Finished training it 123904/153485 of epoch 1, 47.97 ms/it, loss 0.472035
Finished training it 124928/153485 of epoch 1, 48.80 ms/it, loss 0.474771
Finished training it 124928/153485 of epoch 1, 48.64 ms/it, loss 0.473283
Finished training it 125952/153485 of epoch 1, 49.00 ms/it, loss 0.473739
Finished training it 125952/153485 of epoch 1, 48.79 ms/it, loss 0.474497
Finished training it 126976/153485 of epoch 1, 49.27 ms/it, loss 0.473464
Finished training it 126976/153485 of epoch 1, 49.06 ms/it, loss 0.473816
Finished training it 128000/153485 of epoch 1, 54.93 ms/it, loss 0.472256
Finished training it 128000/153485 of epoch 1, 54.76 ms/it, loss 0.473661
Finished training it 129024/153485 of epoch 1, 49.60 ms/it, loss 0.475869
Finished training it 129024/153485 of epoch 1, 49.85 ms/it, loss 0.474952
Finished training it 130048/153485 of epoch 1, 49.42 ms/it, loss 0.471360
Finished training it 130048/153485 of epoch 1, 49.04 ms/it, loss 0.471351
Finished training it 131072/153485 of epoch 1, 48.65 ms/it, loss 0.472873
Finished training it 131072/153485 of epoch 1, 48.92 ms/it, loss 0.472784
Finished training it 132096/153485 of epoch 1, 49.22 ms/it, loss 0.474338
Finished training it 132096/153485 of epoch 1, 49.22 ms/it, loss 0.475030
Finished training it 133120/153485 of epoch 1, 49.07 ms/it, loss 0.470509
Finished training it 133120/153485 of epoch 1, 49.08 ms/it, loss 0.472966
Testing at - 133120/153485 of epoch 1,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216rank: 0 test_accu: 2536179.0
get out
0 has test check 2536179.0 and sample count 3274330
 accuracy 77.456 %, best 77.456 %, roc auc score 0.7696, best 0.7696
Testing at - 133120/153485 of epoch 1,
rank: 1 test_accu: 2536179.0
get out
1 has test check 2536179.0 and sample count 3274330
Finished training it 134144/153485 of epoch 1, 48.34 ms/it, loss 0.472414
Saving model to /rscratch/data/dlrm_criteo/save_model_after_training_one1.0.pt
Finished training it 134144/153485 of epoch 1, 48.45 ms/it, loss 0.471556
Finished training it 135168/153485 of epoch 1, 48.40 ms/it, loss 0.471837
Finished training it 135168/153485 of epoch 1, 48.47 ms/it, loss 0.472201
Finished training it 136192/153485 of epoch 1, 48.79 ms/it, loss 0.472552
Finished training it 136192/153485 of epoch 1, 48.98 ms/it, loss 0.471470
Finished training it 137216/153485 of epoch 1, 54.16 ms/it, loss 0.473375
Finished training it 137216/153485 of epoch 1, 54.40 ms/it, loss 0.474162
Finished training it 138240/153485 of epoch 1, 49.94 ms/it, loss 0.472691
Finished training it 138240/153485 of epoch 1, 49.95 ms/it, loss 0.472089
Finished training it 139264/153485 of epoch 1, 49.66 ms/it, loss 0.470255
Finished training it 139264/153485 of epoch 1, 49.53 ms/it, loss 0.472603
Finished training it 140288/153485 of epoch 1, 49.38 ms/it, loss 0.473699
Finished training it 140288/153485 of epoch 1, 49.56 ms/it, loss 0.470551
Finished training it 141312/153485 of epoch 1, 49.73 ms/it, loss 0.469905
Finished training it 141312/153485 of epoch 1, 49.79 ms/it, loss 0.474331
Finished training it 142336/153485 of epoch 1, 49.80 ms/it, loss 0.471236
Finished training it 142336/153485 of epoch 1, 49.82 ms/it, loss 0.471488
Finished training it 143360/153485 of epoch 1, 48.57 ms/it, loss 0.473783
Finished training it 143360/153485 of epoch 1, 48.80 ms/it, loss 0.470990
Testing at - 143360/153485 of epoch 1,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216rank: 0 test_accu: 2537223.0
get out
0 has test check 2537223.0 and sample count 3274330
 accuracy 77.488 %, best 77.488 %, roc auc score 0.7704, best 0.7704
Testing at - 143360/153485 of epoch 1,
rank: 1 test_accu: 2537223.0
get out
1 has test check 2537223.0 and sample count 3274330
Finished training it 144384/153485 of epoch 1, 48.22 ms/it, loss 0.471441
Saving model to /rscratch/data/dlrm_criteo/save_model_after_training_one0.0.pt
Finished training it 144384/153485 of epoch 1, 48.23 ms/it, loss 0.470048
Finished training it 145408/153485 of epoch 1, 49.85 ms/it, loss 0.474712
Finished training it 145408/153485 of epoch 1, 49.81 ms/it, loss 0.473435
Finished training it 146432/153485 of epoch 1, 49.28 ms/it, loss 0.473428
Finished training it 146432/153485 of epoch 1, 49.05 ms/it, loss 0.474504
Finished training it 147456/153485 of epoch 1, 54.06 ms/it, loss 0.473717
Finished training it 147456/153485 of epoch 1, 54.25 ms/it, loss 0.472776
Finished training it 148480/153485 of epoch 1, 48.93 ms/it, loss 0.469333
Finished training it 148480/153485 of epoch 1, 48.80 ms/it, loss 0.475334
Finished training it 149504/153485 of epoch 1, 48.81 ms/it, loss 0.474443
Finished training it 149504/153485 of epoch 1, 48.83 ms/it, loss 0.472447
Finished training it 150528/153485 of epoch 1, 49.04 ms/it, loss 0.468789
Finished training it 150528/153485 of epoch 1, 48.95 ms/it, loss 0.472136
Finished training it 151552/153485 of epoch 1, 49.16 ms/it, loss 0.472884
Finished training it 151552/153485 of epoch 1, 49.31 ms/it, loss 0.473477
Finished training it 152576/153485 of epoch 1, 49.47 ms/it, loss 0.474801
Finished training it 152576/153485 of epoch 1, 49.41 ms/it, loss 0.472773
Warning: Skipping the batch 153484 with size 27
Finished training it 1024/153485 of epoch 2, 50.65 ms/it, loss 0.474436
Warning: Skipping the batch 153484 with size 27
Finished training it 1024/153485 of epoch 2, 49.92 ms/it, loss 0.473789
Finished training it 2048/153485 of epoch 2, 50.02 ms/it, loss 0.473475
Finished training it 2048/153485 of epoch 2, 50.05 ms/it, loss 0.472899
Finished training it 3072/153485 of epoch 2, 49.48 ms/it, loss 0.475827
Finished training it 3072/153485 of epoch 2, 49.34 ms/it, loss 0.470983
Finished training it 4096/153485 of epoch 2, 48.78 ms/it, loss 0.472320
Finished training it 4096/153485 of epoch 2, 48.79 ms/it, loss 0.471925
Finished training it 5120/153485 of epoch 2, 54.43 ms/it, loss 0.470528
Finished training it 5120/153485 of epoch 2, 54.84 ms/it, loss 0.473001
Finished training it 6144/153485 of epoch 2, 49.02 ms/it, loss 0.470893
Finished training it 6144/153485 of epoch 2, 48.87 ms/it, loss 0.472592
Finished training it 7168/153485 of epoch 2, 49.52 ms/it, loss 0.473804
Finished training it 7168/153485 of epoch 2, 49.42 ms/it, loss 0.472199
Finished training it 8192/153485 of epoch 2, 49.21 ms/it, loss 0.469262
Finished training it 8192/153485 of epoch 2, 49.17 ms/it, loss 0.472592
Finished training it 9216/153485 of epoch 2, 48.75 ms/it, loss 0.475055
Finished training it 9216/153485 of epoch 2, 49.15 ms/it, loss 0.474551
Finished training it 10240/153485 of epoch 2, 49.33 ms/it, loss 0.473089
Finished training it 10240/153485 of epoch 2, 49.17 ms/it, loss 0.474456
Testing at - 10240/153485 of epoch 2,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216rank: 0 test_accu: 2537503.0
get out
0 has test check 2537503.0 and sample count 3274330
 accuracy 77.497 %, best 77.497 %, roc auc score 0.7707, best 0.7707
Testing at - 10240/153485 of epoch 2,
rank: 1 test_accu: 2537503.0
get out
1 has test check 2537503.0 and sample count 3274330
Finished training it 11264/153485 of epoch 2, 49.35 ms/it, loss 0.471659
Saving model to /rscratch/data/dlrm_criteo/save_model_after_training_one1.0.pt
Finished training it 11264/153485 of epoch 2, 49.29 ms/it, loss 0.470906
Finished training it 12288/153485 of epoch 2, 49.73 ms/it, loss 0.469921
Finished training it 12288/153485 of epoch 2, 49.87 ms/it, loss 0.471291
Finished training it 13312/153485 of epoch 2, 48.65 ms/it, loss 0.471214
Finished training it 13312/153485 of epoch 2, 48.75 ms/it, loss 0.475397
Finished training it 14336/153485 of epoch 2, 49.30 ms/it, loss 0.472634
Finished training it 14336/153485 of epoch 2, 49.06 ms/it, loss 0.472378
Finished training it 15360/153485 of epoch 2, 49.83 ms/it, loss 0.470400
Finished training it 15360/153485 of epoch 2, 49.65 ms/it, loss 0.472491
Finished training it 16384/153485 of epoch 2, 49.20 ms/it, loss 0.471136
Finished training it 16384/153485 of epoch 2, 49.41 ms/it, loss 0.470975
Finished training it 17408/153485 of epoch 2, 49.44 ms/it, loss 0.471241
Finished training it 17408/153485 of epoch 2, 49.44 ms/it, loss 0.473984
Finished training it 18432/153485 of epoch 2, 49.01 ms/it, loss 0.471933
Finished training it 18432/153485 of epoch 2, 49.14 ms/it, loss 0.471658
Finished training it 19456/153485 of epoch 2, 49.44 ms/it, loss 0.471734
Finished training it 19456/153485 of epoch 2, 49.55 ms/it, loss 0.469436
Finished training it 20480/153485 of epoch 2, 48.76 ms/it, loss 0.471307
Finished training it 20480/153485 of epoch 2, 48.66 ms/it, loss 0.471671
Testing at - 20480/153485 of epoch 2,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216rank: 0 test_accu: 2537744.0
get out
0 has test check 2537744.0 and sample count 3274330
 accuracy 77.504 %, best 77.504 %, roc auc score 0.7710, best 0.7710
Testing at - 20480/153485 of epoch 2,
rank: 1 test_accu: 2537744.0
get out
1 has test check 2537744.0 and sample count 3274330
Finished training it 21504/153485 of epoch 2, 48.08 ms/it, loss 0.469035
Saving model to /rscratch/data/dlrm_criteo/save_model_after_training_one0.0.pt
Finished training it 21504/153485 of epoch 2, 48.04 ms/it, loss 0.469363
Finished training it 22528/153485 of epoch 2, 48.96 ms/it, loss 0.472941
Finished training it 22528/153485 of epoch 2, 48.82 ms/it, loss 0.471577
Finished training it 23552/153485 of epoch 2, 48.50 ms/it, loss 0.472481
Finished training it 23552/153485 of epoch 2, 48.61 ms/it, loss 0.470161
Finished training it 24576/153485 of epoch 2, 54.63 ms/it, loss 0.471830
Finished training it 24576/153485 of epoch 2, 55.15 ms/it, loss 0.472378
Finished training it 25600/153485 of epoch 2, 54.91 ms/it, loss 0.471679
Finished training it 25600/153485 of epoch 2, 54.69 ms/it, loss 0.466498
Finished training it 26624/153485 of epoch 2, 49.29 ms/it, loss 0.473994
Finished training it 26624/153485 of epoch 2, 49.23 ms/it, loss 0.471809
Finished training it 27648/153485 of epoch 2, 49.46 ms/it, loss 0.470572
Finished training it 27648/153485 of epoch 2, 49.46 ms/it, loss 0.470192
Finished training it 28672/153485 of epoch 2, 48.65 ms/it, loss 0.470427
Finished training it 28672/153485 of epoch 2, 48.44 ms/it, loss 0.472361
Finished training it 29696/153485 of epoch 2, 49.63 ms/it, loss 0.471419
Finished training it 29696/153485 of epoch 2, 49.42 ms/it, loss 0.470096
Finished training it 30720/153485 of epoch 2, 49.88 ms/it, loss 0.470919
Finished training it 30720/153485 of epoch 2, 49.80 ms/it, loss 0.471608
Testing at - 30720/153485 of epoch 2,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216rank: 0 test_accu: 2539937.0
get out
0 has test check 2539937.0 and sample count 3274330
 accuracy 77.571 %, best 77.571 %, roc auc score 0.7719, best 0.7719
Saving model to /rscratch/data/dlrm_criteo/save_model_after_training_one1.0.pt
Finished training it 31744/153485 of epoch 2, 49.39 ms/it, loss 0.471534
Testing at - 30720/153485 of epoch 2,
rank: 1 test_accu: 2539937.0
get out
1 has test check 2539937.0 and sample count 3274330
Finished training it 31744/153485 of epoch 2, 49.33 ms/it, loss 0.469641
Finished training it 32768/153485 of epoch 2, 49.44 ms/it, loss 0.468086
Finished training it 32768/153485 of epoch 2, 49.39 ms/it, loss 0.472346
Finished training it 33792/153485 of epoch 2, 48.94 ms/it, loss 0.470886
Finished training it 33792/153485 of epoch 2, 49.24 ms/it, loss 0.470010
Finished training it 34816/153485 of epoch 2, 48.83 ms/it, loss 0.470074
Finished training it 34816/153485 of epoch 2, 48.85 ms/it, loss 0.471361
Finished training it 35840/153485 of epoch 2, 49.51 ms/it, loss 0.469707
Finished training it 35840/153485 of epoch 2, 49.69 ms/it, loss 0.468186
Finished training it 36864/153485 of epoch 2, 49.26 ms/it, loss 0.472756
Finished training it 36864/153485 of epoch 2, 49.33 ms/it, loss 0.471439
Finished training it 37888/153485 of epoch 2, 48.90 ms/it, loss 0.471293
Finished training it 37888/153485 of epoch 2, 48.97 ms/it, loss 0.468968
Finished training it 38912/153485 of epoch 2, 49.48 ms/it, loss 0.470870
Finished training it 38912/153485 of epoch 2, 49.74 ms/it, loss 0.468044
Finished training it 39936/153485 of epoch 2, 49.29 ms/it, loss 0.472102
Finished training it 39936/153485 of epoch 2, 49.55 ms/it, loss 0.471061
Finished training it 40960/153485 of epoch 2, 49.87 ms/it, loss 0.470635
Finished training it 40960/153485 of epoch 2, 49.61 ms/it, loss 0.469795
Testing at - 40960/153485 of epoch 2,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216rank: 0 test_accu: 2539674.0
get out
0 has test check 2539674.0 and sample count 3274330
 accuracy 77.563 %, best 77.571 %, roc auc score 0.7717, best 0.7719
Finished training it 41984/153485 of epoch 2, 49.25 ms/it, loss 0.468377
Testing at - 40960/153485 of epoch 2,
rank: 1 test_accu: 2539674.0
get out
1 has test check 2539674.0 and sample count 3274330
Finished training it 41984/153485 of epoch 2, 49.38 ms/it, loss 0.468815
Finished training it 43008/153485 of epoch 2, 49.68 ms/it, loss 0.471257
Finished training it 43008/153485 of epoch 2, 49.71 ms/it, loss 0.472224
Finished training it 44032/153485 of epoch 2, 49.07 ms/it, loss 0.469018
Finished training it 44032/153485 of epoch 2, 49.18 ms/it, loss 0.472277
Finished training it 45056/153485 of epoch 2, 49.10 ms/it, loss 0.470491
Finished training it 45056/153485 of epoch 2, 48.96 ms/it, loss 0.473226
Finished training it 46080/153485 of epoch 2, 60.80 ms/it, loss 0.471194
Finished training it 46080/153485 of epoch 2, 60.35 ms/it, loss 0.470413
Finished training it 47104/153485 of epoch 2, 49.81 ms/it, loss 0.470689
Finished training it 47104/153485 of epoch 2, 49.62 ms/it, loss 0.469452
Finished training it 48128/153485 of epoch 2, 48.92 ms/it, loss 0.472032
Finished training it 48128/153485 of epoch 2, 48.90 ms/it, loss 0.472257
Finished training it 49152/153485 of epoch 2, 49.31 ms/it, loss 0.471914
Finished training it 49152/153485 of epoch 2, 49.33 ms/it, loss 0.469319
Finished training it 50176/153485 of epoch 2, 49.22 ms/it, loss 0.467719
Finished training it 50176/153485 of epoch 2, 49.08 ms/it, loss 0.468928
Finished training it 51200/153485 of epoch 2, 49.82 ms/it, loss 0.474333
Finished training it 51200/153485 of epoch 2, 49.88 ms/it, loss 0.470212
Testing at - 51200/153485 of epoch 2,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216rank: 0 test_accu: 2540582.0
get out
0 has test check 2540582.0 and sample count 3274330
 accuracy 77.591 %, best 77.591 %, roc auc score 0.7725, best 0.7725
Saving model to /rscratch/data/dlrm_criteo/save_model_after_training_one1.0.pt
Finished training it 52224/153485 of epoch 2, 48.26 ms/it, loss 0.469684
Testing at - 51200/153485 of epoch 2,
rank: 1 test_accu: 2540582.0
get out
1 has test check 2540582.0 and sample count 3274330
Finished training it 52224/153485 of epoch 2, 48.24 ms/it, loss 0.470783
Finished training it 53248/153485 of epoch 2, 49.18 ms/it, loss 0.465650
Finished training it 53248/153485 of epoch 2, 49.35 ms/it, loss 0.465960
Finished training it 54272/153485 of epoch 2, 47.97 ms/it, loss 0.470773
Finished training it 54272/153485 of epoch 2, 48.12 ms/it, loss 0.468940
Finished training it 55296/153485 of epoch 2, 47.95 ms/it, loss 0.468771
Finished training it 55296/153485 of epoch 2, 47.81 ms/it, loss 0.470220
Finished training it 56320/153485 of epoch 2, 48.32 ms/it, loss 0.471915
Finished training it 56320/153485 of epoch 2, 48.41 ms/it, loss 0.471803
Finished training it 57344/153485 of epoch 2, 49.36 ms/it, loss 0.468107
Finished training it 57344/153485 of epoch 2, 49.23 ms/it, loss 0.471450
Finished training it 58368/153485 of epoch 2, 49.08 ms/it, loss 0.470704
Finished training it 58368/153485 of epoch 2, 49.16 ms/it, loss 0.467757
Finished training it 59392/153485 of epoch 2, 48.85 ms/it, loss 0.467004
Finished training it 59392/153485 of epoch 2, 49.00 ms/it, loss 0.468688
Finished training it 60416/153485 of epoch 2, 49.58 ms/it, loss 0.470928
Finished training it 60416/153485 of epoch 2, 49.60 ms/it, loss 0.472118
Finished training it 61440/153485 of epoch 2, 48.86 ms/it, loss 0.469563
Finished training it 61440/153485 of epoch 2, 48.85 ms/it, loss 0.468138
Testing at - 61440/153485 of epoch 2,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216rank: 0 test_accu: 2541311.0
get out
0 has test check 2541311.0 and sample count 3274330
 accuracy 77.613 %, best 77.613 %, roc auc score 0.7726, best 0.7726
Saving model to /rscratch/data/dlrm_criteo/save_model_after_training_one0.0.pt
Finished training it 62464/153485 of epoch 2, 49.08 ms/it, loss 0.470061
Testing at - 61440/153485 of epoch 2,
rank: 1 test_accu: 2541311.0
get out
1 has test check 2541311.0 and sample count 3274330
Finished training it 62464/153485 of epoch 2, 49.26 ms/it, loss 0.470609
Finished training it 63488/153485 of epoch 2, 49.99 ms/it, loss 0.471625
Finished training it 63488/153485 of epoch 2, 49.73 ms/it, loss 0.467243
Finished training it 64512/153485 of epoch 2, 49.83 ms/it, loss 0.469650
Finished training it 64512/153485 of epoch 2, 50.03 ms/it, loss 0.468690
Finished training it 65536/153485 of epoch 2, 59.68 ms/it, loss 0.471091
Finished training it 65536/153485 of epoch 2, 59.78 ms/it, loss 0.471554
Finished training it 66560/153485 of epoch 2, 49.31 ms/it, loss 0.468951
Finished training it 66560/153485 of epoch 2, 49.50 ms/it, loss 0.469379
Finished training it 67584/153485 of epoch 2, 49.02 ms/it, loss 0.471445
Finished training it 67584/153485 of epoch 2, 48.87 ms/it, loss 0.468265
Finished training it 68608/153485 of epoch 2, 48.50 ms/it, loss 0.470689
Finished training it 68608/153485 of epoch 2, 48.43 ms/it, loss 0.471898
Finished training it 69632/153485 of epoch 2, 49.20 ms/it, loss 0.470797
Finished training it 69632/153485 of epoch 2, 49.36 ms/it, loss 0.467591
Finished training it 70656/153485 of epoch 2, 49.26 ms/it, loss 0.471517
Finished training it 70656/153485 of epoch 2, 49.44 ms/it, loss 0.470086
Finished training it 71680/153485 of epoch 2, 49.52 ms/it, loss 0.470979
Finished training it 71680/153485 of epoch 2, 49.53 ms/it, loss 0.470999
Testing at - 71680/153485 of epoch 2,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216rank: 0 test_accu: 2540675.0
get out
0 has test check 2540675.0 and sample count 3274330
 accuracy 77.594 %, best 77.613 %, roc auc score 0.7725, best 0.7726
Finished training it 72704/153485 of epoch 2, 48.44 ms/it, loss 0.470774
Testing at - 71680/153485 of epoch 2,
rank: 1 test_accu: 2540675.0
get out
1 has test check 2540675.0 and sample count 3274330
Finished training it 72704/153485 of epoch 2, 48.61 ms/it, loss 0.468565
Finished training it 73728/153485 of epoch 2, 49.55 ms/it, loss 0.469885
Finished training it 73728/153485 of epoch 2, 49.67 ms/it, loss 0.471908
Finished training it 74752/153485 of epoch 2, 49.77 ms/it, loss 0.471261
Finished training it 74752/153485 of epoch 2, 49.67 ms/it, loss 0.470816
Finished training it 75776/153485 of epoch 2, 49.20 ms/it, loss 0.468957
Finished training it 75776/153485 of epoch 2, 49.39 ms/it, loss 0.472125
Finished training it 76800/153485 of epoch 2, 48.34 ms/it, loss 0.470450
Finished training it 76800/153485 of epoch 2, 48.27 ms/it, loss 0.472784
Finished training it 77824/153485 of epoch 2, 48.48 ms/it, loss 0.470760
Finished training it 77824/153485 of epoch 2, 48.34 ms/it, loss 0.469711
Finished training it 78848/153485 of epoch 2, 48.37 ms/it, loss 0.469829
Finished training it 78848/153485 of epoch 2, 48.48 ms/it, loss 0.472175
Finished training it 79872/153485 of epoch 2, 49.83 ms/it, loss 0.468065
Finished training it 79872/153485 of epoch 2, 49.73 ms/it, loss 0.468840
Finished training it 80896/153485 of epoch 2, 49.18 ms/it, loss 0.470538
Finished training it 80896/153485 of epoch 2, 49.10 ms/it, loss 0.471200
Finished training it 81920/153485 of epoch 2, 50.00 ms/it, loss 0.470069
Finished training it 81920/153485 of epoch 2, 49.80 ms/it, loss 0.467910
Testing at - 81920/153485 of epoch 2,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216rank: 0 test_accu: 2540943.0
get out
0 has test check 2540943.0 and sample count 3274330
 accuracy 77.602 %, best 77.613 %, roc auc score 0.7733, best 0.7733
Finished training it 82944/153485 of epoch 2, 48.67 ms/it, loss 0.470164
Testing at - 81920/153485 of epoch 2,
rank: 1 test_accu: 2540943.0
get out
1 has test check 2540943.0 and sample count 3274330
Finished training it 82944/153485 of epoch 2, 48.69 ms/it, loss 0.471300
Finished training it 83968/153485 of epoch 2, 47.95 ms/it, loss 0.473090
Finished training it 83968/153485 of epoch 2, 48.04 ms/it, loss 0.470182
Finished training it 84992/153485 of epoch 2, 49.01 ms/it, loss 0.468998
Finished training it 84992/153485 of epoch 2, 49.01 ms/it, loss 0.470372
Finished training it 86016/153485 of epoch 2, 60.84 ms/it, loss 0.468707
Finished training it 86016/153485 of epoch 2, 61.01 ms/it, loss 0.468966
Finished training it 87040/153485 of epoch 2, 49.13 ms/it, loss 0.466845
Finished training it 87040/153485 of epoch 2, 49.13 ms/it, loss 0.467449
Finished training it 88064/153485 of epoch 2, 48.73 ms/it, loss 0.470616
Finished training it 88064/153485 of epoch 2, 48.62 ms/it, loss 0.468792
Finished training it 89088/153485 of epoch 2, 49.04 ms/it, loss 0.468651
Finished training it 89088/153485 of epoch 2, 49.21 ms/it, loss 0.470578
Finished training it 90112/153485 of epoch 2, 49.30 ms/it, loss 0.470275
Finished training it 90112/153485 of epoch 2, 49.25 ms/it, loss 0.472216
Finished training it 91136/153485 of epoch 2, 48.34 ms/it, loss 0.470132
Finished training it 91136/153485 of epoch 2, 48.44 ms/it, loss 0.472332
Finished training it 92160/153485 of epoch 2, 49.24 ms/it, loss 0.470917
Finished training it 92160/153485 of epoch 2, 48.99 ms/it, loss 0.470405
Testing at - 92160/153485 of epoch 2,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216rank: 0 test_accu: 2543008.0
get out
0 has test check 2543008.0 and sample count 3274330
 accuracy 77.665 %, best 77.665 %, roc auc score 0.7741, best 0.7741
Testing at - 92160/153485 of epoch 2,
rank: 1 test_accu: 2543008.0
get out
1 has test check 2543008.0 and sample count 3274330
Finished training it 93184/153485 of epoch 2, 48.55 ms/it, loss 0.469543
Saving model to /rscratch/data/dlrm_criteo/save_model_after_training_one1.0.pt
Finished training it 93184/153485 of epoch 2, 48.69 ms/it, loss 0.470206
Finished training it 94208/153485 of epoch 2, 49.72 ms/it, loss 0.469451
Finished training it 94208/153485 of epoch 2, 49.90 ms/it, loss 0.470138
Finished training it 95232/153485 of epoch 2, 48.52 ms/it, loss 0.470088
Finished training it 95232/153485 of epoch 2, 48.70 ms/it, loss 0.469613
Finished training it 96256/153485 of epoch 2, 48.88 ms/it, loss 0.467601
Finished training it 96256/153485 of epoch 2, 48.94 ms/it, loss 0.473658
Finished training it 97280/153485 of epoch 2, 48.61 ms/it, loss 0.468921
Finished training it 97280/153485 of epoch 2, 48.72 ms/it, loss 0.467226
Finished training it 98304/153485 of epoch 2, 49.03 ms/it, loss 0.468771
Finished training it 98304/153485 of epoch 2, 49.13 ms/it, loss 0.468662
Finished training it 99328/153485 of epoch 2, 49.39 ms/it, loss 0.469209
Finished training it 99328/153485 of epoch 2, 49.24 ms/it, loss 0.468095
Finished training it 100352/153485 of epoch 2, 49.66 ms/it, loss 0.469495
Finished training it 100352/153485 of epoch 2, 49.50 ms/it, loss 0.469440
Finished training it 101376/153485 of epoch 2, 49.64 ms/it, loss 0.472431
Finished training it 101376/153485 of epoch 2, 49.82 ms/it, loss 0.469510
Finished training it 102400/153485 of epoch 2, 48.89 ms/it, loss 0.466602
Finished training it 102400/153485 of epoch 2, 48.83 ms/it, loss 0.466887
Testing at - 102400/153485 of epoch 2,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216rank: 0 test_accu: 2541235.0
get out
0 has test check 2541235.0 and sample count 3274330
 accuracy 77.611 %, best 77.665 %, roc auc score 0.7735, best 0.7741
Finished training it 103424/153485 of epoch 2, 48.39 ms/it, loss 0.469831
Testing at - 102400/153485 of epoch 2,
rank: 1 test_accu: 2541235.0
get out
1 has test check 2541235.0 and sample count 3274330
Finished training it 103424/153485 of epoch 2, 48.34 ms/it, loss 0.468017
Finished training it 104448/153485 of epoch 2, 48.19 ms/it, loss 0.473012
Finished training it 104448/153485 of epoch 2, 48.26 ms/it, loss 0.467207
Finished training it 105472/153485 of epoch 2, 49.23 ms/it, loss 0.472119
Finished training it 105472/153485 of epoch 2, 49.05 ms/it, loss 0.468192
Finished training it 106496/153485 of epoch 2, 50.17 ms/it, loss 0.471860
Finished training it 106496/153485 of epoch 2, 50.29 ms/it, loss 0.471080
Finished training it 107520/153485 of epoch 2, 59.54 ms/it, loss 0.467006
Finished training it 107520/153485 of epoch 2, 59.36 ms/it, loss 0.470729
Finished training it 108544/153485 of epoch 2, 49.64 ms/it, loss 0.467343
Finished training it 108544/153485 of epoch 2, 49.78 ms/it, loss 0.470656
Finished training it 109568/153485 of epoch 2, 49.63 ms/it, loss 0.469270
Finished training it 109568/153485 of epoch 2, 49.51 ms/it, loss 0.469703
Finished training it 110592/153485 of epoch 2, 49.67 ms/it, loss 0.468502
Finished training it 110592/153485 of epoch 2, 49.67 ms/it, loss 0.469016
Finished training it 111616/153485 of epoch 2, 49.68 ms/it, loss 0.467494
Finished training it 111616/153485 of epoch 2, 49.61 ms/it, loss 0.465177
Finished training it 112640/153485 of epoch 2, 48.93 ms/it, loss 0.467648
Finished training it 112640/153485 of epoch 2, 49.05 ms/it, loss 0.470772
Testing at - 112640/153485 of epoch 2,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216rank: 0 test_accu: 2542546.0
get out
0 has test check 2542546.0 and sample count 3274330
 accuracy 77.651 %, best 77.665 %, roc auc score 0.7737, best 0.7741
Testing at - 112640/153485 of epoch 2,
rank: 1 test_accu: 2542546.0
get out
1 has test check 2542546.0 and sample count 3274330
Finished training it 113664/153485 of epoch 2, 49.12 ms/it, loss 0.470057
Finished training it 113664/153485 of epoch 2, 49.11 ms/it, loss 0.466989
Finished training it 114688/153485 of epoch 2, 48.26 ms/it, loss 0.468638
Finished training it 114688/153485 of epoch 2, 48.29 ms/it, loss 0.466375
Finished training it 115712/153485 of epoch 2, 48.94 ms/it, loss 0.469545
Finished training it 115712/153485 of epoch 2, 49.20 ms/it, loss 0.465456
Finished training it 116736/153485 of epoch 2, 49.01 ms/it, loss 0.468945
Finished training it 116736/153485 of epoch 2, 48.94 ms/it, loss 0.468692
Finished training it 117760/153485 of epoch 2, 49.64 ms/it, loss 0.468561
Finished training it 117760/153485 of epoch 2, 49.59 ms/it, loss 0.469623
Finished training it 118784/153485 of epoch 2, 48.52 ms/it, loss 0.467380
Finished training it 118784/153485 of epoch 2, 48.44 ms/it, loss 0.465017
Finished training it 119808/153485 of epoch 2, 49.23 ms/it, loss 0.465952
Finished training it 119808/153485 of epoch 2, 49.54 ms/it, loss 0.467796
Finished training it 120832/153485 of epoch 2, 48.92 ms/it, loss 0.465674
Finished training it 120832/153485 of epoch 2, 48.99 ms/it, loss 0.469113
Finished training it 121856/153485 of epoch 2, 49.33 ms/it, loss 0.468482
Finished training it 121856/153485 of epoch 2, 49.48 ms/it, loss 0.469594
Finished training it 122880/153485 of epoch 2, 48.27 ms/it, loss 0.466903
Finished training it 122880/153485 of epoch 2, 48.35 ms/it, loss 0.468263
Testing at - 122880/153485 of epoch 2,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216rank: 0 test_accu: 2543298.0
get out
0 has test check 2543298.0 and sample count 3274330
 accuracy 77.674 %, best 77.674 %, roc auc score 0.7746, best 0.7746
Testing at - 122880/153485 of epoch 2,
rank: 1 test_accu: 2543298.0
get out
1 has test check 2543298.0 and sample count 3274330
Finished training it 123904/153485 of epoch 2, 49.08 ms/it, loss 0.467800
Saving model to /rscratch/data/dlrm_criteo/save_model_after_training_one0.0.pt
Finished training it 123904/153485 of epoch 2, 48.89 ms/it, loss 0.468616
Finished training it 124928/153485 of epoch 2, 48.89 ms/it, loss 0.470631
Finished training it 124928/153485 of epoch 2, 48.75 ms/it, loss 0.468652
Finished training it 125952/153485 of epoch 2, 50.11 ms/it, loss 0.468677
Finished training it 125952/153485 of epoch 2, 49.93 ms/it, loss 0.468996
Finished training it 126976/153485 of epoch 2, 53.27 ms/it, loss 0.468548
Finished training it 126976/153485 of epoch 2, 53.52 ms/it, loss 0.468680
Finished training it 128000/153485 of epoch 2, 53.70 ms/it, loss 0.468426
Finished training it 128000/153485 of epoch 2, 53.88 ms/it, loss 0.467226
Finished training it 129024/153485 of epoch 2, 48.76 ms/it, loss 0.471257
Finished training it 129024/153485 of epoch 2, 48.97 ms/it, loss 0.469950
Finished training it 130048/153485 of epoch 2, 49.10 ms/it, loss 0.466955
Finished training it 130048/153485 of epoch 2, 48.92 ms/it, loss 0.466963
Finished training it 131072/153485 of epoch 2, 49.34 ms/it, loss 0.468387
Finished training it 131072/153485 of epoch 2, 49.38 ms/it, loss 0.468126
Finished training it 132096/153485 of epoch 2, 49.08 ms/it, loss 0.469914
Finished training it 132096/153485 of epoch 2, 49.10 ms/it, loss 0.468977
Finished training it 133120/153485 of epoch 2, 48.16 ms/it, loss 0.468594
Finished training it 133120/153485 of epoch 2, 48.28 ms/it, loss 0.465886
Testing at - 133120/153485 of epoch 2,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216rank: 0 test_accu: 2545235.0
get out
0 has test check 2545235.0 and sample count 3274330
 accuracy 77.733 %, best 77.733 %, roc auc score 0.7761, best 0.7761
Saving model to /rscratch/data/dlrm_criteo/save_model_after_training_one1.0.pt
Finished training it 134144/153485 of epoch 2, 48.58 ms/it, loss 0.466638
Testing at - 133120/153485 of epoch 2,
rank: 1 test_accu: 2545235.0
get out
1 has test check 2545235.0 and sample count 3274330
Finished training it 134144/153485 of epoch 2, 48.61 ms/it, loss 0.467289
Finished training it 135168/153485 of epoch 2, 48.66 ms/it, loss 0.466933
Finished training it 135168/153485 of epoch 2, 48.50 ms/it, loss 0.466912
Finished training it 136192/153485 of epoch 2, 50.02 ms/it, loss 0.467794
Finished training it 136192/153485 of epoch 2, 50.06 ms/it, loss 0.467051
Finished training it 137216/153485 of epoch 2, 49.33 ms/it, loss 0.468355
Finished training it 137216/153485 of epoch 2, 49.26 ms/it, loss 0.469354
Finished training it 138240/153485 of epoch 2, 49.11 ms/it, loss 0.467129
Finished training it 138240/153485 of epoch 2, 49.05 ms/it, loss 0.467918
Finished training it 139264/153485 of epoch 2, 49.59 ms/it, loss 0.468036
Finished training it 139264/153485 of epoch 2, 49.61 ms/it, loss 0.465970
Finished training it 140288/153485 of epoch 2, 49.42 ms/it, loss 0.468475
Finished training it 140288/153485 of epoch 2, 49.33 ms/it, loss 0.465640
Finished training it 141312/153485 of epoch 2, 49.35 ms/it, loss 0.469660
Finished training it 141312/153485 of epoch 2, 49.59 ms/it, loss 0.465487
Finished training it 142336/153485 of epoch 2, 49.36 ms/it, loss 0.467015
Finished training it 142336/153485 of epoch 2, 49.20 ms/it, loss 0.467649
Finished training it 143360/153485 of epoch 2, 48.69 ms/it, loss 0.469087
Finished training it 143360/153485 of epoch 2, 48.69 ms/it, loss 0.466899
Testing at - 143360/153485 of epoch 2,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216rank: 0 test_accu: 2544391.0
get out
0 has test check 2544391.0 and sample count 3274330
 accuracy 77.707 %, best 77.733 %, roc auc score 0.7758, best 0.7761
Testing at - 143360/153485 of epoch 2,
rank: 1 test_accu: 2544391.0
get out
1 has test check 2544391.0 and sample count 3274330
Finished training it 144384/153485 of epoch 2, 48.98 ms/it, loss 0.466334
Finished training it 144384/153485 of epoch 2, 49.04 ms/it, loss 0.465204
Finished training it 145408/153485 of epoch 2, 49.09 ms/it, loss 0.470249
Finished training it 145408/153485 of epoch 2, 49.04 ms/it, loss 0.468479
Finished training it 146432/153485 of epoch 2, 49.24 ms/it, loss 0.468655
Finished training it 146432/153485 of epoch 2, 49.26 ms/it, loss 0.469583
Finished training it 147456/153485 of epoch 2, 61.68 ms/it, loss 0.469050
Finished training it 147456/153485 of epoch 2, 61.43 ms/it, loss 0.467718
Finished training it 148480/153485 of epoch 2, 48.45 ms/it, loss 0.464429
Finished training it 148480/153485 of epoch 2, 48.66 ms/it, loss 0.470305
Finished training it 149504/153485 of epoch 2, 49.56 ms/it, loss 0.467327
Finished training it 149504/153485 of epoch 2, 49.62 ms/it, loss 0.469234
Finished training it 150528/153485 of epoch 2, 48.81 ms/it, loss 0.466788
Finished training it 150528/153485 of epoch 2, 48.66 ms/it, loss 0.463646
Finished training it 151552/153485 of epoch 2, 48.96 ms/it, loss 0.468642
Finished training it 151552/153485 of epoch 2, 49.17 ms/it, loss 0.467816
Finished training it 152576/153485 of epoch 2, 49.33 ms/it, loss 0.470366
Finished training it 152576/153485 of epoch 2, 49.28 ms/it, loss 0.467853
Warning: Skipping the batch 153484 with size 27
Testing at - 153485/153485 of epoch 3,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216rank: 0 test_accu: 2545448.0
get out
0 has test check 2545448.0 and sample count 3274330
 accuracy 77.740 %, best 77.740 %, roc auc score 0.7764, best 0.7764
Saving model to /rscratch/data/dlrm_criteo/save_model_after_training_one0.98876953125.pt
Warning: Skipping the batch 153484 with size 27
Testing at - 153485/153485 of epoch 3,
rank: 1 test_accu: 2545448.0
get out
1 has test check 2545448.0 and sample count 3274330
