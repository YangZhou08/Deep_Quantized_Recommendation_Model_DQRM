Unable to import mlperf_logging,  No module named 'mlperf_logging'
Unable to import mlperf_logging,  No module named 'mlperf_logging'
Warning: local_rank gpu mismatch
4 out of -1 (GPU)
Reading pre-processed data=/rscratch/data/dlrm_criteo/kaggleAdDisplayChallenge_processed.npz
Sparse fea = 26, Dense fea = 13
Defined train indices...
Randomized indices across days ...
Split data according to indices...
Reading pre-processed data=/rscratch/data/dlrm_criteo/kaggleAdDisplayChallenge_processed.npz
Sparse fea = 26, Dense fea = 13
Defined test indices...
Randomized indices across days ...
Split data according to indices...
number of devices 1
world size found is -1
optimizer selected is  sgd
Finished training it 1024/76743 of epoch 0, 55.31 ms/it, loss 0.516167
Unable to import mlperf_logging,  No module named 'mlperf_logging'
Warning: local_rank gpu mismatch
4 out of -1 (GPU)
Reading pre-processed data=/rscratch/data/dlrm_criteo/kaggleAdDisplayChallenge_processed.npz
Sparse fea = 26, Dense fea = 13
Defined train indices...
Randomized indices across days ...
Split data according to indices...
Reading pre-processed data=/rscratch/data/dlrm_criteo/kaggleAdDisplayChallenge_processed.npz
Sparse fea = 26, Dense fea = 13
Defined test indices...
Randomized indices across days ...
Split data according to indices...
number of devices 1
world size found is -1
optimizer selected is  sgd
Finished training it 1024/76743 of epoch 0, 53.15 ms/it, loss 0.515170
Unable to import mlperf_logging,  No module named 'mlperf_logging'
Warning: local_rank gpu mismatch
4 out of -1 (GPU)
Reading pre-processed data=/rscratch/data/dlrm_criteo/kaggleAdDisplayChallenge_processed.npz
Sparse fea = 26, Dense fea = 13
Defined train indices...
Randomized indices across days ...
Split data according to indices...
Reading pre-processed data=/rscratch/data/dlrm_criteo/kaggleAdDisplayChallenge_processed.npz
Sparse fea = 26, Dense fea = 13
Defined test indices...
Randomized indices across days ...
Split data according to indices...
number of devices 1
world size found is -1
optimizer selected is  sgd
Finished training it 1024/76743 of epoch 0, 54.84 ms/it, loss 0.515087
Unable to import mlperf_logging,  No module named 'mlperf_logging'
Warning: local_rank gpu mismatch
4 out of -1 (GPU)
Reading pre-processed data=/rscratch/data/dlrm_criteo/kaggleAdDisplayChallenge_processed.npz
Sparse fea = 26, Dense fea = 13
Defined train indices...
Randomized indices across days ...
Split data according to indices...
Reading pre-processed data=/rscratch/data/dlrm_criteo/kaggleAdDisplayChallenge_processed.npz
Sparse fea = 26, Dense fea = 13
Defined test indices...
Randomized indices across days ...
Split data according to indices...
number of devices 1
world size found is -1
optimizer selected is  sgd
Finished training it 1024/76743 of epoch 0, 53.22 ms/it, loss 0.515641
Finished training it 2048/76743 of epoch 0, 50.94 ms/it, loss 0.500341
Finished training it 2048/76743 of epoch 0, 50.86 ms/it, loss 0.499848
Finished training it 2048/76743 of epoch 0, 50.86 ms/it, loss 0.499089
Finished training it 2048/76743 of epoch 0, 50.83 ms/it, loss 0.501554
Finished training it 3072/76743 of epoch 0, 50.39 ms/it, loss 0.490934
Finished training it 3072/76743 of epoch 0, 50.23 ms/it, loss 0.489168
Finished training it 3072/76743 of epoch 0, 50.55 ms/it, loss 0.490154
Finished training it 3072/76743 of epoch 0, 50.46 ms/it, loss 0.488083
Finished training it 4096/76743 of epoch 0, 50.45 ms/it, loss 0.481001
Finished training it 4096/76743 of epoch 0, 49.81 ms/it, loss 0.483392
Finished training it 4096/76743 of epoch 0, 50.29 ms/it, loss 0.480042
Finished training it 4096/76743 of epoch 0, 50.26 ms/it, loss 0.483088
Finished training it 5120/76743 of epoch 0, 49.39 ms/it, loss 0.476266
Finished training it 5120/76743 of epoch 0, 50.19 ms/it, loss 0.474124
Finished training it 5120/76743 of epoch 0, 50.37 ms/it, loss 0.476800
Finished training it 5120/76743 of epoch 0, 50.14 ms/it, loss 0.476654
Finished training it 6144/76743 of epoch 0, 49.94 ms/it, loss 0.474476
Finished training it 6144/76743 of epoch 0, 50.31 ms/it, loss 0.472833
Finished training it 6144/76743 of epoch 0, 49.44 ms/it, loss 0.473392
Finished training it 6144/76743 of epoch 0, 49.94 ms/it, loss 0.473543
Finished training it 7168/76743 of epoch 0, 48.54 ms/it, loss 0.468542
Finished training it 7168/76743 of epoch 0, 48.14 ms/it, loss 0.469939
Finished training it 7168/76743 of epoch 0, 48.10 ms/it, loss 0.469636
Finished training it 7168/76743 of epoch 0, 47.44 ms/it, loss 0.469787
Finished training it 8192/76743 of epoch 0, 46.71 ms/it, loss 0.471104
Finished training it 8192/76743 of epoch 0, 46.85 ms/it, loss 0.468877
Finished training it 8192/76743 of epoch 0, 46.61 ms/it, loss 0.467051
Finished training it 8192/76743 of epoch 0, 45.91 ms/it, loss 0.469754
Finished training it 9216/76743 of epoch 0, 47.24 ms/it, loss 0.465573
Finished training it 9216/76743 of epoch 0, 47.17 ms/it, loss 0.466835
Finished training it 9216/76743 of epoch 0, 46.32 ms/it, loss 0.466410
Finished training it 9216/76743 of epoch 0, 47.12 ms/it, loss 0.467468
Finished training it 10240/76743 of epoch 0, 49.43 ms/it, loss 0.464115
Finished training it 10240/76743 of epoch 0, 49.31 ms/it, loss 0.467501
Finished training it 10240/76743 of epoch 0, 48.12 ms/it, loss 0.464678
Finished training it 10240/76743 of epoch 0, 49.53 ms/it, loss 0.467959
Testing at - 10240/76743 of epoch 0,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216Warning: Skipping the batch 25580 with size 90
rank: 0 test_accu: 2551121.0
get out
0 has test check 2551121.0 and sample count 3274240
 accuracy 77.915 %, best 77.915 %, roc auc score 0.7836, best 0.7836
Testing at - 10240/76743 of epoch 0,
Warning: Skipping the batch 25580 with size 90
rank: 1 test_accu: 2551121.0
get out
1 has test check 2551121.0 and sample count 3274240
Finished training it 11264/76743 of epoch 0, 49.23 ms/it, loss 0.465379
Testing at - 10240/76743 of epoch 0,
Warning: Skipping the batch 25580 with size 90
rank: 2 test_accu: 2551121.0
get out
2 has test check 2551121.0 and sample count 3274240
Finished training it 11264/76743 of epoch 0, 48.13 ms/it, loss 0.466368
Saving model to /rscratch/data/dlrm_criteo/save_model_after_training_one1.0.pt
Finished training it 11264/76743 of epoch 0, 49.65 ms/it, loss 0.464482
Testing at - 10240/76743 of epoch 0,
Warning: Skipping the batch 25580 with size 90
rank: 3 test_accu: 2551121.0
get out
3 has test check 2551121.0 and sample count 3274240
Finished training it 11264/76743 of epoch 0, 49.57 ms/it, loss 0.465481
Finished training it 12288/76743 of epoch 0, 48.60 ms/it, loss 0.460461
Finished training it 12288/76743 of epoch 0, 48.81 ms/it, loss 0.463868
Finished training it 12288/76743 of epoch 0, 48.73 ms/it, loss 0.461544
Finished training it 12288/76743 of epoch 0, 47.67 ms/it, loss 0.460979
Finished training it 13312/76743 of epoch 0, 49.50 ms/it, loss 0.463303
Finished training it 13312/76743 of epoch 0, 49.54 ms/it, loss 0.462461
Finished training it 13312/76743 of epoch 0, 49.52 ms/it, loss 0.461715
Finished training it 13312/76743 of epoch 0, 47.89 ms/it, loss 0.463899
Finished training it 14336/76743 of epoch 0, 49.89 ms/it, loss 0.462212
Finished training it 14336/76743 of epoch 0, 49.82 ms/it, loss 0.462659
Finished training it 14336/76743 of epoch 0, 49.98 ms/it, loss 0.462291
Finished training it 14336/76743 of epoch 0, 48.35 ms/it, loss 0.461872
Finished training it 15360/76743 of epoch 0, 56.16 ms/it, loss 0.458281
Finished training it 15360/76743 of epoch 0, 56.32 ms/it, loss 0.458075
Finished training it 15360/76743 of epoch 0, 55.30 ms/it, loss 0.460209
Finished training it 15360/76743 of epoch 0, 53.88 ms/it, loss 0.461063
Finished training it 16384/76743 of epoch 0, 49.99 ms/it, loss 0.458731
Finished training it 16384/76743 of epoch 0, 49.58 ms/it, loss 0.460652
Finished training it 16384/76743 of epoch 0, 50.06 ms/it, loss 0.459314
Finished training it 16384/76743 of epoch 0, 47.98 ms/it, loss 0.457865
Finished training it 17408/76743 of epoch 0, 48.38 ms/it, loss 0.458858
Finished training it 17408/76743 of epoch 0, 48.44 ms/it, loss 0.458377
Finished training it 17408/76743 of epoch 0, 48.17 ms/it, loss 0.460091
Finished training it 17408/76743 of epoch 0, 47.07 ms/it, loss 0.457636
Finished training it 18432/76743 of epoch 0, 46.65 ms/it, loss 0.458709
Finished training it 18432/76743 of epoch 0, 45.79 ms/it, loss 0.458278
Finished training it 18432/76743 of epoch 0, 46.74 ms/it, loss 0.457175
Finished training it 18432/76743 of epoch 0, 46.77 ms/it, loss 0.458447
Finished training it 19456/76743 of epoch 0, 46.73 ms/it, loss 0.458430
Finished training it 19456/76743 of epoch 0, 46.74 ms/it, loss 0.457354
Finished training it 19456/76743 of epoch 0, 46.44 ms/it, loss 0.461682
Finished training it 19456/76743 of epoch 0, 45.77 ms/it, loss 0.456829
Finished training it 20480/76743 of epoch 0, 49.16 ms/it, loss 0.457291
Finished training it 20480/76743 of epoch 0, 49.27 ms/it, loss 0.456262
Finished training it 20480/76743 of epoch 0, 49.08 ms/it, loss 0.460691
Finished training it 20480/76743 of epoch 0, 48.02 ms/it, loss 0.454993
Testing at - 20480/76743 of epoch 0,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216Warning: Skipping the batch 25580 with size 90
rank: 0 test_accu: 2565250.0
get out
0 has test check 2565250.0 and sample count 3274240
 accuracy 78.346 %, best 78.346 %, roc auc score 0.7916, best 0.7916
Testing at - 20480/76743 of epoch 0,
Warning: Skipping the batch 25580 with size 90
rank: 3 test_accu: 2565250.0
get out
3 has test check 2565250.0 and sample count 3274240
Finished training it 21504/76743 of epoch 0, 50.00 ms/it, loss 0.457933
Testing at - 20480/76743 of epoch 0,
Warning: Skipping the batch 25580 with size 90
rank: 1 test_accu: 2565250.0
get out
1 has test check 2565250.0 and sample count 3274240
Finished training it 21504/76743 of epoch 0, 49.76 ms/it, loss 0.456893
Saving model to /rscratch/data/dlrm_criteo/save_model_after_training_one0.0.pt
Finished training it 21504/76743 of epoch 0, 49.90 ms/it, loss 0.456776
Testing at - 20480/76743 of epoch 0,
Warning: Skipping the batch 25580 with size 90
rank: 2 test_accu: 2565250.0
get out
2 has test check 2565250.0 and sample count 3274240
Finished training it 21504/76743 of epoch 0, 48.29 ms/it, loss 0.458370
Finished training it 22528/76743 of epoch 0, 50.02 ms/it, loss 0.458611
Finished training it 22528/76743 of epoch 0, 50.25 ms/it, loss 0.457382
Finished training it 22528/76743 of epoch 0, 49.92 ms/it, loss 0.456403
Finished training it 22528/76743 of epoch 0, 48.38 ms/it, loss 0.456988
Finished training it 23552/76743 of epoch 0, 49.88 ms/it, loss 0.455904
Finished training it 23552/76743 of epoch 0, 49.52 ms/it, loss 0.458057
Finished training it 23552/76743 of epoch 0, 49.77 ms/it, loss 0.455602
Finished training it 23552/76743 of epoch 0, 48.12 ms/it, loss 0.458754
Finished training it 24576/76743 of epoch 0, 49.91 ms/it, loss 0.452250
Finished training it 24576/76743 of epoch 0, 50.13 ms/it, loss 0.456524
Finished training it 24576/76743 of epoch 0, 49.85 ms/it, loss 0.457185
Finished training it 24576/76743 of epoch 0, 48.29 ms/it, loss 0.457381
Finished training it 25600/76743 of epoch 0, 50.17 ms/it, loss 0.454711
Finished training it 25600/76743 of epoch 0, 50.16 ms/it, loss 0.456356
Finished training it 25600/76743 of epoch 0, 50.12 ms/it, loss 0.456877
Finished training it 25600/76743 of epoch 0, 48.53 ms/it, loss 0.456600
Finished training it 26624/76743 of epoch 0, 50.19 ms/it, loss 0.454632
Finished training it 26624/76743 of epoch 0, 48.49 ms/it, loss 0.456364
Finished training it 26624/76743 of epoch 0, 49.99 ms/it, loss 0.456486
Finished training it 26624/76743 of epoch 0, 50.25 ms/it, loss 0.455864
Finished training it 27648/76743 of epoch 0, 47.06 ms/it, loss 0.452942
Finished training it 27648/76743 of epoch 0, 48.15 ms/it, loss 0.457489
Finished training it 27648/76743 of epoch 0, 48.18 ms/it, loss 0.453652
Finished training it 27648/76743 of epoch 0, 48.12 ms/it, loss 0.453975
Finished training it 28672/76743 of epoch 0, 46.86 ms/it, loss 0.453828
Finished training it 28672/76743 of epoch 0, 47.21 ms/it, loss 0.454711
Finished training it 28672/76743 of epoch 0, 46.93 ms/it, loss 0.455815
Finished training it 28672/76743 of epoch 0, 46.35 ms/it, loss 0.456072
Finished training it 29696/76743 of epoch 0, 45.67 ms/it, loss 0.452413
Finished training it 29696/76743 of epoch 0, 46.41 ms/it, loss 0.457450
Finished training it 29696/76743 of epoch 0, 46.62 ms/it, loss 0.452535
Finished training it 29696/76743 of epoch 0, 46.59 ms/it, loss 0.455919
Finished training it 30720/76743 of epoch 0, 49.68 ms/it, loss 0.454670
Finished training it 30720/76743 of epoch 0, 49.80 ms/it, loss 0.454964
Finished training it 30720/76743 of epoch 0, 49.84 ms/it, loss 0.453189
Finished training it 30720/76743 of epoch 0, 48.37 ms/it, loss 0.454209
Testing at - 30720/76743 of epoch 0,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216Warning: Skipping the batch 25580 with size 90
rank: 0 test_accu: 2569441.0
get out
0 has test check 2569441.0 and sample count 3274240
 accuracy 78.474 %, best 78.474 %, roc auc score 0.7942, best 0.7942
Testing at - 30720/76743 of epoch 0,
Warning: Skipping the batch 25580 with size 90
rank: 1 test_accu: 2569441.0
get out
1 has test check 2569441.0 and sample count 3274240
Finished training it 31744/76743 of epoch 0, 49.72 ms/it, loss 0.454461
Testing at - 30720/76743 of epoch 0,
Warning: Skipping the batch 25580 with size 90
rank: 3 test_accu: 2569441.0
get out
3 has test check 2569441.0 and sample count 3274240
Finished training it 31744/76743 of epoch 0, 49.70 ms/it, loss 0.452853
Saving model to /rscratch/data/dlrm_criteo/save_model_after_training_one1.0.pt
Finished training it 31744/76743 of epoch 0, 49.56 ms/it, loss 0.453143
Testing at - 30720/76743 of epoch 0,
Warning: Skipping the batch 25580 with size 90
rank: 2 test_accu: 2569441.0
get out
2 has test check 2569441.0 and sample count 3274240
Finished training it 31744/76743 of epoch 0, 48.37 ms/it, loss 0.456443
Finished training it 32768/76743 of epoch 0, 48.39 ms/it, loss 0.451980
Finished training it 32768/76743 of epoch 0, 49.71 ms/it, loss 0.454524
Finished training it 32768/76743 of epoch 0, 49.53 ms/it, loss 0.452857
Finished training it 32768/76743 of epoch 0, 49.59 ms/it, loss 0.454386
Finished training it 33792/76743 of epoch 0, 47.99 ms/it, loss 0.452624
Finished training it 33792/76743 of epoch 0, 49.68 ms/it, loss 0.454742
Finished training it 33792/76743 of epoch 0, 49.54 ms/it, loss 0.454233
Finished training it 33792/76743 of epoch 0, 49.66 ms/it, loss 0.453767
Finished training it 34816/76743 of epoch 0, 50.03 ms/it, loss 0.455206
Finished training it 34816/76743 of epoch 0, 49.99 ms/it, loss 0.451559
Finished training it 34816/76743 of epoch 0, 49.84 ms/it, loss 0.452728
Finished training it 34816/76743 of epoch 0, 48.61 ms/it, loss 0.455043
Finished training it 35840/76743 of epoch 0, 49.19 ms/it, loss 0.453748
Finished training it 35840/76743 of epoch 0, 49.58 ms/it, loss 0.454377
Finished training it 35840/76743 of epoch 0, 49.27 ms/it, loss 0.450884
Finished training it 35840/76743 of epoch 0, 48.07 ms/it, loss 0.450362
Finished training it 36864/76743 of epoch 0, 50.12 ms/it, loss 0.453979
Finished training it 36864/76743 of epoch 0, 50.07 ms/it, loss 0.451236
Finished training it 36864/76743 of epoch 0, 48.25 ms/it, loss 0.454088
Finished training it 36864/76743 of epoch 0, 49.79 ms/it, loss 0.451685
Finished training it 37888/76743 of epoch 0, 47.67 ms/it, loss 0.452837
Finished training it 37888/76743 of epoch 0, 47.85 ms/it, loss 0.452825
Finished training it 37888/76743 of epoch 0, 46.50 ms/it, loss 0.453376
Finished training it 37888/76743 of epoch 0, 47.67 ms/it, loss 0.450941
Finished training it 38912/76743 of epoch 0, 46.88 ms/it, loss 0.454569
Finished training it 38912/76743 of epoch 0, 47.14 ms/it, loss 0.450951
Finished training it 38912/76743 of epoch 0, 47.01 ms/it, loss 0.452678
Finished training it 38912/76743 of epoch 0, 45.88 ms/it, loss 0.453193
Finished training it 39936/76743 of epoch 0, 46.53 ms/it, loss 0.451657
Finished training it 39936/76743 of epoch 0, 46.56 ms/it, loss 0.451627
Finished training it 39936/76743 of epoch 0, 46.65 ms/it, loss 0.452938
Finished training it 39936/76743 of epoch 0, 45.82 ms/it, loss 0.451535
Finished training it 40960/76743 of epoch 0, 49.70 ms/it, loss 0.452250
Finished training it 40960/76743 of epoch 0, 49.35 ms/it, loss 0.452322
Finished training it 40960/76743 of epoch 0, 49.60 ms/it, loss 0.449908
Finished training it 40960/76743 of epoch 0, 47.94 ms/it, loss 0.451834
Testing at - 40960/76743 of epoch 0,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216Warning: Skipping the batch 25580 with size 90
rank: 0 test_accu: 2573000.0
get out
0 has test check 2573000.0 and sample count 3274240
 accuracy 78.583 %, best 78.583 %, roc auc score 0.7962, best 0.7962
Testing at - 40960/76743 of epoch 0,
Warning: Skipping the batch 25580 with size 90
rank: 1 test_accu: 2573000.0
get out
1 has test check 2573000.0 and sample count 3274240
Finished training it 41984/76743 of epoch 0, 48.89 ms/it, loss 0.451975
Saving model to /rscratch/data/dlrm_criteo/save_model_after_training_one0.0.pt
Finished training it 41984/76743 of epoch 0, 48.83 ms/it, loss 0.451880
Testing at - 40960/76743 of epoch 0,
Warning: Skipping the batch 25580 with size 90
rank: 3 test_accu: 2573000.0
get out
3 has test check 2573000.0 and sample count 3274240
Finished training it 41984/76743 of epoch 0, 48.94 ms/it, loss 0.449891
Testing at - 40960/76743 of epoch 0,
Warning: Skipping the batch 25580 with size 90
rank: 2 test_accu: 2573000.0
get out
2 has test check 2573000.0 and sample count 3274240
Finished training it 41984/76743 of epoch 0, 47.61 ms/it, loss 0.453681
Finished training it 43008/76743 of epoch 0, 49.76 ms/it, loss 0.449079
Finished training it 43008/76743 of epoch 0, 49.92 ms/it, loss 0.453445
Finished training it 43008/76743 of epoch 0, 49.91 ms/it, loss 0.453838
Finished training it 43008/76743 of epoch 0, 48.53 ms/it, loss 0.450349
Finished training it 44032/76743 of epoch 0, 49.71 ms/it, loss 0.453002
Finished training it 44032/76743 of epoch 0, 49.80 ms/it, loss 0.449644
Finished training it 44032/76743 of epoch 0, 49.65 ms/it, loss 0.450037
Finished training it 44032/76743 of epoch 0, 48.44 ms/it, loss 0.450667
Finished training it 45056/76743 of epoch 0, 55.77 ms/it, loss 0.451041
Finished training it 45056/76743 of epoch 0, 55.46 ms/it, loss 0.454558
Finished training it 45056/76743 of epoch 0, 56.44 ms/it, loss 0.450335
Finished training it 45056/76743 of epoch 0, 54.73 ms/it, loss 0.452206
Finished training it 46080/76743 of epoch 0, 49.68 ms/it, loss 0.451445
Finished training it 46080/76743 of epoch 0, 49.47 ms/it, loss 0.451605
Finished training it 46080/76743 of epoch 0, 49.74 ms/it, loss 0.452344
Finished training it 46080/76743 of epoch 0, 47.88 ms/it, loss 0.449009
Finished training it 47104/76743 of epoch 0, 49.94 ms/it, loss 0.451780
Finished training it 47104/76743 of epoch 0, 49.96 ms/it, loss 0.453518
Finished training it 47104/76743 of epoch 0, 50.07 ms/it, loss 0.450868
Finished training it 47104/76743 of epoch 0, 48.89 ms/it, loss 0.448105
Finished training it 48128/76743 of epoch 0, 47.50 ms/it, loss 0.449701
Finished training it 48128/76743 of epoch 0, 46.34 ms/it, loss 0.452838
Finished training it 48128/76743 of epoch 0, 47.54 ms/it, loss 0.452993
Finished training it 48128/76743 of epoch 0, 47.47 ms/it, loss 0.450267
Finished training it 49152/76743 of epoch 0, 46.49 ms/it, loss 0.450583
Finished training it 49152/76743 of epoch 0, 46.63 ms/it, loss 0.450205
Finished training it 49152/76743 of epoch 0, 45.96 ms/it, loss 0.449945
Finished training it 49152/76743 of epoch 0, 46.69 ms/it, loss 0.448744
Finished training it 50176/76743 of epoch 0, 46.72 ms/it, loss 0.446320
Finished training it 50176/76743 of epoch 0, 46.84 ms/it, loss 0.452089
Finished training it 50176/76743 of epoch 0, 46.56 ms/it, loss 0.449458
Finished training it 50176/76743 of epoch 0, 45.96 ms/it, loss 0.450276
Finished training it 51200/76743 of epoch 0, 49.37 ms/it, loss 0.448805
Finished training it 51200/76743 of epoch 0, 47.93 ms/it, loss 0.451969
Finished training it 51200/76743 of epoch 0, 49.65 ms/it, loss 0.450670
Finished training it 51200/76743 of epoch 0, 49.37 ms/it, loss 0.448309
Testing at - 51200/76743 of epoch 0,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216Warning: Skipping the batch 25580 with size 90
rank: 0 test_accu: 2574471.0
get out
0 has test check 2574471.0 and sample count 3274240
 accuracy 78.628 %, best 78.628 %, roc auc score 0.7975, best 0.7975
Saving model to /rscratch/data/dlrm_criteo/save_model_after_training_one1.0.pt
Finished training it 52224/76743 of epoch 0, 49.27 ms/it, loss 0.448000
Testing at - 51200/76743 of epoch 0,
Warning: Skipping the batch 25580 with size 90
rank: 3 test_accu: 2574471.0
get out
3 has test check 2574471.0 and sample count 3274240
Finished training it 52224/76743 of epoch 0, 49.32 ms/it, loss 0.450105
Testing at - 51200/76743 of epoch 0,
Warning: Skipping the batch 25580 with size 90
rank: 1 test_accu: 2574471.0
get out
1 has test check 2574471.0 and sample count 3274240
Finished training it 52224/76743 of epoch 0, 49.53 ms/it, loss 0.450771
Testing at - 51200/76743 of epoch 0,
Warning: Skipping the batch 25580 with size 90
rank: 2 test_accu: 2574471.0
get out
2 has test check 2574471.0 and sample count 3274240
Finished training it 52224/76743 of epoch 0, 47.88 ms/it, loss 0.450424
Finished training it 53248/76743 of epoch 0, 49.93 ms/it, loss 0.449643
Finished training it 53248/76743 of epoch 0, 49.88 ms/it, loss 0.450061
Finished training it 53248/76743 of epoch 0, 48.63 ms/it, loss 0.448291
Finished training it 53248/76743 of epoch 0, 50.06 ms/it, loss 0.450068
Finished training it 54272/76743 of epoch 0, 49.69 ms/it, loss 0.448714
Finished training it 54272/76743 of epoch 0, 49.58 ms/it, loss 0.449460
Finished training it 54272/76743 of epoch 0, 49.75 ms/it, loss 0.446935
Finished training it 54272/76743 of epoch 0, 47.97 ms/it, loss 0.450040
Finished training it 55296/76743 of epoch 0, 49.64 ms/it, loss 0.450580
Finished training it 55296/76743 of epoch 0, 47.80 ms/it, loss 0.448756
Finished training it 55296/76743 of epoch 0, 49.80 ms/it, loss 0.452175
Finished training it 55296/76743 of epoch 0, 49.78 ms/it, loss 0.449385
Finished training it 56320/76743 of epoch 0, 49.50 ms/it, loss 0.451358
Finished training it 56320/76743 of epoch 0, 49.21 ms/it, loss 0.451132
Finished training it 56320/76743 of epoch 0, 49.25 ms/it, loss 0.446684
Finished training it 56320/76743 of epoch 0, 47.77 ms/it, loss 0.449879
Finished training it 57344/76743 of epoch 0, 49.59 ms/it, loss 0.447724
Finished training it 57344/76743 of epoch 0, 49.76 ms/it, loss 0.448652
Finished training it 57344/76743 of epoch 0, 49.76 ms/it, loss 0.449795
Finished training it 57344/76743 of epoch 0, 48.13 ms/it, loss 0.450424
Finished training it 58368/76743 of epoch 0, 47.62 ms/it, loss 0.447338
Finished training it 58368/76743 of epoch 0, 47.31 ms/it, loss 0.446500
Finished training it 58368/76743 of epoch 0, 47.52 ms/it, loss 0.448937
Finished training it 58368/76743 of epoch 0, 46.38 ms/it, loss 0.448122
Finished training it 59392/76743 of epoch 0, 46.42 ms/it, loss 0.446569
Finished training it 59392/76743 of epoch 0, 45.63 ms/it, loss 0.448645
Finished training it 59392/76743 of epoch 0, 46.65 ms/it, loss 0.449673
Finished training it 59392/76743 of epoch 0, 46.76 ms/it, loss 0.446894
Finished training it 60416/76743 of epoch 0, 46.96 ms/it, loss 0.449442
Finished training it 60416/76743 of epoch 0, 47.03 ms/it, loss 0.448942
Finished training it 60416/76743 of epoch 0, 46.14 ms/it, loss 0.446599
Finished training it 60416/76743 of epoch 0, 46.80 ms/it, loss 0.447177
Finished training it 61440/76743 of epoch 0, 49.58 ms/it, loss 0.448146
Finished training it 61440/76743 of epoch 0, 49.63 ms/it, loss 0.447725
Finished training it 61440/76743 of epoch 0, 49.84 ms/it, loss 0.450699
Finished training it 61440/76743 of epoch 0, 48.24 ms/it, loss 0.446509
Testing at - 61440/76743 of epoch 0,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216Warning: Skipping the batch 25580 with size 90
rank: 0 test_accu: 2576762.0
get out
0 has test check 2576762.0 and sample count 3274240
 accuracy 78.698 %, best 78.698 %, roc auc score 0.7989, best 0.7989
Testing at - 61440/76743 of epoch 0,
Warning: Skipping the batch 25580 with size 90
rank: 1 test_accu: 2576762.0
get out
1 has test check 2576762.0 and sample count 3274240
Finished training it 62464/76743 of epoch 0, 49.45 ms/it, loss 0.446815
Saving model to /rscratch/data/dlrm_criteo/save_model_after_training_one0.0.pt
Finished training it 62464/76743 of epoch 0, 49.56 ms/it, loss 0.450208
Testing at - 61440/76743 of epoch 0,
Warning: Skipping the batch 25580 with size 90
rank: 3 test_accu: 2576762.0
get out
3 has test check 2576762.0 and sample count 3274240
Finished training it 62464/76743 of epoch 0, 49.52 ms/it, loss 0.447999
Testing at - 61440/76743 of epoch 0,
Warning: Skipping the batch 25580 with size 90
rank: 2 test_accu: 2576762.0
get out
2 has test check 2576762.0 and sample count 3274240
Finished training it 62464/76743 of epoch 0, 47.78 ms/it, loss 0.449642
Finished training it 63488/76743 of epoch 0, 48.84 ms/it, loss 0.447734
Finished training it 63488/76743 of epoch 0, 48.96 ms/it, loss 0.449740
Finished training it 63488/76743 of epoch 0, 49.01 ms/it, loss 0.447938
Finished training it 63488/76743 of epoch 0, 47.75 ms/it, loss 0.451909
Finished training it 64512/76743 of epoch 0, 49.74 ms/it, loss 0.447702
Finished training it 64512/76743 of epoch 0, 49.94 ms/it, loss 0.446628
Finished training it 64512/76743 of epoch 0, 49.69 ms/it, loss 0.449356
Finished training it 64512/76743 of epoch 0, 48.67 ms/it, loss 0.448989
Finished training it 65536/76743 of epoch 0, 49.81 ms/it, loss 0.449757
Finished training it 65536/76743 of epoch 0, 49.78 ms/it, loss 0.449560
Finished training it 65536/76743 of epoch 0, 48.20 ms/it, loss 0.448877
Finished training it 65536/76743 of epoch 0, 49.82 ms/it, loss 0.447427
Finished training it 66560/76743 of epoch 0, 50.12 ms/it, loss 0.448460
Finished training it 66560/76743 of epoch 0, 50.01 ms/it, loss 0.448158
Finished training it 66560/76743 of epoch 0, 48.30 ms/it, loss 0.449872
Finished training it 66560/76743 of epoch 0, 50.07 ms/it, loss 0.449511
Finished training it 67584/76743 of epoch 0, 54.75 ms/it, loss 0.445817
Finished training it 67584/76743 of epoch 0, 55.51 ms/it, loss 0.448502
Finished training it 67584/76743 of epoch 0, 55.14 ms/it, loss 0.446927
Finished training it 67584/76743 of epoch 0, 53.73 ms/it, loss 0.445087
Finished training it 68608/76743 of epoch 0, 47.11 ms/it, loss 0.445928
Finished training it 68608/76743 of epoch 0, 47.20 ms/it, loss 0.446652
Finished training it 68608/76743 of epoch 0, 47.07 ms/it, loss 0.447555
Finished training it 68608/76743 of epoch 0, 45.99 ms/it, loss 0.448760
Finished training it 69632/76743 of epoch 0, 46.15 ms/it, loss 0.447523
Finished training it 69632/76743 of epoch 0, 45.91 ms/it, loss 0.445899
Finished training it 69632/76743 of epoch 0, 46.15 ms/it, loss 0.447103
Finished training it 69632/76743 of epoch 0, 45.14 ms/it, loss 0.445375
Finished training it 70656/76743 of epoch 0, 46.51 ms/it, loss 0.447806
Finished training it 70656/76743 of epoch 0, 46.95 ms/it, loss 0.450182
Finished training it 70656/76743 of epoch 0, 47.21 ms/it, loss 0.445099
Finished training it 70656/76743 of epoch 0, 47.17 ms/it, loss 0.447125
Finished training it 71680/76743 of epoch 0, 50.13 ms/it, loss 0.448809
Finished training it 71680/76743 of epoch 0, 49.98 ms/it, loss 0.447168
Finished training it 71680/76743 of epoch 0, 49.71 ms/it, loss 0.442720
Finished training it 71680/76743 of epoch 0, 48.26 ms/it, loss 0.448542
Testing at - 71680/76743 of epoch 0,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216Warning: Skipping the batch 25580 with size 90
rank: 0 test_accu: 2575491.0
get out
0 has test check 2575491.0 and sample count 3274240
 accuracy 78.659 %, best 78.698 %, roc auc score 0.7998, best 0.7998
Testing at - 71680/76743 of epoch 0,
Warning: Skipping the batch 25580 with size 90
rank: 1 test_accu: 2575491.0
get out
1 has test check 2575491.0 and sample count 3274240
Finished training it 72704/76743 of epoch 0, 49.62 ms/it, loss 0.448104
Finished training it 72704/76743 of epoch 0, 49.72 ms/it, loss 0.446724
Testing at - 71680/76743 of epoch 0,
Warning: Skipping the batch 25580 with size 90
rank: 3 test_accu: 2575491.0
get out
3 has test check 2575491.0 and sample count 3274240
Finished training it 72704/76743 of epoch 0, 49.69 ms/it, loss 0.447663
Testing at - 71680/76743 of epoch 0,
Warning: Skipping the batch 25580 with size 90
rank: 2 test_accu: 2575491.0
get out
2 has test check 2575491.0 and sample count 3274240
Finished training it 72704/76743 of epoch 0, 48.43 ms/it, loss 0.448134
Finished training it 73728/76743 of epoch 0, 49.12 ms/it, loss 0.448907
Finished training it 73728/76743 of epoch 0, 49.18 ms/it, loss 0.446653
Finished training it 73728/76743 of epoch 0, 49.18 ms/it, loss 0.447812
Finished training it 73728/76743 of epoch 0, 47.54 ms/it, loss 0.448040
Finished training it 74752/76743 of epoch 0, 49.68 ms/it, loss 0.445701
Finished training it 74752/76743 of epoch 0, 49.76 ms/it, loss 0.446934
Finished training it 74752/76743 of epoch 0, 49.68 ms/it, loss 0.446576
Finished training it 74752/76743 of epoch 0, 47.92 ms/it, loss 0.449143
Finished training it 75776/76743 of epoch 0, 49.78 ms/it, loss 0.448422
Finished training it 75776/76743 of epoch 0, 49.47 ms/it, loss 0.445318
Finished training it 75776/76743 of epoch 0, 48.35 ms/it, loss 0.448923
Finished training it 75776/76743 of epoch 0, 49.59 ms/it, loss 0.446451
Warning: Skipping the batch 76742 with size 14
Finished training it 1024/76743 of epoch 1, 50.18 ms/it, loss 0.447065
Warning: Skipping the batch 76742 with size 14
Finished training it 1024/76743 of epoch 1, 50.38 ms/it, loss 0.446841
Warning: Skipping the batch 76742 with size 14
Finished training it 1024/76743 of epoch 1, 48.80 ms/it, loss 0.446926
Warning: Skipping the batch 76742 with size 14
Finished training it 1024/76743 of epoch 1, 50.34 ms/it, loss 0.447118
Finished training it 2048/76743 of epoch 1, 49.70 ms/it, loss 0.444535
Finished training it 2048/76743 of epoch 1, 49.53 ms/it, loss 0.447261
Finished training it 2048/76743 of epoch 1, 49.51 ms/it, loss 0.445381
Finished training it 2048/76743 of epoch 1, 47.86 ms/it, loss 0.444596
Finished training it 3072/76743 of epoch 1, 49.42 ms/it, loss 0.444363
Finished training it 3072/76743 of epoch 1, 49.58 ms/it, loss 0.445765
Finished training it 3072/76743 of epoch 1, 49.34 ms/it, loss 0.443251
Finished training it 3072/76743 of epoch 1, 48.18 ms/it, loss 0.446045
Finished training it 4096/76743 of epoch 1, 47.81 ms/it, loss 0.447977
Finished training it 4096/76743 of epoch 1, 49.29 ms/it, loss 0.444765
Finished training it 4096/76743 of epoch 1, 49.12 ms/it, loss 0.444349
Finished training it 4096/76743 of epoch 1, 49.26 ms/it, loss 0.446434
Finished training it 5120/76743 of epoch 1, 49.55 ms/it, loss 0.443891
Finished training it 5120/76743 of epoch 1, 49.71 ms/it, loss 0.442892
Finished training it 5120/76743 of epoch 1, 49.76 ms/it, loss 0.443907
Finished training it 5120/76743 of epoch 1, 48.60 ms/it, loss 0.443878
Finished training it 6144/76743 of epoch 1, 49.83 ms/it, loss 0.444580
Finished training it 6144/76743 of epoch 1, 49.41 ms/it, loss 0.445262
Finished training it 6144/76743 of epoch 1, 48.29 ms/it, loss 0.444484
Finished training it 6144/76743 of epoch 1, 49.51 ms/it, loss 0.443005
Finished training it 7168/76743 of epoch 1, 47.80 ms/it, loss 0.441310
Finished training it 7168/76743 of epoch 1, 47.71 ms/it, loss 0.442458
Finished training it 7168/76743 of epoch 1, 46.50 ms/it, loss 0.443060
Finished training it 7168/76743 of epoch 1, 47.87 ms/it, loss 0.444051
Finished training it 8192/76743 of epoch 1, 45.80 ms/it, loss 0.443862
Finished training it 8192/76743 of epoch 1, 46.68 ms/it, loss 0.444519
Finished training it 8192/76743 of epoch 1, 46.42 ms/it, loss 0.445473
Finished training it 8192/76743 of epoch 1, 46.27 ms/it, loss 0.441945
Finished training it 9216/76743 of epoch 1, 46.78 ms/it, loss 0.443421
Finished training it 9216/76743 of epoch 1, 46.99 ms/it, loss 0.443972
Finished training it 9216/76743 of epoch 1, 46.82 ms/it, loss 0.444392
Finished training it 9216/76743 of epoch 1, 46.43 ms/it, loss 0.443467
Finished training it 10240/76743 of epoch 1, 49.89 ms/it, loss 0.442006
Finished training it 10240/76743 of epoch 1, 49.70 ms/it, loss 0.445973
Finished training it 10240/76743 of epoch 1, 49.62 ms/it, loss 0.444781
Finished training it 10240/76743 of epoch 1, 48.17 ms/it, loss 0.442785
Testing at - 10240/76743 of epoch 1,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216Warning: Skipping the batch 25580 with size 90
rank: 0 test_accu: 2574086.0
get out
0 has test check 2574086.0 and sample count 3274240
 accuracy 78.616 %, best 78.698 %, roc auc score 0.7991, best 0.7998
Finished training it 11264/76743 of epoch 1, 49.71 ms/it, loss 0.444678
Testing at - 10240/76743 of epoch 1,
Warning: Skipping the batch 25580 with size 90
rank: 3 test_accu: 2574086.0
get out
3 has test check 2574086.0 and sample count 3274240
Finished training it 11264/76743 of epoch 1, 49.76 ms/it, loss 0.444550
Testing at - 10240/76743 of epoch 1,
Warning: Skipping the batch 25580 with size 90
rank: 1 test_accu: 2574086.0
get out
1 has test check 2574086.0 and sample count 3274240
Finished training it 11264/76743 of epoch 1, 49.75 ms/it, loss 0.444197
Testing at - 10240/76743 of epoch 1,
Warning: Skipping the batch 25580 with size 90
rank: 2 test_accu: 2574086.0
get out
2 has test check 2574086.0 and sample count 3274240
Finished training it 11264/76743 of epoch 1, 48.30 ms/it, loss 0.444963
Finished training it 12288/76743 of epoch 1, 49.55 ms/it, loss 0.443774
Finished training it 12288/76743 of epoch 1, 49.41 ms/it, loss 0.441188
Finished training it 12288/76743 of epoch 1, 47.89 ms/it, loss 0.441447
Finished training it 12288/76743 of epoch 1, 49.44 ms/it, loss 0.440478
Finished training it 13312/76743 of epoch 1, 49.67 ms/it, loss 0.443341
Finished training it 13312/76743 of epoch 1, 49.46 ms/it, loss 0.442076
Finished training it 13312/76743 of epoch 1, 48.24 ms/it, loss 0.445170
Finished training it 13312/76743 of epoch 1, 49.76 ms/it, loss 0.443862
Finished training it 14336/76743 of epoch 1, 49.93 ms/it, loss 0.444075
Finished training it 14336/76743 of epoch 1, 49.81 ms/it, loss 0.443000
Finished training it 14336/76743 of epoch 1, 50.01 ms/it, loss 0.443670
Finished training it 14336/76743 of epoch 1, 48.41 ms/it, loss 0.442904
Finished training it 15360/76743 of epoch 1, 50.09 ms/it, loss 0.440337
Finished training it 15360/76743 of epoch 1, 49.93 ms/it, loss 0.439716
Finished training it 15360/76743 of epoch 1, 48.44 ms/it, loss 0.443218
Finished training it 15360/76743 of epoch 1, 50.27 ms/it, loss 0.441860
Finished training it 16384/76743 of epoch 1, 49.50 ms/it, loss 0.440201
Finished training it 16384/76743 of epoch 1, 49.33 ms/it, loss 0.442732
Finished training it 16384/76743 of epoch 1, 47.84 ms/it, loss 0.439629
Finished training it 16384/76743 of epoch 1, 49.43 ms/it, loss 0.441610
Finished training it 17408/76743 of epoch 1, 48.00 ms/it, loss 0.441065
Finished training it 17408/76743 of epoch 1, 48.03 ms/it, loss 0.441200
Finished training it 17408/76743 of epoch 1, 47.73 ms/it, loss 0.440121
Finished training it 17408/76743 of epoch 1, 48.22 ms/it, loss 0.441982
Finished training it 18432/76743 of epoch 1, 45.77 ms/it, loss 0.440617
Finished training it 18432/76743 of epoch 1, 46.41 ms/it, loss 0.440919
Finished training it 18432/76743 of epoch 1, 46.29 ms/it, loss 0.441550
Finished training it 18432/76743 of epoch 1, 46.50 ms/it, loss 0.439787
Finished training it 19456/76743 of epoch 1, 46.90 ms/it, loss 0.444962
Finished training it 19456/76743 of epoch 1, 46.73 ms/it, loss 0.440710
Finished training it 19456/76743 of epoch 1, 46.58 ms/it, loss 0.440166
Finished training it 19456/76743 of epoch 1, 46.24 ms/it, loss 0.440245
Finished training it 20480/76743 of epoch 1, 49.68 ms/it, loss 0.439001
Finished training it 20480/76743 of epoch 1, 48.15 ms/it, loss 0.438367
Finished training it 20480/76743 of epoch 1, 49.79 ms/it, loss 0.443185
Finished training it 20480/76743 of epoch 1, 49.66 ms/it, loss 0.439954
Testing at - 20480/76743 of epoch 1,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216Warning: Skipping the batch 25580 with size 90
rank: 0 test_accu: 2577768.0
get out
0 has test check 2577768.0 and sample count 3274240
 accuracy 78.729 %, best 78.729 %, roc auc score 0.7993, best 0.7998
Testing at - 20480/76743 of epoch 1,
Warning: Skipping the batch 25580 with size 90
rank: 1 test_accu: 2577768.0
get out
1 has test check 2577768.0 and sample count 3274240
Finished training it 21504/76743 of epoch 1, 48.68 ms/it, loss 0.440506
Saving model to /rscratch/data/dlrm_criteo/save_model_after_training_one0.0.pt
Finished training it 21504/76743 of epoch 1, 48.67 ms/it, loss 0.440089
Testing at - 20480/76743 of epoch 1,
Warning: Skipping the batch 25580 with size 90
rank: 3 test_accu: 2577768.0
get out
3 has test check 2577768.0 and sample count 3274240
Finished training it 21504/76743 of epoch 1, 48.67 ms/it, loss 0.441448
Testing at - 20480/76743 of epoch 1,
Warning: Skipping the batch 25580 with size 90
rank: 2 test_accu: 2577768.0
get out
2 has test check 2577768.0 and sample count 3274240
Finished training it 21504/76743 of epoch 1, 47.45 ms/it, loss 0.441729
Finished training it 22528/76743 of epoch 1, 49.74 ms/it, loss 0.439695
Finished training it 22528/76743 of epoch 1, 49.60 ms/it, loss 0.441563
Finished training it 22528/76743 of epoch 1, 48.45 ms/it, loss 0.439821
Finished training it 22528/76743 of epoch 1, 49.86 ms/it, loss 0.441882
Finished training it 23552/76743 of epoch 1, 49.13 ms/it, loss 0.438974
Finished training it 23552/76743 of epoch 1, 49.43 ms/it, loss 0.441023
Finished training it 23552/76743 of epoch 1, 47.63 ms/it, loss 0.441521
Finished training it 23552/76743 of epoch 1, 49.34 ms/it, loss 0.439445
Finished training it 24576/76743 of epoch 1, 56.35 ms/it, loss 0.440734
Finished training it 24576/76743 of epoch 1, 56.25 ms/it, loss 0.436645
Finished training it 24576/76743 of epoch 1, 56.29 ms/it, loss 0.440082
Finished training it 24576/76743 of epoch 1, 52.86 ms/it, loss 0.440714
Finished training it 25600/76743 of epoch 1, 49.40 ms/it, loss 0.439851
Finished training it 25600/76743 of epoch 1, 50.10 ms/it, loss 0.438547
Finished training it 25600/76743 of epoch 1, 48.81 ms/it, loss 0.440231
Finished training it 25600/76743 of epoch 1, 48.97 ms/it, loss 0.440551
Finished training it 26624/76743 of epoch 1, 49.18 ms/it, loss 0.439652
Finished training it 26624/76743 of epoch 1, 49.39 ms/it, loss 0.440833
Finished training it 26624/76743 of epoch 1, 49.40 ms/it, loss 0.437330
Finished training it 26624/76743 of epoch 1, 47.84 ms/it, loss 0.439941
Finished training it 27648/76743 of epoch 1, 48.13 ms/it, loss 0.437588
Finished training it 27648/76743 of epoch 1, 48.06 ms/it, loss 0.437895
Finished training it 27648/76743 of epoch 1, 47.75 ms/it, loss 0.441297
Finished training it 27648/76743 of epoch 1, 46.79 ms/it, loss 0.436368
Finished training it 28672/76743 of epoch 1, 46.52 ms/it, loss 0.438059
Finished training it 28672/76743 of epoch 1, 46.15 ms/it, loss 0.439007
Finished training it 28672/76743 of epoch 1, 45.96 ms/it, loss 0.436938
Finished training it 28672/76743 of epoch 1, 46.12 ms/it, loss 0.439727
Finished training it 29696/76743 of epoch 1, 46.58 ms/it, loss 0.435524
Finished training it 29696/76743 of epoch 1, 45.55 ms/it, loss 0.435528
Finished training it 29696/76743 of epoch 1, 46.40 ms/it, loss 0.439296
Finished training it 29696/76743 of epoch 1, 46.25 ms/it, loss 0.440550
Finished training it 30720/76743 of epoch 1, 49.73 ms/it, loss 0.437398
Finished training it 30720/76743 of epoch 1, 49.94 ms/it, loss 0.438013
Finished training it 30720/76743 of epoch 1, 48.43 ms/it, loss 0.437286
Finished training it 30720/76743 of epoch 1, 49.79 ms/it, loss 0.438325
Testing at - 30720/76743 of epoch 1,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216Warning: Skipping the batch 25580 with size 90
rank: 0 test_accu: 2573840.0
get out
0 has test check 2573840.0 and sample count 3274240
 accuracy 78.609 %, best 78.729 %, roc auc score 0.7982, best 0.7998
Testing at - 30720/76743 of epoch 1,
Warning: Skipping the batch 25580 with size 90
rank: 2 test_accu: 2573840.0
get out
2 has test check 2573840.0 and sample count 3274240
Finished training it 31744/76743 of epoch 1, 47.84 ms/it, loss 0.439398
Testing at - 30720/76743 of epoch 1,
Warning: Skipping the batch 25580 with size 90
rank: 3 test_accu: 2573840.0
get out
3 has test check 2573840.0 and sample count 3274240
Finished training it 31744/76743 of epoch 1, 49.77 ms/it, loss 0.436250
Testing at - 30720/76743 of epoch 1,
Warning: Skipping the batch 25580 with size 90
rank: 1 test_accu: 2573840.0
get out
1 has test check 2573840.0 and sample count 3274240
Finished training it 31744/76743 of epoch 1, 49.69 ms/it, loss 0.437760
Finished training it 31744/76743 of epoch 1, 49.49 ms/it, loss 0.435814
Finished training it 32768/76743 of epoch 1, 49.41 ms/it, loss 0.436400
Finished training it 32768/76743 of epoch 1, 49.66 ms/it, loss 0.436956
Finished training it 32768/76743 of epoch 1, 49.41 ms/it, loss 0.437476
Finished training it 32768/76743 of epoch 1, 47.82 ms/it, loss 0.435284
Finished training it 33792/76743 of epoch 1, 49.93 ms/it, loss 0.436485
Finished training it 33792/76743 of epoch 1, 49.38 ms/it, loss 0.437866
Finished training it 33792/76743 of epoch 1, 49.86 ms/it, loss 0.437014
Finished training it 33792/76743 of epoch 1, 48.33 ms/it, loss 0.435147
Finished training it 34816/76743 of epoch 1, 49.64 ms/it, loss 0.437668
Finished training it 34816/76743 of epoch 1, 49.54 ms/it, loss 0.434353
Finished training it 34816/76743 of epoch 1, 49.48 ms/it, loss 0.435523
Finished training it 34816/76743 of epoch 1, 48.09 ms/it, loss 0.437847
Finished training it 35840/76743 of epoch 1, 47.84 ms/it, loss 0.433523
Finished training it 35840/76743 of epoch 1, 49.52 ms/it, loss 0.435399
Finished training it 35840/76743 of epoch 1, 49.55 ms/it, loss 0.437019
Finished training it 35840/76743 of epoch 1, 49.64 ms/it, loss 0.433853
Finished training it 36864/76743 of epoch 1, 49.80 ms/it, loss 0.435831
Finished training it 36864/76743 of epoch 1, 49.47 ms/it, loss 0.433110
Finished training it 36864/76743 of epoch 1, 49.97 ms/it, loss 0.433364
Finished training it 36864/76743 of epoch 1, 48.02 ms/it, loss 0.435576
Finished training it 37888/76743 of epoch 1, 47.71 ms/it, loss 0.434022
Finished training it 37888/76743 of epoch 1, 48.10 ms/it, loss 0.434133
Finished training it 37888/76743 of epoch 1, 47.98 ms/it, loss 0.432632
Finished training it 37888/76743 of epoch 1, 46.76 ms/it, loss 0.434980
Finished training it 38912/76743 of epoch 1, 46.59 ms/it, loss 0.436184
Finished training it 38912/76743 of epoch 1, 46.90 ms/it, loss 0.432176
Finished training it 38912/76743 of epoch 1, 46.38 ms/it, loss 0.434010
Finished training it 38912/76743 of epoch 1, 45.83 ms/it, loss 0.433858
Finished training it 39936/76743 of epoch 1, 47.28 ms/it, loss 0.433405
Finished training it 39936/76743 of epoch 1, 46.20 ms/it, loss 0.432185
Finished training it 39936/76743 of epoch 1, 47.10 ms/it, loss 0.431673
Finished training it 39936/76743 of epoch 1, 47.01 ms/it, loss 0.432586
Finished training it 40960/76743 of epoch 1, 49.54 ms/it, loss 0.432449
Finished training it 40960/76743 of epoch 1, 49.60 ms/it, loss 0.430897
Finished training it 40960/76743 of epoch 1, 49.76 ms/it, loss 0.431815
Finished training it 40960/76743 of epoch 1, 48.13 ms/it, loss 0.432617
Testing at - 40960/76743 of epoch 1,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216Warning: Skipping the batch 25580 with size 90
rank: 0 test_accu: 2570174.0
get out
0 has test check 2570174.0 and sample count 3274240
 accuracy 78.497 %, best 78.729 %, roc auc score 0.7928, best 0.7998
Finished training it 41984/76743 of epoch 1, 49.30 ms/it, loss 0.432488
Testing at - 40960/76743 of epoch 1,
Warning: Skipping the batch 25580 with size 90
rank: 3 test_accu: 2570174.0
get out
3 has test check 2570174.0 and sample count 3274240
Finished training it 41984/76743 of epoch 1, 49.10 ms/it, loss 0.430536
Testing at - 40960/76743 of epoch 1,
Warning: Skipping the batch 25580 with size 90
rank: 1 test_accu: 2570174.0
get out
1 has test check 2570174.0 and sample count 3274240
Finished training it 41984/76743 of epoch 1, 49.13 ms/it, loss 0.432258
Testing at - 40960/76743 of epoch 1,
Warning: Skipping the batch 25580 with size 90
rank: 2 test_accu: 2570174.0
get out
2 has test check 2570174.0 and sample count 3274240
Finished training it 41984/76743 of epoch 1, 47.77 ms/it, loss 0.434118
Finished training it 43008/76743 of epoch 1, 48.54 ms/it, loss 0.433034
Finished training it 43008/76743 of epoch 1, 48.42 ms/it, loss 0.428641
Finished training it 43008/76743 of epoch 1, 48.25 ms/it, loss 0.432985
Finished training it 43008/76743 of epoch 1, 47.29 ms/it, loss 0.430106
Finished training it 44032/76743 of epoch 1, 49.64 ms/it, loss 0.429286
Finished training it 44032/76743 of epoch 1, 49.62 ms/it, loss 0.432318
Finished training it 44032/76743 of epoch 1, 48.11 ms/it, loss 0.429365
Finished training it 44032/76743 of epoch 1, 49.34 ms/it, loss 0.429535
Finished training it 45056/76743 of epoch 1, 49.88 ms/it, loss 0.433305
Finished training it 45056/76743 of epoch 1, 49.80 ms/it, loss 0.430357
Finished training it 45056/76743 of epoch 1, 49.82 ms/it, loss 0.428912
Finished training it 45056/76743 of epoch 1, 48.09 ms/it, loss 0.430847
Finished training it 46080/76743 of epoch 1, 49.77 ms/it, loss 0.429188
Finished training it 46080/76743 of epoch 1, 49.73 ms/it, loss 0.430547
Finished training it 46080/76743 of epoch 1, 49.49 ms/it, loss 0.430951
Finished training it 46080/76743 of epoch 1, 48.23 ms/it, loss 0.425748
Finished training it 47104/76743 of epoch 1, 55.55 ms/it, loss 0.431054
Finished training it 47104/76743 of epoch 1, 55.23 ms/it, loss 0.429464
Finished training it 47104/76743 of epoch 1, 55.48 ms/it, loss 0.428766
Finished training it 47104/76743 of epoch 1, 53.75 ms/it, loss 0.425258
Finished training it 48128/76743 of epoch 1, 46.55 ms/it, loss 0.429870
Finished training it 48128/76743 of epoch 1, 47.45 ms/it, loss 0.428428
Finished training it 48128/76743 of epoch 1, 47.25 ms/it, loss 0.429880
Finished training it 48128/76743 of epoch 1, 47.39 ms/it, loss 0.427197
Finished training it 49152/76743 of epoch 1, 45.73 ms/it, loss 0.427090
Finished training it 49152/76743 of epoch 1, 46.25 ms/it, loss 0.427110
Finished training it 49152/76743 of epoch 1, 46.40 ms/it, loss 0.426586
Finished training it 49152/76743 of epoch 1, 46.29 ms/it, loss 0.424980
Finished training it 50176/76743 of epoch 1, 46.14 ms/it, loss 0.425242
Finished training it 50176/76743 of epoch 1, 45.93 ms/it, loss 0.427718
Finished training it 50176/76743 of epoch 1, 45.41 ms/it, loss 0.426030
Finished training it 50176/76743 of epoch 1, 46.06 ms/it, loss 0.422430
Finished training it 51200/76743 of epoch 1, 49.51 ms/it, loss 0.425751
Finished training it 51200/76743 of epoch 1, 49.35 ms/it, loss 0.423043
Finished training it 51200/76743 of epoch 1, 49.36 ms/it, loss 0.422835
Finished training it 51200/76743 of epoch 1, 47.66 ms/it, loss 0.428511
Testing at - 51200/76743 of epoch 1,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216Warning: Skipping the batch 25580 with size 90
rank: 0 test_accu: 2568881.0
get out
0 has test check 2568881.0 and sample count 3274240
 accuracy 78.457 %, best 78.729 %, roc auc score 0.7922, best 0.7998
Finished training it 52224/76743 of epoch 1, 49.10 ms/it, loss 0.422234
Testing at - 51200/76743 of epoch 1,
Warning: Skipping the batch 25580 with size 90
rank: 3 test_accu: 2568881.0
get out
3 has test check 2568881.0 and sample count 3274240
Finished training it 52224/76743 of epoch 1, 49.13 ms/it, loss 0.424281
Testing at - 51200/76743 of epoch 1,
Warning: Skipping the batch 25580 with size 90
rank: 1 test_accu: 2568881.0
get out
1 has test check 2568881.0 and sample count 3274240
Finished training it 52224/76743 of epoch 1, 49.02 ms/it, loss 0.425328
Testing at - 51200/76743 of epoch 1,
Warning: Skipping the batch 25580 with size 90
rank: 2 test_accu: 2568881.0
get out
2 has test check 2568881.0 and sample count 3274240
Finished training it 52224/76743 of epoch 1, 47.61 ms/it, loss 0.425590
Finished training it 53248/76743 of epoch 1, 49.13 ms/it, loss 0.424683
Finished training it 53248/76743 of epoch 1, 49.26 ms/it, loss 0.423617
Finished training it 53248/76743 of epoch 1, 48.04 ms/it, loss 0.422399
Finished training it 53248/76743 of epoch 1, 49.27 ms/it, loss 0.423261
Finished training it 54272/76743 of epoch 1, 49.66 ms/it, loss 0.420882
Finished training it 54272/76743 of epoch 1, 49.75 ms/it, loss 0.422732
Finished training it 54272/76743 of epoch 1, 49.59 ms/it, loss 0.422858
Finished training it 54272/76743 of epoch 1, 48.11 ms/it, loss 0.422832
Finished training it 55296/76743 of epoch 1, 48.18 ms/it, loss 0.421481
Finished training it 55296/76743 of epoch 1, 49.60 ms/it, loss 0.422298
Finished training it 55296/76743 of epoch 1, 49.68 ms/it, loss 0.424423
Finished training it 55296/76743 of epoch 1, 49.52 ms/it, loss 0.423089
Finished training it 56320/76743 of epoch 1, 49.68 ms/it, loss 0.423158
Finished training it 56320/76743 of epoch 1, 49.67 ms/it, loss 0.423326
Finished training it 56320/76743 of epoch 1, 49.48 ms/it, loss 0.419123
Finished training it 56320/76743 of epoch 1, 48.29 ms/it, loss 0.421400
Finished training it 57344/76743 of epoch 1, 49.91 ms/it, loss 0.419637
Finished training it 57344/76743 of epoch 1, 49.96 ms/it, loss 0.421507
Finished training it 57344/76743 of epoch 1, 48.23 ms/it, loss 0.421912
Finished training it 57344/76743 of epoch 1, 50.30 ms/it, loss 0.419900
Finished training it 58368/76743 of epoch 1, 47.93 ms/it, loss 0.419634
Finished training it 58368/76743 of epoch 1, 47.83 ms/it, loss 0.416819
Finished training it 58368/76743 of epoch 1, 46.68 ms/it, loss 0.418150
Finished training it 58368/76743 of epoch 1, 47.66 ms/it, loss 0.417169
Finished training it 59392/76743 of epoch 1, 46.04 ms/it, loss 0.415898
Finished training it 59392/76743 of epoch 1, 46.10 ms/it, loss 0.417124
Finished training it 59392/76743 of epoch 1, 46.43 ms/it, loss 0.419992
Finished training it 59392/76743 of epoch 1, 45.35 ms/it, loss 0.419134
Finished training it 60416/76743 of epoch 1, 46.65 ms/it, loss 0.415793
Finished training it 60416/76743 of epoch 1, 46.57 ms/it, loss 0.418645
Finished training it 60416/76743 of epoch 1, 46.60 ms/it, loss 0.418343
Finished training it 60416/76743 of epoch 1, 46.01 ms/it, loss 0.416913
Finished training it 61440/76743 of epoch 1, 49.96 ms/it, loss 0.416376
Finished training it 61440/76743 of epoch 1, 49.78 ms/it, loss 0.416954
Finished training it 61440/76743 of epoch 1, 49.76 ms/it, loss 0.418587
Finished training it 61440/76743 of epoch 1, 48.27 ms/it, loss 0.413730
Testing at - 61440/76743 of epoch 1,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216Warning: Skipping the batch 25580 with size 90
rank: 0 test_accu: 2566101.0
get out
0 has test check 2566101.0 and sample count 3274240
 accuracy 78.372 %, best 78.729 %, roc auc score 0.7874, best 0.7998
Testing at - 61440/76743 of epoch 1,
Warning: Skipping the batch 25580 with size 90
rank: 1 test_accu: 2566101.0
get out
1 has test check 2566101.0 and sample count 3274240
Finished training it 62464/76743 of epoch 1, 50.06 ms/it, loss 0.415758
Testing at - 61440/76743 of epoch 1,
Warning: Skipping the batch 25580 with size 90
rank: 3 test_accu: 2566101.0
get out
3 has test check 2566101.0 and sample count 3274240
Finished training it 62464/76743 of epoch 1, 49.94 ms/it, loss 0.415521
Finished training it 62464/76743 of epoch 1, 50.07 ms/it, loss 0.417678
Testing at - 61440/76743 of epoch 1,
Warning: Skipping the batch 25580 with size 90
rank: 2 test_accu: 2566101.0
get out
2 has test check 2566101.0 and sample count 3274240
Finished training it 62464/76743 of epoch 1, 48.33 ms/it, loss 0.416744
Finished training it 63488/76743 of epoch 1, 49.30 ms/it, loss 0.417547
Finished training it 63488/76743 of epoch 1, 49.67 ms/it, loss 0.414124
Finished training it 63488/76743 of epoch 1, 49.49 ms/it, loss 0.414278
Finished training it 63488/76743 of epoch 1, 47.82 ms/it, loss 0.417276
Finished training it 64512/76743 of epoch 1, 50.21 ms/it, loss 0.412341
Finished training it 64512/76743 of epoch 1, 48.17 ms/it, loss 0.414340
Finished training it 64512/76743 of epoch 1, 50.07 ms/it, loss 0.416328
Finished training it 64512/76743 of epoch 1, 49.89 ms/it, loss 0.413774
Finished training it 65536/76743 of epoch 1, 50.27 ms/it, loss 0.414338
Finished training it 65536/76743 of epoch 1, 49.94 ms/it, loss 0.414180
Finished training it 65536/76743 of epoch 1, 48.51 ms/it, loss 0.414190
Finished training it 65536/76743 of epoch 1, 50.10 ms/it, loss 0.411742
Finished training it 66560/76743 of epoch 1, 49.64 ms/it, loss 0.411758
Finished training it 66560/76743 of epoch 1, 49.64 ms/it, loss 0.413679
Finished training it 66560/76743 of epoch 1, 48.24 ms/it, loss 0.413291
Finished training it 66560/76743 of epoch 1, 49.54 ms/it, loss 0.412322
Finished training it 67584/76743 of epoch 1, 49.77 ms/it, loss 0.410344
Finished training it 67584/76743 of epoch 1, 49.68 ms/it, loss 0.410841
Finished training it 67584/76743 of epoch 1, 49.60 ms/it, loss 0.409594
Finished training it 67584/76743 of epoch 1, 48.05 ms/it, loss 0.408468
Finished training it 68608/76743 of epoch 1, 48.23 ms/it, loss 0.409154
Finished training it 68608/76743 of epoch 1, 48.11 ms/it, loss 0.408738
Finished training it 68608/76743 of epoch 1, 48.25 ms/it, loss 0.407967
Finished training it 68608/76743 of epoch 1, 46.91 ms/it, loss 0.411128
Finished training it 69632/76743 of epoch 1, 46.15 ms/it, loss 0.407397
Finished training it 69632/76743 of epoch 1, 46.07 ms/it, loss 0.409596
Finished training it 69632/76743 of epoch 1, 45.68 ms/it, loss 0.406506
Finished training it 69632/76743 of epoch 1, 45.94 ms/it, loss 0.407196
Finished training it 70656/76743 of epoch 1, 47.05 ms/it, loss 0.406557
Finished training it 70656/76743 of epoch 1, 46.97 ms/it, loss 0.406416
Finished training it 70656/76743 of epoch 1, 46.89 ms/it, loss 0.410803
Finished training it 70656/76743 of epoch 1, 45.85 ms/it, loss 0.408402
Finished training it 71680/76743 of epoch 1, 49.00 ms/it, loss 0.406631
Finished training it 71680/76743 of epoch 1, 49.21 ms/it, loss 0.403357
Finished training it 71680/76743 of epoch 1, 47.87 ms/it, loss 0.408135
Finished training it 71680/76743 of epoch 1, 49.33 ms/it, loss 0.407907
Testing at - 71680/76743 of epoch 1,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216Warning: Skipping the batch 25580 with size 90
rank: 0 test_accu: 2542426.0
get out
0 has test check 2542426.0 and sample count 3274240
 accuracy 77.649 %, best 78.729 %, roc auc score 0.7884, best 0.7998
Testing at - 71680/76743 of epoch 1,
Warning: Skipping the batch 25580 with size 90
rank: 2 test_accu: 2542426.0
get out
2 has test check 2542426.0 and sample count 3274240
Finished training it 72704/76743 of epoch 1, 47.97 ms/it, loss 0.407173
Testing at - 71680/76743 of epoch 1,
Warning: Skipping the batch 25580 with size 90
rank: 3 test_accu: 2542426.0
get out
3 has test check 2542426.0 and sample count 3274240
Finished training it 72704/76743 of epoch 1, 49.44 ms/it, loss 0.405576
Finished training it 72704/76743 of epoch 1, 49.52 ms/it, loss 0.405060
Testing at - 71680/76743 of epoch 1,
Warning: Skipping the batch 25580 with size 90
rank: 1 test_accu: 2542426.0
get out
1 has test check 2542426.0 and sample count 3274240
Finished training it 72704/76743 of epoch 1, 49.41 ms/it, loss 0.407215
Finished training it 73728/76743 of epoch 1, 49.44 ms/it, loss 0.407584
Finished training it 73728/76743 of epoch 1, 48.18 ms/it, loss 0.404601
Finished training it 73728/76743 of epoch 1, 49.35 ms/it, loss 0.405984
Finished training it 73728/76743 of epoch 1, 49.75 ms/it, loss 0.404562
Finished training it 74752/76743 of epoch 1, 48.93 ms/it, loss 0.405160
Finished training it 74752/76743 of epoch 1, 49.69 ms/it, loss 0.402530
Finished training it 74752/76743 of epoch 1, 49.53 ms/it, loss 0.404036
Finished training it 74752/76743 of epoch 1, 49.60 ms/it, loss 0.402894
Finished training it 75776/76743 of epoch 1, 49.60 ms/it, loss 0.402687
Finished training it 75776/76743 of epoch 1, 49.58 ms/it, loss 0.400719
Finished training it 75776/76743 of epoch 1, 49.77 ms/it, loss 0.405301
Finished training it 75776/76743 of epoch 1, 49.12 ms/it, loss 0.404207
Warning: Skipping the batch 76742 with size 14
Finished training it 1024/76743 of epoch 2, 53.53 ms/it, loss 0.400988
Warning: Skipping the batch 76742 with size 14
Finished training it 1024/76743 of epoch 2, 52.96 ms/it, loss 0.400926
Warning: Skipping the batch 76742 with size 14
Finished training it 1024/76743 of epoch 2, 53.17 ms/it, loss 0.401806
Warning: Skipping the batch 76742 with size 14
Finished training it 1024/76743 of epoch 2, 52.36 ms/it, loss 0.400480
Finished training it 2048/76743 of epoch 2, 49.87 ms/it, loss 0.397598
Finished training it 2048/76743 of epoch 2, 50.00 ms/it, loss 0.396346
Finished training it 2048/76743 of epoch 2, 49.15 ms/it, loss 0.396192
Finished training it 2048/76743 of epoch 2, 49.80 ms/it, loss 0.399113
Finished training it 3072/76743 of epoch 2, 49.91 ms/it, loss 0.393572
Finished training it 3072/76743 of epoch 2, 49.76 ms/it, loss 0.397150
Finished training it 3072/76743 of epoch 2, 49.92 ms/it, loss 0.394415
Finished training it 3072/76743 of epoch 2, 48.97 ms/it, loss 0.394868
Finished training it 4096/76743 of epoch 2, 49.86 ms/it, loss 0.393856
Finished training it 4096/76743 of epoch 2, 50.02 ms/it, loss 0.393947
Finished training it 4096/76743 of epoch 2, 49.64 ms/it, loss 0.392027
Finished training it 4096/76743 of epoch 2, 49.12 ms/it, loss 0.395952
Finished training it 5120/76743 of epoch 2, 50.11 ms/it, loss 0.390848
Finished training it 5120/76743 of epoch 2, 49.33 ms/it, loss 0.390579
Finished training it 5120/76743 of epoch 2, 49.90 ms/it, loss 0.391761
Finished training it 5120/76743 of epoch 2, 49.83 ms/it, loss 0.390022
Finished training it 6144/76743 of epoch 2, 49.87 ms/it, loss 0.391366
Finished training it 6144/76743 of epoch 2, 49.73 ms/it, loss 0.388349
Finished training it 6144/76743 of epoch 2, 49.11 ms/it, loss 0.390475
Finished training it 6144/76743 of epoch 2, 49.75 ms/it, loss 0.390367
Finished training it 7168/76743 of epoch 2, 47.25 ms/it, loss 0.385976
Finished training it 7168/76743 of epoch 2, 47.92 ms/it, loss 0.385594
Finished training it 7168/76743 of epoch 2, 47.87 ms/it, loss 0.385961
Finished training it 7168/76743 of epoch 2, 47.65 ms/it, loss 0.388109
Finished training it 8192/76743 of epoch 2, 44.70 ms/it, loss 0.386856
Finished training it 8192/76743 of epoch 2, 45.21 ms/it, loss 0.384748
Finished training it 8192/76743 of epoch 2, 45.10 ms/it, loss 0.387349
Finished training it 8192/76743 of epoch 2, 45.14 ms/it, loss 0.389008
Finished training it 9216/76743 of epoch 2, 46.49 ms/it, loss 0.385044
Finished training it 9216/76743 of epoch 2, 46.65 ms/it, loss 0.385125
Finished training it 9216/76743 of epoch 2, 46.03 ms/it, loss 0.384008
Finished training it 9216/76743 of epoch 2, 46.35 ms/it, loss 0.385377
Finished training it 10240/76743 of epoch 2, 49.28 ms/it, loss 0.386616
Finished training it 10240/76743 of epoch 2, 49.54 ms/it, loss 0.387269
Finished training it 10240/76743 of epoch 2, 49.11 ms/it, loss 0.383570
Finished training it 10240/76743 of epoch 2, 49.32 ms/it, loss 0.382998
Testing at - 10240/76743 of epoch 2,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216Warning: Skipping the batch 25580 with size 90
rank: 0 test_accu: 2556614.0
get out
0 has test check 2556614.0 and sample count 3274240
 accuracy 78.083 %, best 78.729 %, roc auc score 0.7687, best 0.7998
Finished training it 11264/76743 of epoch 2, 49.80 ms/it, loss 0.384222
Testing at - 10240/76743 of epoch 2,
Warning: Skipping the batch 25580 with size 90
rank: 1 test_accu: 2556614.0
get out
1 has test check 2556614.0 and sample count 3274240
Finished training it 11264/76743 of epoch 2, 49.80 ms/it, loss 0.384691
Testing at - 10240/76743 of epoch 2,
Warning: Skipping the batch 25580 with size 90
rank: 2 test_accu: 2556614.0
get out
2 has test check 2556614.0 and sample count 3274240
Finished training it 11264/76743 of epoch 2, 48.89 ms/it, loss 0.385050
Testing at - 10240/76743 of epoch 2,
Warning: Skipping the batch 25580 with size 90
rank: 3 test_accu: 2556614.0
get out
3 has test check 2556614.0 and sample count 3274240
Finished training it 11264/76743 of epoch 2, 49.90 ms/it, loss 0.385880
Finished training it 12288/76743 of epoch 2, 48.96 ms/it, loss 0.379196
Finished training it 12288/76743 of epoch 2, 49.52 ms/it, loss 0.377060
Finished training it 12288/76743 of epoch 2, 49.86 ms/it, loss 0.380126
Finished training it 12288/76743 of epoch 2, 49.72 ms/it, loss 0.379604
Finished training it 13312/76743 of epoch 2, 49.85 ms/it, loss 0.378027
Finished training it 13312/76743 of epoch 2, 50.03 ms/it, loss 0.379425
Finished training it 13312/76743 of epoch 2, 49.78 ms/it, loss 0.380691
Finished training it 13312/76743 of epoch 2, 49.24 ms/it, loss 0.380842
Finished training it 14336/76743 of epoch 2, 49.34 ms/it, loss 0.379611
Finished training it 14336/76743 of epoch 2, 48.72 ms/it, loss 0.379003
Finished training it 14336/76743 of epoch 2, 49.36 ms/it, loss 0.377507
Finished training it 14336/76743 of epoch 2, 49.37 ms/it, loss 0.377888
Finished training it 15360/76743 of epoch 2, 49.62 ms/it, loss 0.373849
Finished training it 15360/76743 of epoch 2, 49.81 ms/it, loss 0.373505
Finished training it 15360/76743 of epoch 2, 49.55 ms/it, loss 0.375372
Finished training it 15360/76743 of epoch 2, 48.86 ms/it, loss 0.376104
Finished training it 16384/76743 of epoch 2, 49.02 ms/it, loss 0.372310
Finished training it 16384/76743 of epoch 2, 50.12 ms/it, loss 0.374855
Finished training it 16384/76743 of epoch 2, 50.07 ms/it, loss 0.374050
Finished training it 16384/76743 of epoch 2, 49.91 ms/it, loss 0.373499
Finished training it 17408/76743 of epoch 2, 47.77 ms/it, loss 0.370876
Finished training it 17408/76743 of epoch 2, 47.79 ms/it, loss 0.373378
Finished training it 17408/76743 of epoch 2, 47.91 ms/it, loss 0.372847
Finished training it 17408/76743 of epoch 2, 47.33 ms/it, loss 0.370793
Finished training it 18432/76743 of epoch 2, 45.48 ms/it, loss 0.370606
Finished training it 18432/76743 of epoch 2, 45.56 ms/it, loss 0.372655
Finished training it 18432/76743 of epoch 2, 45.86 ms/it, loss 0.371700
Finished training it 18432/76743 of epoch 2, 45.76 ms/it, loss 0.371104
Finished training it 19456/76743 of epoch 2, 45.97 ms/it, loss 0.368705
Finished training it 19456/76743 of epoch 2, 45.90 ms/it, loss 0.373628
Finished training it 19456/76743 of epoch 2, 45.19 ms/it, loss 0.367755
Finished training it 19456/76743 of epoch 2, 45.90 ms/it, loss 0.369768
Finished training it 20480/76743 of epoch 2, 50.10 ms/it, loss 0.368446
Finished training it 20480/76743 of epoch 2, 50.00 ms/it, loss 0.368451
Finished training it 20480/76743 of epoch 2, 49.18 ms/it, loss 0.367072
Finished training it 20480/76743 of epoch 2, 49.72 ms/it, loss 0.367392
Testing at - 20480/76743 of epoch 2,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216Warning: Skipping the batch 25580 with size 90
rank: 0 test_accu: 2540679.0
get out
0 has test check 2540679.0 and sample count 3274240
 accuracy 77.596 %, best 78.729 %, roc auc score 0.7752, best 0.7998
Testing at - 20480/76743 of epoch 2,
Warning: Skipping the batch 25580 with size 90
rank: 1 test_accu: 2540679.0
get out
1 has test check 2540679.0 and sample count 3274240
Finished training it 21504/76743 of epoch 2, 49.92 ms/it, loss 0.367812
Finished training it 21504/76743 of epoch 2, 49.74 ms/it, loss 0.368464
Testing at - 20480/76743 of epoch 2,
Warning: Skipping the batch 25580 with size 90
rank: 3 test_accu: 2540679.0
get out
3 has test check 2540679.0 and sample count 3274240
Finished training it 21504/76743 of epoch 2, 49.73 ms/it, loss 0.368166
Testing at - 20480/76743 of epoch 2,
Warning: Skipping the batch 25580 with size 90
rank: 2 test_accu: 2540679.0
get out
2 has test check 2540679.0 and sample count 3274240
Finished training it 21504/76743 of epoch 2, 49.14 ms/it, loss 0.368292
Finished training it 22528/76743 of epoch 2, 49.91 ms/it, loss 0.367452
Finished training it 22528/76743 of epoch 2, 49.88 ms/it, loss 0.366493
Finished training it 22528/76743 of epoch 2, 48.84 ms/it, loss 0.365533
Finished training it 22528/76743 of epoch 2, 49.79 ms/it, loss 0.365811
Finished training it 23552/76743 of epoch 2, 48.37 ms/it, loss 0.364964
Finished training it 23552/76743 of epoch 2, 49.21 ms/it, loss 0.365606
Finished training it 23552/76743 of epoch 2, 49.21 ms/it, loss 0.361848
Finished training it 23552/76743 of epoch 2, 49.11 ms/it, loss 0.364520
Finished training it 24576/76743 of epoch 2, 49.90 ms/it, loss 0.364918
Finished training it 24576/76743 of epoch 2, 49.91 ms/it, loss 0.364695
Finished training it 24576/76743 of epoch 2, 48.99 ms/it, loss 0.363359
Finished training it 24576/76743 of epoch 2, 49.65 ms/it, loss 0.363026
Finished training it 25600/76743 of epoch 2, 49.80 ms/it, loss 0.360799
Finished training it 25600/76743 of epoch 2, 49.79 ms/it, loss 0.364705
Finished training it 25600/76743 of epoch 2, 49.65 ms/it, loss 0.362909
Finished training it 25600/76743 of epoch 2, 48.67 ms/it, loss 0.363164
Finished training it 26624/76743 of epoch 2, 54.96 ms/it, loss 0.360051
Finished training it 26624/76743 of epoch 2, 54.70 ms/it, loss 0.362504
Finished training it 26624/76743 of epoch 2, 54.97 ms/it, loss 0.360177
Finished training it 26624/76743 of epoch 2, 54.09 ms/it, loss 0.362573
Finished training it 27648/76743 of epoch 2, 47.94 ms/it, loss 0.357676
Finished training it 27648/76743 of epoch 2, 47.30 ms/it, loss 0.358500
Finished training it 27648/76743 of epoch 2, 47.79 ms/it, loss 0.356484
Finished training it 27648/76743 of epoch 2, 47.90 ms/it, loss 0.360008
Finished training it 28672/76743 of epoch 2, 45.68 ms/it, loss 0.358165
Finished training it 28672/76743 of epoch 2, 45.57 ms/it, loss 0.360249
Finished training it 28672/76743 of epoch 2, 45.13 ms/it, loss 0.360529
Finished training it 28672/76743 of epoch 2, 45.64 ms/it, loss 0.359317
Finished training it 29696/76743 of epoch 2, 44.87 ms/it, loss 0.354274
Finished training it 29696/76743 of epoch 2, 45.46 ms/it, loss 0.358723
Finished training it 29696/76743 of epoch 2, 45.80 ms/it, loss 0.359750
Finished training it 29696/76743 of epoch 2, 45.48 ms/it, loss 0.355144
Finished training it 30720/76743 of epoch 2, 49.81 ms/it, loss 0.358100
Finished training it 30720/76743 of epoch 2, 49.85 ms/it, loss 0.356746
Finished training it 30720/76743 of epoch 2, 49.84 ms/it, loss 0.356684
Finished training it 30720/76743 of epoch 2, 49.31 ms/it, loss 0.356165
Testing at - 30720/76743 of epoch 2,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216Warning: Skipping the batch 25580 with size 90
rank: 0 test_accu: 2539814.0
get out
0 has test check 2539814.0 and sample count 3274240
 accuracy 77.570 %, best 78.729 %, roc auc score 0.7772, best 0.7998
Finished training it 31744/76743 of epoch 2, 49.83 ms/it, loss 0.354110
Testing at - 30720/76743 of epoch 2,
Warning: Skipping the batch 25580 with size 90
rank: 1 test_accu: 2539814.0
get out
1 has test check 2539814.0 and sample count 3274240
Finished training it 31744/76743 of epoch 2, 49.88 ms/it, loss 0.356709
Testing at - 30720/76743 of epoch 2,
Warning: Skipping the batch 25580 with size 90
rank: 3 test_accu: 2539814.0
get out
3 has test check 2539814.0 and sample count 3274240
Finished training it 31744/76743 of epoch 2, 49.84 ms/it, loss 0.353351
Testing at - 30720/76743 of epoch 2,
Warning: Skipping the batch 25580 with size 90
rank: 2 test_accu: 2539814.0
get out
2 has test check 2539814.0 and sample count 3274240
Finished training it 31744/76743 of epoch 2, 49.31 ms/it, loss 0.356647
Finished training it 32768/76743 of epoch 2, 49.81 ms/it, loss 0.356376
Finished training it 32768/76743 of epoch 2, 49.67 ms/it, loss 0.353906
Finished training it 32768/76743 of epoch 2, 48.79 ms/it, loss 0.353070
Finished training it 32768/76743 of epoch 2, 49.87 ms/it, loss 0.354777
Finished training it 33792/76743 of epoch 2, 50.12 ms/it, loss 0.354311
Finished training it 33792/76743 of epoch 2, 49.94 ms/it, loss 0.350613
Finished training it 33792/76743 of epoch 2, 50.02 ms/it, loss 0.353115
Finished training it 33792/76743 of epoch 2, 48.95 ms/it, loss 0.351768
Finished training it 34816/76743 of epoch 2, 49.77 ms/it, loss 0.352488
Finished training it 34816/76743 of epoch 2, 48.85 ms/it, loss 0.353228
Finished training it 34816/76743 of epoch 2, 49.90 ms/it, loss 0.352614
Finished training it 34816/76743 of epoch 2, 49.76 ms/it, loss 0.351949
Finished training it 35840/76743 of epoch 2, 49.70 ms/it, loss 0.349896
Finished training it 35840/76743 of epoch 2, 49.79 ms/it, loss 0.352211
Finished training it 35840/76743 of epoch 2, 50.02 ms/it, loss 0.353706
Finished training it 35840/76743 of epoch 2, 49.10 ms/it, loss 0.349759
Finished training it 36864/76743 of epoch 2, 49.73 ms/it, loss 0.347204
Finished training it 36864/76743 of epoch 2, 49.90 ms/it, loss 0.348272
Finished training it 36864/76743 of epoch 2, 49.89 ms/it, loss 0.351725
Finished training it 36864/76743 of epoch 2, 49.02 ms/it, loss 0.351808
Finished training it 37888/76743 of epoch 2, 46.69 ms/it, loss 0.351330
Finished training it 37888/76743 of epoch 2, 47.28 ms/it, loss 0.350255
Finished training it 37888/76743 of epoch 2, 47.18 ms/it, loss 0.350146
Finished training it 37888/76743 of epoch 2, 47.26 ms/it, loss 0.349063
Finished training it 38912/76743 of epoch 2, 45.16 ms/it, loss 0.350566
Finished training it 38912/76743 of epoch 2, 45.31 ms/it, loss 0.349799
Finished training it 38912/76743 of epoch 2, 45.35 ms/it, loss 0.348032
Finished training it 38912/76743 of epoch 2, 44.96 ms/it, loss 0.349192
Finished training it 39936/76743 of epoch 2, 45.71 ms/it, loss 0.345889
Finished training it 39936/76743 of epoch 2, 45.77 ms/it, loss 0.347618
Finished training it 39936/76743 of epoch 2, 45.72 ms/it, loss 0.345302
Finished training it 39936/76743 of epoch 2, 45.07 ms/it, loss 0.344838
Finished training it 40960/76743 of epoch 2, 49.03 ms/it, loss 0.346656
Finished training it 40960/76743 of epoch 2, 49.95 ms/it, loss 0.348369
Finished training it 40960/76743 of epoch 2, 49.79 ms/it, loss 0.348362
Finished training it 40960/76743 of epoch 2, 49.85 ms/it, loss 0.346051
Testing at - 40960/76743 of epoch 2,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216Warning: Skipping the batch 25580 with size 90
rank: 0 test_accu: 2525383.0
get out
0 has test check 2525383.0 and sample count 3274240
 accuracy 77.129 %, best 78.729 %, roc auc score 0.7779, best 0.7998
Testing at - 40960/76743 of epoch 2,
Warning: Skipping the batch 25580 with size 90
rank: 1 test_accu: 2525383.0
get out
1 has test check 2525383.0 and sample count 3274240
Finished training it 41984/76743 of epoch 2, 50.41 ms/it, loss 0.346699
Testing at - 40960/76743 of epoch 2,
Warning: Skipping the batch 25580 with size 90
rank: 3 test_accu: 2525383.0
get out
3 has test check 2525383.0 and sample count 3274240
Finished training it 41984/76743 of epoch 2, 50.34 ms/it, loss 0.345470
Finished training it 41984/76743 of epoch 2, 50.34 ms/it, loss 0.347121
Testing at - 40960/76743 of epoch 2,
Warning: Skipping the batch 25580 with size 90
rank: 2 test_accu: 2525383.0
get out
2 has test check 2525383.0 and sample count 3274240
Finished training it 41984/76743 of epoch 2, 49.70 ms/it, loss 0.346814
Finished training it 43008/76743 of epoch 2, 49.79 ms/it, loss 0.346797
Finished training it 43008/76743 of epoch 2, 49.77 ms/it, loss 0.344213
Finished training it 43008/76743 of epoch 2, 49.08 ms/it, loss 0.344733
Finished training it 43008/76743 of epoch 2, 49.94 ms/it, loss 0.346747
Finished training it 44032/76743 of epoch 2, 50.22 ms/it, loss 0.341980
Finished training it 44032/76743 of epoch 2, 49.17 ms/it, loss 0.345109
Finished training it 44032/76743 of epoch 2, 50.02 ms/it, loss 0.343407
Finished training it 44032/76743 of epoch 2, 49.99 ms/it, loss 0.345599
Finished training it 45056/76743 of epoch 2, 49.69 ms/it, loss 0.346018
Finished training it 45056/76743 of epoch 2, 49.87 ms/it, loss 0.346263
Finished training it 45056/76743 of epoch 2, 48.94 ms/it, loss 0.342852
Finished training it 45056/76743 of epoch 2, 49.56 ms/it, loss 0.344930
Finished training it 46080/76743 of epoch 2, 49.68 ms/it, loss 0.343662
Finished training it 46080/76743 of epoch 2, 49.90 ms/it, loss 0.343689
Finished training it 46080/76743 of epoch 2, 48.95 ms/it, loss 0.341075
Finished training it 46080/76743 of epoch 2, 49.78 ms/it, loss 0.342932
Finished training it 47104/76743 of epoch 2, 49.54 ms/it, loss 0.343237
Finished training it 47104/76743 of epoch 2, 49.74 ms/it, loss 0.345445
Finished training it 47104/76743 of epoch 2, 48.82 ms/it, loss 0.338513
Finished training it 47104/76743 of epoch 2, 49.76 ms/it, loss 0.343935
Finished training it 48128/76743 of epoch 2, 47.15 ms/it, loss 0.341750
Finished training it 48128/76743 of epoch 2, 47.22 ms/it, loss 0.343243
Finished training it 48128/76743 of epoch 2, 46.50 ms/it, loss 0.343033
Finished training it 48128/76743 of epoch 2, 47.07 ms/it, loss 0.342784
Finished training it 49152/76743 of epoch 2, 44.78 ms/it, loss 0.341636
Finished training it 49152/76743 of epoch 2, 45.25 ms/it, loss 0.340239
Finished training it 49152/76743 of epoch 2, 45.59 ms/it, loss 0.339959
Finished training it 49152/76743 of epoch 2, 45.38 ms/it, loss 0.340924
Finished training it 50176/76743 of epoch 2, 46.41 ms/it, loss 0.337282
Finished training it 50176/76743 of epoch 2, 45.69 ms/it, loss 0.340347
Finished training it 50176/76743 of epoch 2, 46.42 ms/it, loss 0.338260
Finished training it 50176/76743 of epoch 2, 46.58 ms/it, loss 0.340008
Finished training it 51200/76743 of epoch 2, 49.53 ms/it, loss 0.338609
Finished training it 51200/76743 of epoch 2, 49.91 ms/it, loss 0.338104
Finished training it 51200/76743 of epoch 2, 49.19 ms/it, loss 0.343366
Finished training it 51200/76743 of epoch 2, 49.82 ms/it, loss 0.339114
Testing at - 51200/76743 of epoch 2,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216Warning: Skipping the batch 25580 with size 90
rank: 0 test_accu: 2549580.0
get out
0 has test check 2549580.0 and sample count 3274240
 accuracy 77.868 %, best 78.729 %, roc auc score 0.7797, best 0.7998
Testing at - 51200/76743 of epoch 2,
Warning: Skipping the batch 25580 with size 90
rank: 2 test_accu: 2549580.0
get out
2 has test check 2549580.0 and sample count 3274240
Finished training it 52224/76743 of epoch 2, 49.44 ms/it, loss 0.339895
Finished training it 52224/76743 of epoch 2, 49.75 ms/it, loss 0.336291
Testing at - 51200/76743 of epoch 2,
Warning: Skipping the batch 25580 with size 90
rank: 3 test_accu: 2549580.0
get out
3 has test check 2549580.0 and sample count 3274240
Finished training it 52224/76743 of epoch 2, 49.77 ms/it, loss 0.339135
Testing at - 51200/76743 of epoch 2,
Warning: Skipping the batch 25580 with size 90
rank: 1 test_accu: 2549580.0
get out
1 has test check 2549580.0 and sample count 3274240
Finished training it 52224/76743 of epoch 2, 49.80 ms/it, loss 0.338689
Finished training it 53248/76743 of epoch 2, 48.87 ms/it, loss 0.340115
Finished training it 53248/76743 of epoch 2, 48.80 ms/it, loss 0.339518
Finished training it 53248/76743 of epoch 2, 48.14 ms/it, loss 0.335323
Finished training it 53248/76743 of epoch 2, 48.85 ms/it, loss 0.338207
Finished training it 54272/76743 of epoch 2, 50.20 ms/it, loss 0.335648
Finished training it 54272/76743 of epoch 2, 50.05 ms/it, loss 0.337340
Finished training it 54272/76743 of epoch 2, 50.03 ms/it, loss 0.338107
Finished training it 54272/76743 of epoch 2, 49.39 ms/it, loss 0.338595
Finished training it 55296/76743 of epoch 2, 49.85 ms/it, loss 0.338744
Finished training it 55296/76743 of epoch 2, 48.91 ms/it, loss 0.337228
Finished training it 55296/76743 of epoch 2, 49.50 ms/it, loss 0.339263
Finished training it 55296/76743 of epoch 2, 49.66 ms/it, loss 0.336172
Finished training it 56320/76743 of epoch 2, 48.72 ms/it, loss 0.338069
Finished training it 56320/76743 of epoch 2, 49.84 ms/it, loss 0.338691
Finished training it 56320/76743 of epoch 2, 49.30 ms/it, loss 0.336818
Finished training it 56320/76743 of epoch 2, 49.32 ms/it, loss 0.337272
Finished training it 57344/76743 of epoch 2, 54.81 ms/it, loss 0.335651
Finished training it 57344/76743 of epoch 2, 55.35 ms/it, loss 0.336167
Finished training it 57344/76743 of epoch 2, 54.09 ms/it, loss 0.337898
Finished training it 57344/76743 of epoch 2, 54.97 ms/it, loss 0.337819
Finished training it 58368/76743 of epoch 2, 46.85 ms/it, loss 0.335434
Finished training it 58368/76743 of epoch 2, 46.79 ms/it, loss 0.334203
Finished training it 58368/76743 of epoch 2, 46.67 ms/it, loss 0.335760
Finished training it 58368/76743 of epoch 2, 46.33 ms/it, loss 0.336391
Finished training it 59392/76743 of epoch 2, 45.63 ms/it, loss 0.333754
Finished training it 59392/76743 of epoch 2, 45.66 ms/it, loss 0.336037
Finished training it 59392/76743 of epoch 2, 45.38 ms/it, loss 0.337861
Finished training it 59392/76743 of epoch 2, 45.08 ms/it, loss 0.335823
Finished training it 60416/76743 of epoch 2, 45.92 ms/it, loss 0.334292
Finished training it 60416/76743 of epoch 2, 46.32 ms/it, loss 0.333637
Finished training it 60416/76743 of epoch 2, 46.41 ms/it, loss 0.337872
Finished training it 60416/76743 of epoch 2, 46.40 ms/it, loss 0.337089
Finished training it 61440/76743 of epoch 2, 49.59 ms/it, loss 0.337402
Finished training it 61440/76743 of epoch 2, 49.88 ms/it, loss 0.335720
Finished training it 61440/76743 of epoch 2, 49.88 ms/it, loss 0.335804
Finished training it 61440/76743 of epoch 2, 49.06 ms/it, loss 0.334948
Testing at - 61440/76743 of epoch 2,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216Warning: Skipping the batch 25580 with size 90
rank: 0 test_accu: 2549398.0
get out
0 has test check 2549398.0 and sample count 3274240
 accuracy 77.862 %, best 78.729 %, roc auc score 0.7747, best 0.7998
Testing at - 61440/76743 of epoch 2,
Warning: Skipping the batch 25580 with size 90
rank: 3 test_accu: 2549398.0
get out
3 has test check 2549398.0 and sample count 3274240
Finished training it 62464/76743 of epoch 2, 49.69 ms/it, loss 0.335468
Finished training it 62464/76743 of epoch 2, 49.90 ms/it, loss 0.336186
Testing at - 61440/76743 of epoch 2,
Warning: Skipping the batch 25580 with size 90
rank: 1 test_accu: 2549398.0
get out
1 has test check 2549398.0 and sample count 3274240
Finished training it 62464/76743 of epoch 2, 49.96 ms/it, loss 0.334126
Testing at - 61440/76743 of epoch 2,
Warning: Skipping the batch 25580 with size 90
rank: 2 test_accu: 2549398.0
get out
2 has test check 2549398.0 and sample count 3274240
Finished training it 62464/76743 of epoch 2, 49.31 ms/it, loss 0.337565
Finished training it 63488/76743 of epoch 2, 49.74 ms/it, loss 0.337802
Finished training it 63488/76743 of epoch 2, 49.66 ms/it, loss 0.333362
Finished training it 63488/76743 of epoch 2, 49.05 ms/it, loss 0.336777
Finished training it 63488/76743 of epoch 2, 49.77 ms/it, loss 0.334263
Finished training it 64512/76743 of epoch 2, 49.57 ms/it, loss 0.334242
Finished training it 64512/76743 of epoch 2, 48.70 ms/it, loss 0.336770
Finished training it 64512/76743 of epoch 2, 49.70 ms/it, loss 0.336647
Finished training it 64512/76743 of epoch 2, 49.63 ms/it, loss 0.332614
Finished training it 65536/76743 of epoch 2, 49.80 ms/it, loss 0.336375
Finished training it 65536/76743 of epoch 2, 49.44 ms/it, loss 0.336005
Finished training it 65536/76743 of epoch 2, 48.81 ms/it, loss 0.334241
Finished training it 65536/76743 of epoch 2, 49.75 ms/it, loss 0.334498
Finished training it 66560/76743 of epoch 2, 49.65 ms/it, loss 0.337729
Finished training it 66560/76743 of epoch 2, 49.63 ms/it, loss 0.335230
Finished training it 66560/76743 of epoch 2, 48.95 ms/it, loss 0.337663
Finished training it 66560/76743 of epoch 2, 49.91 ms/it, loss 0.335234
Finished training it 67584/76743 of epoch 2, 49.84 ms/it, loss 0.333909
Finished training it 67584/76743 of epoch 2, 48.82 ms/it, loss 0.332273
Finished training it 67584/76743 of epoch 2, 49.57 ms/it, loss 0.334136
Finished training it 67584/76743 of epoch 2, 49.72 ms/it, loss 0.334337
Finished training it 68608/76743 of epoch 2, 46.98 ms/it, loss 0.333404
Finished training it 68608/76743 of epoch 2, 47.10 ms/it, loss 0.333608
Finished training it 68608/76743 of epoch 2, 46.40 ms/it, loss 0.336555
Finished training it 68608/76743 of epoch 2, 47.03 ms/it, loss 0.334609
Finished training it 69632/76743 of epoch 2, 45.47 ms/it, loss 0.334442
Finished training it 69632/76743 of epoch 2, 45.69 ms/it, loss 0.333096
Finished training it 69632/76743 of epoch 2, 45.64 ms/it, loss 0.331423
Finished training it 69632/76743 of epoch 2, 44.67 ms/it, loss 0.332403
Finished training it 70656/76743 of epoch 2, 46.01 ms/it, loss 0.332646
Finished training it 70656/76743 of epoch 2, 46.27 ms/it, loss 0.332903
Finished training it 70656/76743 of epoch 2, 45.98 ms/it, loss 0.335600
Finished training it 70656/76743 of epoch 2, 45.24 ms/it, loss 0.334177
Finished training it 71680/76743 of epoch 2, 49.91 ms/it, loss 0.332076
Finished training it 71680/76743 of epoch 2, 49.77 ms/it, loss 0.334621
Finished training it 71680/76743 of epoch 2, 48.83 ms/it, loss 0.334773
Finished training it 71680/76743 of epoch 2, 49.77 ms/it, loss 0.335395
Testing at - 71680/76743 of epoch 2,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216Warning: Skipping the batch 25580 with size 90
rank: 0 test_accu: 2550518.0
get out
0 has test check 2550518.0 and sample count 3274240
 accuracy 77.896 %, best 78.729 %, roc auc score 0.7762, best 0.7998
Testing at - 71680/76743 of epoch 2,
Warning: Skipping the batch 25580 with size 90
rank: 3 test_accu: 2550518.0
get out
3 has test check 2550518.0 and sample count 3274240
Finished training it 72704/76743 of epoch 2, 49.67 ms/it, loss 0.333433
Finished training it 72704/76743 of epoch 2, 49.71 ms/it, loss 0.332735
Testing at - 71680/76743 of epoch 2,
Warning: Skipping the batch 25580 with size 90
rank: 1 test_accu: 2550518.0
get out
1 has test check 2550518.0 and sample count 3274240
Finished training it 72704/76743 of epoch 2, 49.67 ms/it, loss 0.334375
Testing at - 71680/76743 of epoch 2,
Warning: Skipping the batch 25580 with size 90
rank: 2 test_accu: 2550518.0
get out
2 has test check 2550518.0 and sample count 3274240
Finished training it 72704/76743 of epoch 2, 49.18 ms/it, loss 0.335080
Finished training it 73728/76743 of epoch 2, 49.02 ms/it, loss 0.334203
Finished training it 73728/76743 of epoch 2, 49.24 ms/it, loss 0.331279
Finished training it 73728/76743 of epoch 2, 48.93 ms/it, loss 0.336132
Finished training it 73728/76743 of epoch 2, 48.65 ms/it, loss 0.332757
Finished training it 74752/76743 of epoch 2, 48.91 ms/it, loss 0.335194
Finished training it 74752/76743 of epoch 2, 49.69 ms/it, loss 0.333851
Finished training it 74752/76743 of epoch 2, 49.46 ms/it, loss 0.335392
Finished training it 74752/76743 of epoch 2, 49.78 ms/it, loss 0.332518
Finished training it 75776/76743 of epoch 2, 50.00 ms/it, loss 0.335610
Finished training it 75776/76743 of epoch 2, 49.89 ms/it, loss 0.332738
Finished training it 75776/76743 of epoch 2, 49.90 ms/it, loss 0.331677
Finished training it 75776/76743 of epoch 2, 49.02 ms/it, loss 0.335379
Warning: Skipping the batch 76742 with size 14
Finished training it 1024/76743 of epoch 3, 50.20 ms/it, loss 0.332464
Warning: Skipping the batch 76742 with size 14
Finished training it 1024/76743 of epoch 3, 50.35 ms/it, loss 0.334622
Warning: Skipping the batch 76742 with size 14
Finished training it 1024/76743 of epoch 3, 50.20 ms/it, loss 0.334470
Warning: Skipping the batch 76742 with size 14
Finished training it 1024/76743 of epoch 3, 49.91 ms/it, loss 0.332671
Finished training it 2048/76743 of epoch 3, 50.01 ms/it, loss 0.331749
Finished training it 2048/76743 of epoch 3, 49.96 ms/it, loss 0.334599
Finished training it 2048/76743 of epoch 3, 49.25 ms/it, loss 0.332955
Finished training it 2048/76743 of epoch 3, 50.05 ms/it, loss 0.332045
Finished training it 3072/76743 of epoch 3, 49.54 ms/it, loss 0.332730
Finished training it 3072/76743 of epoch 3, 49.98 ms/it, loss 0.333363
Finished training it 3072/76743 of epoch 3, 50.24 ms/it, loss 0.332512
Finished training it 3072/76743 of epoch 3, 50.00 ms/it, loss 0.332178
Finished training it 4096/76743 of epoch 3, 48.79 ms/it, loss 0.335736
Finished training it 4096/76743 of epoch 3, 49.63 ms/it, loss 0.332463
Finished training it 4096/76743 of epoch 3, 49.62 ms/it, loss 0.332473
Finished training it 4096/76743 of epoch 3, 49.39 ms/it, loss 0.333722
Finished training it 5120/76743 of epoch 3, 50.05 ms/it, loss 0.333216
Finished training it 5120/76743 of epoch 3, 49.84 ms/it, loss 0.331525
Finished training it 5120/76743 of epoch 3, 50.21 ms/it, loss 0.330425
Finished training it 5120/76743 of epoch 3, 49.25 ms/it, loss 0.331367
Finished training it 6144/76743 of epoch 3, 50.15 ms/it, loss 0.334810
Finished training it 6144/76743 of epoch 3, 49.91 ms/it, loss 0.330939
Finished training it 6144/76743 of epoch 3, 49.21 ms/it, loss 0.333769
Finished training it 6144/76743 of epoch 3, 49.90 ms/it, loss 0.333517
Finished training it 7168/76743 of epoch 3, 46.62 ms/it, loss 0.331942
Finished training it 7168/76743 of epoch 3, 46.30 ms/it, loss 0.331333
Finished training it 7168/76743 of epoch 3, 46.48 ms/it, loss 0.332448
Finished training it 7168/76743 of epoch 3, 45.92 ms/it, loss 0.330335
Finished training it 8192/76743 of epoch 3, 45.03 ms/it, loss 0.331218
Finished training it 8192/76743 of epoch 3, 45.28 ms/it, loss 0.335546
Finished training it 8192/76743 of epoch 3, 45.35 ms/it, loss 0.332551
Finished training it 8192/76743 of epoch 3, 44.90 ms/it, loss 0.331822
Finished training it 9216/76743 of epoch 3, 46.06 ms/it, loss 0.333709
Finished training it 9216/76743 of epoch 3, 45.86 ms/it, loss 0.331797
Finished training it 9216/76743 of epoch 3, 46.09 ms/it, loss 0.331312
Finished training it 9216/76743 of epoch 3, 45.75 ms/it, loss 0.331744
Finished training it 10240/76743 of epoch 3, 49.47 ms/it, loss 0.335249
Finished training it 10240/76743 of epoch 3, 49.64 ms/it, loss 0.333571
Finished training it 10240/76743 of epoch 3, 49.34 ms/it, loss 0.330817
Finished training it 10240/76743 of epoch 3, 48.77 ms/it, loss 0.331638
Testing at - 10240/76743 of epoch 3,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216Warning: Skipping the batch 25580 with size 90
rank: 0 test_accu: 2551329.0
get out
0 has test check 2551329.0 and sample count 3274240
 accuracy 77.921 %, best 78.729 %, roc auc score 0.7687, best 0.7998
Testing at - 10240/76743 of epoch 3,
Warning: Skipping the batch 25580 with size 90
rank: 1 test_accu: 2551329.0
get out
1 has test check 2551329.0 and sample count 3274240
Finished training it 11264/76743 of epoch 3, 49.90 ms/it, loss 0.333898
Testing at - 10240/76743 of epoch 3,
Warning: Skipping the batch 25580 with size 90
rank: 3 test_accu: 2551329.0
get out
3 has test check 2551329.0 and sample count 3274240
Finished training it 11264/76743 of epoch 3, 49.99 ms/it, loss 0.334118
Finished training it 11264/76743 of epoch 3, 50.01 ms/it, loss 0.332818
Testing at - 10240/76743 of epoch 3,
Warning: Skipping the batch 25580 with size 90
rank: 2 test_accu: 2551329.0
get out
2 has test check 2551329.0 and sample count 3274240
Finished training it 11264/76743 of epoch 3, 49.40 ms/it, loss 0.332536
Finished training it 12288/76743 of epoch 3, 48.83 ms/it, loss 0.329964
Finished training it 12288/76743 of epoch 3, 48.68 ms/it, loss 0.330613
Finished training it 12288/76743 of epoch 3, 48.83 ms/it, loss 0.328960
Finished training it 12288/76743 of epoch 3, 48.02 ms/it, loss 0.330975
Finished training it 13312/76743 of epoch 3, 49.90 ms/it, loss 0.331207
Finished training it 13312/76743 of epoch 3, 48.97 ms/it, loss 0.331798
Finished training it 13312/76743 of epoch 3, 49.69 ms/it, loss 0.330595
Finished training it 13312/76743 of epoch 3, 49.84 ms/it, loss 0.333171
Finished training it 14336/76743 of epoch 3, 49.80 ms/it, loss 0.331287
Finished training it 14336/76743 of epoch 3, 49.83 ms/it, loss 0.332363
Finished training it 14336/76743 of epoch 3, 49.84 ms/it, loss 0.332083
Finished training it 14336/76743 of epoch 3, 48.97 ms/it, loss 0.331861
Finished training it 15360/76743 of epoch 3, 49.57 ms/it, loss 0.330262
Finished training it 15360/76743 of epoch 3, 49.46 ms/it, loss 0.328673
Finished training it 15360/76743 of epoch 3, 49.53 ms/it, loss 0.330721
Finished training it 15360/76743 of epoch 3, 48.86 ms/it, loss 0.331811
Finished training it 16384/76743 of epoch 3, 55.07 ms/it, loss 0.329793
Finished training it 16384/76743 of epoch 3, 55.30 ms/it, loss 0.330168
Finished training it 16384/76743 of epoch 3, 55.70 ms/it, loss 0.329208
Finished training it 16384/76743 of epoch 3, 54.75 ms/it, loss 0.328760
Finished training it 17408/76743 of epoch 3, 47.39 ms/it, loss 0.330263
Finished training it 17408/76743 of epoch 3, 47.49 ms/it, loss 0.330528
Finished training it 17408/76743 of epoch 3, 46.65 ms/it, loss 0.329274
Finished training it 17408/76743 of epoch 3, 47.39 ms/it, loss 0.329506
Finished training it 18432/76743 of epoch 3, 45.32 ms/it, loss 0.331057
Finished training it 18432/76743 of epoch 3, 45.17 ms/it, loss 0.330465
Finished training it 18432/76743 of epoch 3, 45.34 ms/it, loss 0.331520
Finished training it 18432/76743 of epoch 3, 44.75 ms/it, loss 0.329355
Finished training it 19456/76743 of epoch 3, 46.40 ms/it, loss 0.329046
Finished training it 19456/76743 of epoch 3, 46.38 ms/it, loss 0.329485
Finished training it 19456/76743 of epoch 3, 46.27 ms/it, loss 0.327926
Finished training it 19456/76743 of epoch 3, 46.72 ms/it, loss 0.331354
Finished training it 20480/76743 of epoch 3, 50.02 ms/it, loss 0.328539
Finished training it 20480/76743 of epoch 3, 50.10 ms/it, loss 0.328061
Finished training it 20480/76743 of epoch 3, 49.95 ms/it, loss 0.327577
Finished training it 20480/76743 of epoch 3, 49.06 ms/it, loss 0.326797
Testing at - 20480/76743 of epoch 3,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216Warning: Skipping the batch 25580 with size 90
rank: 0 test_accu: 2553728.0
get out
0 has test check 2553728.0 and sample count 3274240
 accuracy 77.995 %, best 78.729 %, roc auc score 0.7668, best 0.7998
Finished training it 21504/76743 of epoch 3, 49.82 ms/it, loss 0.330850
Testing at - 20480/76743 of epoch 3,
Warning: Skipping the batch 25580 with size 90
rank: 3 test_accu: 2553728.0
get out
3 has test check 2553728.0 and sample count 3274240
Finished training it 21504/76743 of epoch 3, 49.72 ms/it, loss 0.329831
Testing at - 20480/76743 of epoch 3,
Warning: Skipping the batch 25580 with size 90
rank: 2 test_accu: 2553728.0
get out
2 has test check 2553728.0 and sample count 3274240
Finished training it 21504/76743 of epoch 3, 49.26 ms/it, loss 0.329289
Testing at - 20480/76743 of epoch 3,
Warning: Skipping the batch 25580 with size 90
rank: 1 test_accu: 2553728.0
get out
1 has test check 2553728.0 and sample count 3274240
Finished training it 21504/76743 of epoch 3, 49.75 ms/it, loss 0.329304
Finished training it 22528/76743 of epoch 3, 49.75 ms/it, loss 0.329136
Finished training it 22528/76743 of epoch 3, 49.09 ms/it, loss 0.328404
Finished training it 22528/76743 of epoch 3, 49.68 ms/it, loss 0.330374
Finished training it 22528/76743 of epoch 3, 49.90 ms/it, loss 0.329676
Finished training it 23552/76743 of epoch 3, 50.00 ms/it, loss 0.331306
Finished training it 23552/76743 of epoch 3, 50.61 ms/it, loss 0.327682
Finished training it 23552/76743 of epoch 3, 50.32 ms/it, loss 0.325446
Finished training it 23552/76743 of epoch 3, 49.71 ms/it, loss 0.329130
Finished training it 24576/76743 of epoch 3, 49.30 ms/it, loss 0.326948
Finished training it 24576/76743 of epoch 3, 49.98 ms/it, loss 0.326767
Finished training it 24576/76743 of epoch 3, 50.13 ms/it, loss 0.327965
Finished training it 24576/76743 of epoch 3, 50.14 ms/it, loss 0.328834
Finished training it 25600/76743 of epoch 3, 50.12 ms/it, loss 0.324807
Finished training it 25600/76743 of epoch 3, 49.81 ms/it, loss 0.325704
Finished training it 25600/76743 of epoch 3, 50.02 ms/it, loss 0.328887
Finished training it 25600/76743 of epoch 3, 49.30 ms/it, loss 0.327784
Finished training it 26624/76743 of epoch 3, 50.19 ms/it, loss 0.328010
Finished training it 26624/76743 of epoch 3, 49.49 ms/it, loss 0.329226
Finished training it 26624/76743 of epoch 3, 50.56 ms/it, loss 0.327761
Finished training it 26624/76743 of epoch 3, 50.31 ms/it, loss 0.329043
Finished training it 27648/76743 of epoch 3, 45.91 ms/it, loss 0.325149
Finished training it 27648/76743 of epoch 3, 46.41 ms/it, loss 0.325809
Finished training it 27648/76743 of epoch 3, 46.37 ms/it, loss 0.327172
Finished training it 27648/76743 of epoch 3, 46.18 ms/it, loss 0.324478
Finished training it 28672/76743 of epoch 3, 45.81 ms/it, loss 0.326483
Finished training it 28672/76743 of epoch 3, 45.59 ms/it, loss 0.328156
Finished training it 28672/76743 of epoch 3, 45.25 ms/it, loss 0.327033
Finished training it 28672/76743 of epoch 3, 45.14 ms/it, loss 0.329332
Finished training it 29696/76743 of epoch 3, 46.23 ms/it, loss 0.323433
Finished training it 29696/76743 of epoch 3, 46.88 ms/it, loss 0.325445
Finished training it 29696/76743 of epoch 3, 46.56 ms/it, loss 0.328478
Finished training it 29696/76743 of epoch 3, 47.05 ms/it, loss 0.327791
Finished training it 30720/76743 of epoch 3, 49.90 ms/it, loss 0.325757
Finished training it 30720/76743 of epoch 3, 50.25 ms/it, loss 0.326551
Finished training it 30720/76743 of epoch 3, 49.44 ms/it, loss 0.325485
Finished training it 30720/76743 of epoch 3, 50.19 ms/it, loss 0.327833
Testing at - 30720/76743 of epoch 3,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216Warning: Skipping the batch 25580 with size 90
rank: 0 test_accu: 2561768.0
get out
0 has test check 2561768.0 and sample count 3274240
 accuracy 78.240 %, best 78.729 %, roc auc score 0.7642, best 0.7998
Finished training it 31744/76743 of epoch 3, 49.76 ms/it, loss 0.324390
Testing at - 30720/76743 of epoch 3,
Warning: Skipping the batch 25580 with size 90
rank: 3 test_accu: 2561768.0
get out
3 has test check 2561768.0 and sample count 3274240
Finished training it 31744/76743 of epoch 3, 49.68 ms/it, loss 0.324720
Testing at - 30720/76743 of epoch 3,
Warning: Skipping the batch 25580 with size 90
rank: 1 test_accu: 2561768.0
get out
1 has test check 2561768.0 and sample count 3274240
Finished training it 31744/76743 of epoch 3, 49.65 ms/it, loss 0.325797
Testing at - 30720/76743 of epoch 3,
Warning: Skipping the batch 25580 with size 90
rank: 2 test_accu: 2561768.0
get out
2 has test check 2561768.0 and sample count 3274240
Finished training it 31744/76743 of epoch 3, 48.83 ms/it, loss 0.327221
Finished training it 32768/76743 of epoch 3, 49.97 ms/it, loss 0.327415
Finished training it 32768/76743 of epoch 3, 49.97 ms/it, loss 0.325785
Finished training it 32768/76743 of epoch 3, 49.26 ms/it, loss 0.324985
Finished training it 32768/76743 of epoch 3, 49.82 ms/it, loss 0.325601
Finished training it 33792/76743 of epoch 3, 49.52 ms/it, loss 0.325890
Finished training it 33792/76743 of epoch 3, 49.37 ms/it, loss 0.326570
Finished training it 33792/76743 of epoch 3, 49.09 ms/it, loss 0.324016
Finished training it 33792/76743 of epoch 3, 49.84 ms/it, loss 0.324277
Finished training it 34816/76743 of epoch 3, 49.41 ms/it, loss 0.326139
Finished training it 34816/76743 of epoch 3, 50.12 ms/it, loss 0.325017
Finished training it 34816/76743 of epoch 3, 50.04 ms/it, loss 0.326194
Finished training it 34816/76743 of epoch 3, 49.86 ms/it, loss 0.323923
Finished training it 35840/76743 of epoch 3, 50.08 ms/it, loss 0.324737
Finished training it 35840/76743 of epoch 3, 50.34 ms/it, loss 0.325925
Finished training it 35840/76743 of epoch 3, 50.01 ms/it, loss 0.322264
Finished training it 35840/76743 of epoch 3, 49.58 ms/it, loss 0.322207
Finished training it 36864/76743 of epoch 3, 49.22 ms/it, loss 0.324310
Finished training it 36864/76743 of epoch 3, 50.05 ms/it, loss 0.325359
Finished training it 36864/76743 of epoch 3, 49.98 ms/it, loss 0.320998
Finished training it 36864/76743 of epoch 3, 49.85 ms/it, loss 0.322466
Finished training it 37888/76743 of epoch 3, 46.71 ms/it, loss 0.325308
Finished training it 37888/76743 of epoch 3, 46.46 ms/it, loss 0.324114
Finished training it 37888/76743 of epoch 3, 46.30 ms/it, loss 0.324919
Finished training it 37888/76743 of epoch 3, 45.83 ms/it, loss 0.325978
Finished training it 38912/76743 of epoch 3, 45.65 ms/it, loss 0.325674
Finished training it 38912/76743 of epoch 3, 45.70 ms/it, loss 0.322487
Finished training it 38912/76743 of epoch 3, 45.02 ms/it, loss 0.325649
Finished training it 38912/76743 of epoch 3, 44.94 ms/it, loss 0.324275
Finished training it 39936/76743 of epoch 3, 47.17 ms/it, loss 0.321576
Finished training it 39936/76743 of epoch 3, 47.71 ms/it, loss 0.323760
Finished training it 39936/76743 of epoch 3, 47.36 ms/it, loss 0.321961
Finished training it 39936/76743 of epoch 3, 47.49 ms/it, loss 0.321892
Finished training it 40960/76743 of epoch 3, 49.76 ms/it, loss 0.324009
Finished training it 40960/76743 of epoch 3, 49.63 ms/it, loss 0.324829
Finished training it 40960/76743 of epoch 3, 50.01 ms/it, loss 0.321064
Finished training it 40960/76743 of epoch 3, 49.15 ms/it, loss 0.323051
Testing at - 40960/76743 of epoch 3,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216Warning: Skipping the batch 25580 with size 90
rank: 0 test_accu: 2554229.0
get out
0 has test check 2554229.0 and sample count 3274240
 accuracy 78.010 %, best 78.729 %, roc auc score 0.7677, best 0.7998
Testing at - 40960/76743 of epoch 3,
Warning: Skipping the batch 25580 with size 90
rank: 3 test_accu: 2554229.0
get out
3 has test check 2554229.0 and sample count 3274240
Finished training it 41984/76743 of epoch 3, 50.25 ms/it, loss 0.321988
Testing at - 40960/76743 of epoch 3,
Warning: Skipping the batch 25580 with size 90
rank: 1 test_accu: 2554229.0
get out
1 has test check 2554229.0 and sample count 3274240
Finished training it 41984/76743 of epoch 3, 50.02 ms/it, loss 0.322954
Testing at - 40960/76743 of epoch 3,
Warning: Skipping the batch 25580 with size 90
rank: 2 test_accu: 2554229.0
get out
2 has test check 2554229.0 and sample count 3274240
Finished training it 41984/76743 of epoch 3, 49.61 ms/it, loss 0.323361
Finished training it 41984/76743 of epoch 3, 50.27 ms/it, loss 0.323739
Finished training it 43008/76743 of epoch 3, 49.43 ms/it, loss 0.323484
Finished training it 43008/76743 of epoch 3, 48.88 ms/it, loss 0.320952
Finished training it 43008/76743 of epoch 3, 48.97 ms/it, loss 0.321435
Finished training it 43008/76743 of epoch 3, 49.37 ms/it, loss 0.322765
Finished training it 44032/76743 of epoch 3, 50.32 ms/it, loss 0.323251
Finished training it 44032/76743 of epoch 3, 50.73 ms/it, loss 0.319736
Finished training it 44032/76743 of epoch 3, 49.89 ms/it, loss 0.322561
Finished training it 44032/76743 of epoch 3, 50.42 ms/it, loss 0.321161
Finished training it 45056/76743 of epoch 3, 49.50 ms/it, loss 0.320614
Finished training it 45056/76743 of epoch 3, 50.05 ms/it, loss 0.322223
Finished training it 45056/76743 of epoch 3, 50.28 ms/it, loss 0.323525
Finished training it 45056/76743 of epoch 3, 49.80 ms/it, loss 0.323914
Finished training it 46080/76743 of epoch 3, 50.45 ms/it, loss 0.319705
Finished training it 46080/76743 of epoch 3, 49.78 ms/it, loss 0.321203
Finished training it 46080/76743 of epoch 3, 49.79 ms/it, loss 0.321250
Finished training it 46080/76743 of epoch 3, 49.50 ms/it, loss 0.318927
Finished training it 47104/76743 of epoch 3, 58.33 ms/it, loss 0.320555
Finished training it 47104/76743 of epoch 3, 54.31 ms/it, loss 0.317258
Finished training it 47104/76743 of epoch 3, 57.08 ms/it, loss 0.321132
Finished training it 47104/76743 of epoch 3, 57.29 ms/it, loss 0.322154
Finished training it 48128/76743 of epoch 3, 45.10 ms/it, loss 0.321553
Finished training it 48128/76743 of epoch 3, 45.32 ms/it, loss 0.320053
Finished training it 48128/76743 of epoch 3, 45.56 ms/it, loss 0.321714
Finished training it 48128/76743 of epoch 3, 45.96 ms/it, loss 0.320738
Finished training it 49152/76743 of epoch 3, 45.17 ms/it, loss 0.318493
Finished training it 49152/76743 of epoch 3, 44.63 ms/it, loss 0.319382
Finished training it 49152/76743 of epoch 3, 45.06 ms/it, loss 0.317811
Finished training it 49152/76743 of epoch 3, 45.14 ms/it, loss 0.317218
Finished training it 50176/76743 of epoch 3, 48.10 ms/it, loss 0.315617
Finished training it 50176/76743 of epoch 3, 48.34 ms/it, loss 0.318863
Finished training it 50176/76743 of epoch 3, 48.36 ms/it, loss 0.316411
Finished training it 50176/76743 of epoch 3, 47.49 ms/it, loss 0.318584
Finished training it 51200/76743 of epoch 3, 50.04 ms/it, loss 0.317342
Finished training it 51200/76743 of epoch 3, 49.46 ms/it, loss 0.320686
Finished training it 51200/76743 of epoch 3, 49.91 ms/it, loss 0.316218
Finished training it 51200/76743 of epoch 3, 49.76 ms/it, loss 0.317776
Testing at - 51200/76743 of epoch 3,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216Warning: Skipping the batch 25580 with size 90
rank: 0 test_accu: 2538168.0
get out
0 has test check 2538168.0 and sample count 3274240
 accuracy 77.519 %, best 78.729 %, roc auc score 0.7716, best 0.7998
Finished training it 52224/76743 of epoch 3, 49.93 ms/it, loss 0.315524
Testing at - 51200/76743 of epoch 3,
Warning: Skipping the batch 25580 with size 90
rank: 3 test_accu: 2538168.0
get out
3 has test check 2538168.0 and sample count 3274240
Finished training it 52224/76743 of epoch 3, 50.04 ms/it, loss 0.320837
Testing at - 51200/76743 of epoch 3,
Warning: Skipping the batch 25580 with size 90
rank: 2 test_accu: 2538168.0
get out
2 has test check 2538168.0 and sample count 3274240
Finished training it 52224/76743 of epoch 3, 49.45 ms/it, loss 0.319920
Testing at - 51200/76743 of epoch 3,
Warning: Skipping the batch 25580 with size 90
rank: 1 test_accu: 2538168.0
get out
1 has test check 2538168.0 and sample count 3274240
Finished training it 52224/76743 of epoch 3, 49.78 ms/it, loss 0.317802
Finished training it 53248/76743 of epoch 3, 50.19 ms/it, loss 0.319483
Finished training it 53248/76743 of epoch 3, 50.23 ms/it, loss 0.317407
Finished training it 53248/76743 of epoch 3, 49.52 ms/it, loss 0.315573
Finished training it 53248/76743 of epoch 3, 50.59 ms/it, loss 0.319410
Finished training it 54272/76743 of epoch 3, 50.19 ms/it, loss 0.315200
Finished training it 54272/76743 of epoch 3, 49.88 ms/it, loss 0.318212
Finished training it 54272/76743 of epoch 3, 49.05 ms/it, loss 0.317837
Finished training it 54272/76743 of epoch 3, 49.75 ms/it, loss 0.316814
Finished training it 55296/76743 of epoch 3, 50.44 ms/it, loss 0.318756
Finished training it 55296/76743 of epoch 3, 49.75 ms/it, loss 0.318015
Finished training it 55296/76743 of epoch 3, 50.20 ms/it, loss 0.317837
Finished training it 55296/76743 of epoch 3, 49.41 ms/it, loss 0.317228
Finished training it 56320/76743 of epoch 3, 49.83 ms/it, loss 0.316124
Finished training it 56320/76743 of epoch 3, 49.37 ms/it, loss 0.317588
Finished training it 56320/76743 of epoch 3, 49.46 ms/it, loss 0.317540
Finished training it 56320/76743 of epoch 3, 49.97 ms/it, loss 0.317905
Finished training it 57344/76743 of epoch 3, 48.81 ms/it, loss 0.315220
Finished training it 57344/76743 of epoch 3, 48.52 ms/it, loss 0.317108
Finished training it 57344/76743 of epoch 3, 49.20 ms/it, loss 0.316398
Finished training it 57344/76743 of epoch 3, 48.59 ms/it, loss 0.317394
Finished training it 58368/76743 of epoch 3, 44.99 ms/it, loss 0.316248
Finished training it 58368/76743 of epoch 3, 45.22 ms/it, loss 0.314598
Finished training it 58368/76743 of epoch 3, 45.49 ms/it, loss 0.316120
Finished training it 58368/76743 of epoch 3, 45.39 ms/it, loss 0.315805
Finished training it 59392/76743 of epoch 3, 45.60 ms/it, loss 0.314208
Finished training it 59392/76743 of epoch 3, 45.94 ms/it, loss 0.317103
Finished training it 59392/76743 of epoch 3, 45.17 ms/it, loss 0.315568
Finished training it 59392/76743 of epoch 3, 45.20 ms/it, loss 0.316204
Finished training it 60416/76743 of epoch 3, 49.18 ms/it, loss 0.315956
Finished training it 60416/76743 of epoch 3, 48.87 ms/it, loss 0.312578
Finished training it 60416/76743 of epoch 3, 48.89 ms/it, loss 0.316647
Finished training it 60416/76743 of epoch 3, 48.50 ms/it, loss 0.314399
Finished training it 61440/76743 of epoch 3, 49.31 ms/it, loss 0.316171
Finished training it 61440/76743 of epoch 3, 49.67 ms/it, loss 0.316279
Finished training it 61440/76743 of epoch 3, 50.28 ms/it, loss 0.317867
Finished training it 61440/76743 of epoch 3, 49.62 ms/it, loss 0.314810
Testing at - 61440/76743 of epoch 3,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216Warning: Skipping the batch 25580 with size 90
rank: 0 test_accu: 2553811.0
get out
0 has test check 2553811.0 and sample count 3274240
 accuracy 77.997 %, best 78.729 %, roc auc score 0.7611, best 0.7998
Testing at - 61440/76743 of epoch 3,
Warning: Skipping the batch 25580 with size 90
rank: 1 test_accu: 2553811.0
get out
1 has test check 2553811.0 and sample count 3274240
Finished training it 62464/76743 of epoch 3, 49.43 ms/it, loss 0.314182
Testing at - 61440/76743 of epoch 3,
Warning: Skipping the batch 25580 with size 90
rank: 3 test_accu: 2553811.0
get out
3 has test check 2553811.0 and sample count 3274240
Finished training it 62464/76743 of epoch 3, 49.88 ms/it, loss 0.316003
Testing at - 61440/76743 of epoch 3,
Warning: Skipping the batch 25580 with size 90
rank: 2 test_accu: 2553811.0
get out
2 has test check 2553811.0 and sample count 3274240
Finished training it 62464/76743 of epoch 3, 48.97 ms/it, loss 0.316989
Finished training it 62464/76743 of epoch 3, 49.51 ms/it, loss 0.315613
Finished training it 63488/76743 of epoch 3, 49.30 ms/it, loss 0.317296
Finished training it 63488/76743 of epoch 3, 50.15 ms/it, loss 0.312516
Finished training it 63488/76743 of epoch 3, 49.80 ms/it, loss 0.316508
Finished training it 63488/76743 of epoch 3, 49.67 ms/it, loss 0.313599
Finished training it 64512/76743 of epoch 3, 50.15 ms/it, loss 0.314611
Finished training it 64512/76743 of epoch 3, 49.99 ms/it, loss 0.315849
Finished training it 64512/76743 of epoch 3, 49.35 ms/it, loss 0.316614
Finished training it 64512/76743 of epoch 3, 49.71 ms/it, loss 0.313140
Finished training it 65536/76743 of epoch 3, 49.72 ms/it, loss 0.315097
Finished training it 65536/76743 of epoch 3, 49.25 ms/it, loss 0.314508
Finished training it 65536/76743 of epoch 3, 50.30 ms/it, loss 0.314398
Finished training it 65536/76743 of epoch 3, 50.03 ms/it, loss 0.317181
Finished training it 66560/76743 of epoch 3, 50.42 ms/it, loss 0.318441
Finished training it 66560/76743 of epoch 3, 50.17 ms/it, loss 0.314128
Finished training it 66560/76743 of epoch 3, 49.47 ms/it, loss 0.317248
Finished training it 66560/76743 of epoch 3, 49.87 ms/it, loss 0.314998
Finished training it 67584/76743 of epoch 3, 48.68 ms/it, loss 0.311986
Finished training it 67584/76743 of epoch 3, 49.26 ms/it, loss 0.313943
Finished training it 67584/76743 of epoch 3, 49.27 ms/it, loss 0.313000
Finished training it 67584/76743 of epoch 3, 49.52 ms/it, loss 0.314170
Finished training it 68608/76743 of epoch 3, 45.58 ms/it, loss 0.313449
Finished training it 68608/76743 of epoch 3, 45.80 ms/it, loss 0.314896
Finished training it 68608/76743 of epoch 3, 45.36 ms/it, loss 0.313280
Finished training it 68608/76743 of epoch 3, 45.25 ms/it, loss 0.315939
Finished training it 69632/76743 of epoch 3, 45.61 ms/it, loss 0.314358
Finished training it 69632/76743 of epoch 3, 45.49 ms/it, loss 0.311159
Finished training it 69632/76743 of epoch 3, 45.08 ms/it, loss 0.311578
Finished training it 69632/76743 of epoch 3, 45.84 ms/it, loss 0.312776
Finished training it 70656/76743 of epoch 3, 48.29 ms/it, loss 0.312817
Finished training it 70656/76743 of epoch 3, 48.84 ms/it, loss 0.315588
Finished training it 70656/76743 of epoch 3, 49.01 ms/it, loss 0.312820
Finished training it 70656/76743 of epoch 3, 48.46 ms/it, loss 0.312398
Finished training it 71680/76743 of epoch 3, 49.58 ms/it, loss 0.314297
Finished training it 71680/76743 of epoch 3, 49.64 ms/it, loss 0.311953
Finished training it 71680/76743 of epoch 3, 49.76 ms/it, loss 0.314541
Finished training it 71680/76743 of epoch 3, 49.14 ms/it, loss 0.314405
Testing at - 71680/76743 of epoch 3,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216Warning: Skipping the batch 25580 with size 90
rank: 0 test_accu: 2558397.0
get out
0 has test check 2558397.0 and sample count 3274240
 accuracy 78.137 %, best 78.729 %, roc auc score 0.7567, best 0.7998
Finished training it 72704/76743 of epoch 3, 49.87 ms/it, loss 0.312988
Testing at - 71680/76743 of epoch 3,
Warning: Skipping the batch 25580 with size 90
rank: 1 test_accu: 2558397.0
get out
1 has test check 2558397.0 and sample count 3274240
Finished training it 72704/76743 of epoch 3, 49.67 ms/it, loss 0.314728
Testing at - 71680/76743 of epoch 3,
Warning: Skipping the batch 25580 with size 90
rank: 3 test_accu: 2558397.0
get out
3 has test check 2558397.0 and sample count 3274240
Finished training it 72704/76743 of epoch 3, 49.87 ms/it, loss 0.312988
Testing at - 71680/76743 of epoch 3,
Warning: Skipping the batch 25580 with size 90
rank: 2 test_accu: 2558397.0
get out
2 has test check 2558397.0 and sample count 3274240
Finished training it 72704/76743 of epoch 3, 49.29 ms/it, loss 0.313979
Finished training it 73728/76743 of epoch 3, 48.97 ms/it, loss 0.313749
Finished training it 73728/76743 of epoch 3, 48.51 ms/it, loss 0.313300
Finished training it 73728/76743 of epoch 3, 48.98 ms/it, loss 0.315106
Finished training it 73728/76743 of epoch 3, 49.09 ms/it, loss 0.311583
Finished training it 74752/76743 of epoch 3, 49.55 ms/it, loss 0.314398
Finished training it 74752/76743 of epoch 3, 48.99 ms/it, loss 0.314682
Finished training it 74752/76743 of epoch 3, 49.68 ms/it, loss 0.313584
Finished training it 74752/76743 of epoch 3, 50.05 ms/it, loss 0.312293
Finished training it 75776/76743 of epoch 3, 50.15 ms/it, loss 0.314809
Finished training it 75776/76743 of epoch 3, 49.95 ms/it, loss 0.311228
Finished training it 75776/76743 of epoch 3, 49.42 ms/it, loss 0.315065
Finished training it 75776/76743 of epoch 3, 49.92 ms/it, loss 0.313610
Warning: Skipping the batch 76742 with size 14
Finished training it 1024/76743 of epoch 4, 53.20 ms/it, loss 0.313498
Warning: Skipping the batch 76742 with size 14
Finished training it 1024/76743 of epoch 4, 53.39 ms/it, loss 0.314110
Warning: Skipping the batch 76742 with size 14
Finished training it 1024/76743 of epoch 4, 52.90 ms/it, loss 0.312837
Warning: Skipping the batch 76742 with size 14
Finished training it 1024/76743 of epoch 4, 52.80 ms/it, loss 0.312705
Finished training it 2048/76743 of epoch 4, 50.30 ms/it, loss 0.313879
Finished training it 2048/76743 of epoch 4, 50.47 ms/it, loss 0.312649
Finished training it 2048/76743 of epoch 4, 50.14 ms/it, loss 0.312006
Finished training it 2048/76743 of epoch 4, 49.54 ms/it, loss 0.313263
Finished training it 3072/76743 of epoch 4, 49.40 ms/it, loss 0.312843
Finished training it 3072/76743 of epoch 4, 50.09 ms/it, loss 0.313060
Finished training it 3072/76743 of epoch 4, 49.34 ms/it, loss 0.312405
Finished training it 3072/76743 of epoch 4, 49.62 ms/it, loss 0.313263
Finished training it 4096/76743 of epoch 4, 50.14 ms/it, loss 0.313682
Finished training it 4096/76743 of epoch 4, 50.52 ms/it, loss 0.313444
Finished training it 4096/76743 of epoch 4, 49.96 ms/it, loss 0.314195
Finished training it 4096/76743 of epoch 4, 49.43 ms/it, loss 0.315989
Finished training it 5120/76743 of epoch 4, 49.33 ms/it, loss 0.311398
Finished training it 5120/76743 of epoch 4, 49.88 ms/it, loss 0.312004
Finished training it 5120/76743 of epoch 4, 50.03 ms/it, loss 0.312834
Finished training it 5120/76743 of epoch 4, 49.83 ms/it, loss 0.311746
Finished training it 6144/76743 of epoch 4, 48.52 ms/it, loss 0.316559
Finished training it 6144/76743 of epoch 4, 47.95 ms/it, loss 0.314124
Finished training it 6144/76743 of epoch 4, 48.99 ms/it, loss 0.312496
Finished training it 6144/76743 of epoch 4, 48.81 ms/it, loss 0.315009
Finished training it 7168/76743 of epoch 4, 45.38 ms/it, loss 0.313397
Finished training it 7168/76743 of epoch 4, 45.38 ms/it, loss 0.313630
Finished training it 7168/76743 of epoch 4, 45.04 ms/it, loss 0.314259
Finished training it 7168/76743 of epoch 4, 44.88 ms/it, loss 0.311740
Finished training it 8192/76743 of epoch 4, 46.03 ms/it, loss 0.313652
Finished training it 8192/76743 of epoch 4, 45.76 ms/it, loss 0.315017
Finished training it 8192/76743 of epoch 4, 45.62 ms/it, loss 0.314105
Finished training it 8192/76743 of epoch 4, 46.10 ms/it, loss 0.317236
Finished training it 9216/76743 of epoch 4, 48.95 ms/it, loss 0.313189
Finished training it 9216/76743 of epoch 4, 49.44 ms/it, loss 0.314383
Finished training it 9216/76743 of epoch 4, 49.19 ms/it, loss 0.314475
Finished training it 9216/76743 of epoch 4, 48.46 ms/it, loss 0.314344
Finished training it 10240/76743 of epoch 4, 49.74 ms/it, loss 0.317533
Finished training it 10240/76743 of epoch 4, 49.45 ms/it, loss 0.313379
Finished training it 10240/76743 of epoch 4, 50.13 ms/it, loss 0.313159
Finished training it 10240/76743 of epoch 4, 49.94 ms/it, loss 0.315275
Testing at - 10240/76743 of epoch 4,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216Warning: Skipping the batch 25580 with size 90
rank: 0 test_accu: 2557476.0
get out
0 has test check 2557476.0 and sample count 3274240
 accuracy 78.109 %, best 78.729 %, roc auc score 0.7562, best 0.7998
Testing at - 10240/76743 of epoch 4,
Warning: Skipping the batch 25580 with size 90
rank: 1 test_accu: 2557476.0
get out
1 has test check 2557476.0 and sample count 3274240
Finished training it 11264/76743 of epoch 4, 49.72 ms/it, loss 0.317624
Finished training it 11264/76743 of epoch 4, 49.80 ms/it, loss 0.315444
Testing at - 10240/76743 of epoch 4,
Warning: Skipping the batch 25580 with size 90
rank: 2 test_accu: 2557476.0
get out
2 has test check 2557476.0 and sample count 3274240
Finished training it 11264/76743 of epoch 4, 49.19 ms/it, loss 0.315106
Testing at - 10240/76743 of epoch 4,
Warning: Skipping the batch 25580 with size 90
rank: 3 test_accu: 2557476.0
get out
3 has test check 2557476.0 and sample count 3274240
Finished training it 11264/76743 of epoch 4, 49.93 ms/it, loss 0.317027
Finished training it 12288/76743 of epoch 4, 49.43 ms/it, loss 0.312848
Finished training it 12288/76743 of epoch 4, 49.93 ms/it, loss 0.313795
Finished training it 12288/76743 of epoch 4, 49.91 ms/it, loss 0.312874
Finished training it 12288/76743 of epoch 4, 50.11 ms/it, loss 0.313560
Finished training it 13312/76743 of epoch 4, 49.63 ms/it, loss 0.316064
Finished training it 13312/76743 of epoch 4, 49.83 ms/it, loss 0.314974
Finished training it 13312/76743 of epoch 4, 49.33 ms/it, loss 0.316223
Finished training it 13312/76743 of epoch 4, 50.38 ms/it, loss 0.314410
Finished training it 14336/76743 of epoch 4, 49.57 ms/it, loss 0.314332
Finished training it 14336/76743 of epoch 4, 50.00 ms/it, loss 0.316376
Finished training it 14336/76743 of epoch 4, 49.71 ms/it, loss 0.314481
Finished training it 14336/76743 of epoch 4, 49.09 ms/it, loss 0.315718
Finished training it 15360/76743 of epoch 4, 49.87 ms/it, loss 0.313681
Finished training it 15360/76743 of epoch 4, 49.88 ms/it, loss 0.312195
Finished training it 15360/76743 of epoch 4, 49.75 ms/it, loss 0.314679
Finished training it 15360/76743 of epoch 4, 49.17 ms/it, loss 0.315173
Finished training it 16384/76743 of epoch 4, 47.59 ms/it, loss 0.313463
Finished training it 16384/76743 of epoch 4, 47.91 ms/it, loss 0.313774
Finished training it 16384/76743 of epoch 4, 47.57 ms/it, loss 0.313851
Finished training it 16384/76743 of epoch 4, 47.00 ms/it, loss 0.312987
Finished training it 17408/76743 of epoch 4, 45.44 ms/it, loss 0.314983
Finished training it 17408/76743 of epoch 4, 44.91 ms/it, loss 0.314930
Finished training it 17408/76743 of epoch 4, 45.08 ms/it, loss 0.313508
Finished training it 17408/76743 of epoch 4, 45.63 ms/it, loss 0.315041
Finished training it 18432/76743 of epoch 4, 45.97 ms/it, loss 0.314929
Finished training it 18432/76743 of epoch 4, 46.54 ms/it, loss 0.315096
Finished training it 18432/76743 of epoch 4, 46.16 ms/it, loss 0.315768
Finished training it 18432/76743 of epoch 4, 45.82 ms/it, loss 0.314058
Finished training it 19456/76743 of epoch 4, 50.40 ms/it, loss 0.314094
Finished training it 19456/76743 of epoch 4, 50.83 ms/it, loss 0.313148
Finished training it 19456/76743 of epoch 4, 50.50 ms/it, loss 0.316065
Finished training it 19456/76743 of epoch 4, 49.99 ms/it, loss 0.312083
Finished training it 20480/76743 of epoch 4, 140.22 ms/it, loss 0.313518
Finished training it 20480/76743 of epoch 4, 140.06 ms/it, loss 0.313079
Finished training it 20480/76743 of epoch 4, 140.48 ms/it, loss 0.312484
Finished training it 20480/76743 of epoch 4, 139.31 ms/it, loss 0.310872
Testing at - 20480/76743 of epoch 4,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216Warning: Skipping the batch 25580 with size 90
rank: 0 test_accu: 2557732.0
get out
0 has test check 2557732.0 and sample count 3274240
 accuracy 78.117 %, best 78.729 %, roc auc score 0.7534, best 0.7998
Testing at - 20480/76743 of epoch 4,
Warning: Skipping the batch 25580 with size 90
rank: 3 test_accu: 2557732.0
get out
3 has test check 2557732.0 and sample count 3274240
Finished training it 21504/76743 of epoch 4, 51.43 ms/it, loss 0.314855
Finished training it 21504/76743 of epoch 4, 51.30 ms/it, loss 0.315767
Testing at - 20480/76743 of epoch 4,
Warning: Skipping the batch 25580 with size 90
rank: 2 test_accu: 2557732.0
get out
2 has test check 2557732.0 and sample count 3274240
Finished training it 21504/76743 of epoch 4, 50.79 ms/it, loss 0.314189
Testing at - 20480/76743 of epoch 4,
Warning: Skipping the batch 25580 with size 90
rank: 1 test_accu: 2557732.0
get out
1 has test check 2557732.0 and sample count 3274240
Finished training it 21504/76743 of epoch 4, 51.25 ms/it, loss 0.314318
Finished training it 22528/76743 of epoch 4, 51.12 ms/it, loss 0.314886
Finished training it 22528/76743 of epoch 4, 51.14 ms/it, loss 0.314624
Finished training it 22528/76743 of epoch 4, 50.75 ms/it, loss 0.313983
Finished training it 22528/76743 of epoch 4, 51.49 ms/it, loss 0.314415
Finished training it 23552/76743 of epoch 4, 56.65 ms/it, loss 0.310763
Finished training it 23552/76743 of epoch 4, 57.19 ms/it, loss 0.314099
Finished training it 23552/76743 of epoch 4, 56.69 ms/it, loss 0.315799
Finished training it 23552/76743 of epoch 4, 56.43 ms/it, loss 0.315394
Finished training it 24576/76743 of epoch 4, 51.75 ms/it, loss 0.314861
Finished training it 24576/76743 of epoch 4, 51.78 ms/it, loss 0.313594
Finished training it 24576/76743 of epoch 4, 51.18 ms/it, loss 0.312555
Finished training it 24576/76743 of epoch 4, 51.60 ms/it, loss 0.312497
Finished training it 25600/76743 of epoch 4, 51.94 ms/it, loss 0.314672
Finished training it 25600/76743 of epoch 4, 51.33 ms/it, loss 0.313887
Finished training it 25600/76743 of epoch 4, 52.18 ms/it, loss 0.310626
Finished training it 25600/76743 of epoch 4, 51.76 ms/it, loss 0.312480
Finished training it 26624/76743 of epoch 4, 55.52 ms/it, loss 0.313112
Finished training it 26624/76743 of epoch 4, 53.89 ms/it, loss 0.316162
Finished training it 26624/76743 of epoch 4, 55.71 ms/it, loss 0.314444
Finished training it 26624/76743 of epoch 4, 55.28 ms/it, loss 0.314870
Finished training it 27648/76743 of epoch 4, 45.00 ms/it, loss 0.312421
Finished training it 27648/76743 of epoch 4, 44.64 ms/it, loss 0.312279
Finished training it 27648/76743 of epoch 4, 44.83 ms/it, loss 0.313329
Finished training it 27648/76743 of epoch 4, 44.63 ms/it, loss 0.310631
Finished training it 28672/76743 of epoch 4, 45.65 ms/it, loss 0.312781
Finished training it 28672/76743 of epoch 4, 45.89 ms/it, loss 0.314586
Finished training it 28672/76743 of epoch 4, 45.72 ms/it, loss 0.312389
Finished training it 28672/76743 of epoch 4, 45.89 ms/it, loss 0.314205
Finished training it 29696/76743 of epoch 4, 51.49 ms/it, loss 0.313725
Finished training it 29696/76743 of epoch 4, 51.17 ms/it, loss 0.309844
Finished training it 29696/76743 of epoch 4, 51.60 ms/it, loss 0.314359
Finished training it 29696/76743 of epoch 4, 51.75 ms/it, loss 0.311452
Finished training it 30720/76743 of epoch 4, 52.01 ms/it, loss 0.312374
Finished training it 30720/76743 of epoch 4, 52.30 ms/it, loss 0.312429
Finished training it 30720/76743 of epoch 4, 51.41 ms/it, loss 0.311740
Finished training it 30720/76743 of epoch 4, 52.11 ms/it, loss 0.313377
Testing at - 30720/76743 of epoch 4,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216Warning: Skipping the batch 25580 with size 90
rank: 0 test_accu: 2559398.0
get out
0 has test check 2559398.0 and sample count 3274240
 accuracy 78.168 %, best 78.729 %, roc auc score 0.7515, best 0.7998
Testing at - 30720/76743 of epoch 4,
Warning: Skipping the batch 25580 with size 90
rank: 3 test_accu: 2559398.0
get out
3 has test check 2559398.0 and sample count 3274240
Finished training it 31744/76743 of epoch 4, 51.90 ms/it, loss 0.311049
Testing at - 30720/76743 of epoch 4,
Warning: Skipping the batch 25580 with size 90
rank: 2 test_accu: 2559398.0
get out
2 has test check 2559398.0 and sample count 3274240
Finished training it 31744/76743 of epoch 4, 51.11 ms/it, loss 0.313554
Finished training it 31744/76743 of epoch 4, 51.79 ms/it, loss 0.310291
Testing at - 30720/76743 of epoch 4,
Warning: Skipping the batch 25580 with size 90
rank: 1 test_accu: 2559398.0
get out
1 has test check 2559398.0 and sample count 3274240
Finished training it 31744/76743 of epoch 4, 51.62 ms/it, loss 0.312661
Finished training it 32768/76743 of epoch 4, 51.96 ms/it, loss 0.311990
Finished training it 32768/76743 of epoch 4, 52.50 ms/it, loss 0.312498
Finished training it 32768/76743 of epoch 4, 51.64 ms/it, loss 0.311832
Finished training it 32768/76743 of epoch 4, 52.12 ms/it, loss 0.314227
Finished training it 33792/76743 of epoch 4, 51.82 ms/it, loss 0.311552
Finished training it 33792/76743 of epoch 4, 51.66 ms/it, loss 0.312854
Finished training it 33792/76743 of epoch 4, 51.19 ms/it, loss 0.310697
Finished training it 33792/76743 of epoch 4, 51.48 ms/it, loss 0.312682
Finished training it 34816/76743 of epoch 4, 51.41 ms/it, loss 0.311662
Finished training it 34816/76743 of epoch 4, 51.88 ms/it, loss 0.312241
Finished training it 34816/76743 of epoch 4, 50.84 ms/it, loss 0.312252
Finished training it 34816/76743 of epoch 4, 51.59 ms/it, loss 0.313790
Finished training it 35840/76743 of epoch 4, 51.89 ms/it, loss 0.313636
Finished training it 35840/76743 of epoch 4, 51.64 ms/it, loss 0.312654
Finished training it 35840/76743 of epoch 4, 51.50 ms/it, loss 0.309910
Finished training it 35840/76743 of epoch 4, 51.12 ms/it, loss 0.308832
Finished training it 36864/76743 of epoch 4, 47.93 ms/it, loss 0.309219
Finished training it 36864/76743 of epoch 4, 47.78 ms/it, loss 0.309968
Finished training it 36864/76743 of epoch 4, 48.24 ms/it, loss 0.312453
Finished training it 36864/76743 of epoch 4, 47.47 ms/it, loss 0.312000
Finished training it 37888/76743 of epoch 4, 44.95 ms/it, loss 0.311800
Finished training it 37888/76743 of epoch 4, 45.35 ms/it, loss 0.311619
Finished training it 37888/76743 of epoch 4, 45.28 ms/it, loss 0.311781
Finished training it 37888/76743 of epoch 4, 45.36 ms/it, loss 0.313331
Finished training it 38912/76743 of epoch 4, 46.99 ms/it, loss 0.309937
Finished training it 38912/76743 of epoch 4, 46.88 ms/it, loss 0.312221
Finished training it 38912/76743 of epoch 4, 46.68 ms/it, loss 0.311569
Finished training it 38912/76743 of epoch 4, 46.78 ms/it, loss 0.312875
Finished training it 39936/76743 of epoch 4, 51.48 ms/it, loss 0.309087
Finished training it 39936/76743 of epoch 4, 50.74 ms/it, loss 0.308828
Finished training it 39936/76743 of epoch 4, 51.34 ms/it, loss 0.309559
Finished training it 39936/76743 of epoch 4, 51.60 ms/it, loss 0.310664
Finished training it 40960/76743 of epoch 4, 51.30 ms/it, loss 0.310901
Finished training it 40960/76743 of epoch 4, 50.68 ms/it, loss 0.310749
Finished training it 40960/76743 of epoch 4, 51.48 ms/it, loss 0.312411
Finished training it 40960/76743 of epoch 4, 51.46 ms/it, loss 0.308787
Testing at - 40960/76743 of epoch 4,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216Warning: Skipping the batch 25580 with size 90
rank: 0 test_accu: 2556602.0
get out
0 has test check 2556602.0 and sample count 3274240
 accuracy 78.082 %, best 78.729 %, roc auc score 0.7475, best 0.7998
Finished training it 41984/76743 of epoch 4, 51.56 ms/it, loss 0.312102
Testing at - 40960/76743 of epoch 4,
Warning: Skipping the batch 25580 with size 90
rank: 1 test_accu: 2556602.0
get out
1 has test check 2556602.0 and sample count 3274240
Finished training it 41984/76743 of epoch 4, 51.54 ms/it, loss 0.310133
Testing at - 40960/76743 of epoch 4,
Warning: Skipping the batch 25580 with size 90
rank: 2 test_accu: 2556602.0
get out
2 has test check 2556602.0 and sample count 3274240
Finished training it 41984/76743 of epoch 4, 51.14 ms/it, loss 0.312023
Testing at - 40960/76743 of epoch 4,
Warning: Skipping the batch 25580 with size 90
rank: 3 test_accu: 2556602.0
get out
3 has test check 2556602.0 and sample count 3274240
Finished training it 41984/76743 of epoch 4, 51.88 ms/it, loss 0.309233
Finished training it 43008/76743 of epoch 4, 48.63 ms/it, loss 0.310605
Finished training it 43008/76743 of epoch 4, 48.39 ms/it, loss 0.309472
Finished training it 43008/76743 of epoch 4, 47.93 ms/it, loss 0.308842
Finished training it 43008/76743 of epoch 4, 48.77 ms/it, loss 0.311925
Finished training it 44032/76743 of epoch 4, 43.44 ms/it, loss 0.307589
Finished training it 44032/76743 of epoch 4, 43.20 ms/it, loss 0.311392
Finished training it 44032/76743 of epoch 4, 42.82 ms/it, loss 0.311082
Finished training it 44032/76743 of epoch 4, 43.19 ms/it, loss 0.308154
Finished training it 45056/76743 of epoch 4, 42.07 ms/it, loss 0.308274
Finished training it 45056/76743 of epoch 4, 42.46 ms/it, loss 0.309688
Finished training it 45056/76743 of epoch 4, 42.85 ms/it, loss 0.312083
Finished training it 45056/76743 of epoch 4, 42.46 ms/it, loss 0.311303
Finished training it 46080/76743 of epoch 4, 42.22 ms/it, loss 0.306926
Finished training it 46080/76743 of epoch 4, 43.09 ms/it, loss 0.308305
Finished training it 46080/76743 of epoch 4, 42.85 ms/it, loss 0.310068
Finished training it 46080/76743 of epoch 4, 42.72 ms/it, loss 0.309204
Finished training it 47104/76743 of epoch 4, 43.40 ms/it, loss 0.309599
Finished training it 47104/76743 of epoch 4, 43.78 ms/it, loss 0.309294
Finished training it 47104/76743 of epoch 4, 43.44 ms/it, loss 0.310613
Finished training it 47104/76743 of epoch 4, 43.10 ms/it, loss 0.306631
Finished training it 48128/76743 of epoch 4, 44.88 ms/it, loss 0.308903
Finished training it 48128/76743 of epoch 4, 45.35 ms/it, loss 0.309602
Finished training it 48128/76743 of epoch 4, 44.41 ms/it, loss 0.309991
Finished training it 48128/76743 of epoch 4, 44.95 ms/it, loss 0.308890
Finished training it 49152/76743 of epoch 4, 44.30 ms/it, loss 0.306765
Finished training it 49152/76743 of epoch 4, 43.87 ms/it, loss 0.306988
Finished training it 49152/76743 of epoch 4, 43.81 ms/it, loss 0.306360
Finished training it 49152/76743 of epoch 4, 43.27 ms/it, loss 0.307779
Finished training it 50176/76743 of epoch 4, 43.80 ms/it, loss 0.306861
Finished training it 50176/76743 of epoch 4, 43.67 ms/it, loss 0.304560
Finished training it 50176/76743 of epoch 4, 44.16 ms/it, loss 0.305979
Finished training it 50176/76743 of epoch 4, 43.48 ms/it, loss 0.307305
Finished training it 51200/76743 of epoch 4, 43.38 ms/it, loss 0.305609
Finished training it 51200/76743 of epoch 4, 42.55 ms/it, loss 0.310118
Finished training it 51200/76743 of epoch 4, 43.03 ms/it, loss 0.305987
Finished training it 51200/76743 of epoch 4, 43.12 ms/it, loss 0.306114
Testing at - 51200/76743 of epoch 4,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216Warning: Skipping the batch 25580 with size 90
rank: 0 test_accu: 2551519.0
get out
0 has test check 2551519.0 and sample count 3274240
 accuracy 77.927 %, best 78.729 %, roc auc score 0.7546, best 0.7998
Testing at - 51200/76743 of epoch 4,
Warning: Skipping the batch 25580 with size 90
rank: 3 test_accu: 2551519.0
get out
3 has test check 2551519.0 and sample count 3274240
Finished training it 52224/76743 of epoch 4, 43.51 ms/it, loss 0.309005
Finished training it 52224/76743 of epoch 4, 43.46 ms/it, loss 0.304799
Testing at - 51200/76743 of epoch 4,
Warning: Skipping the batch 25580 with size 90
rank: 2 test_accu: 2551519.0
get out
2 has test check 2551519.0 and sample count 3274240
Finished training it 52224/76743 of epoch 4, 42.88 ms/it, loss 0.308383
Testing at - 51200/76743 of epoch 4,
Warning: Skipping the batch 25580 with size 90
rank: 1 test_accu: 2551519.0
get out
1 has test check 2551519.0 and sample count 3274240
Finished training it 52224/76743 of epoch 4, 43.30 ms/it, loss 0.307759
Finished training it 53248/76743 of epoch 4, 43.66 ms/it, loss 0.308488
Finished training it 53248/76743 of epoch 4, 43.42 ms/it, loss 0.307592
Finished training it 53248/76743 of epoch 4, 43.17 ms/it, loss 0.304808
Finished training it 53248/76743 of epoch 4, 43.37 ms/it, loss 0.308947
Finished training it 54272/76743 of epoch 4, 43.49 ms/it, loss 0.304516
Finished training it 54272/76743 of epoch 4, 43.04 ms/it, loss 0.306982
Finished training it 54272/76743 of epoch 4, 43.12 ms/it, loss 0.306066
Finished training it 54272/76743 of epoch 4, 42.73 ms/it, loss 0.307302
Finished training it 55296/76743 of epoch 4, 43.51 ms/it, loss 0.309949
Finished training it 55296/76743 of epoch 4, 42.93 ms/it, loss 0.306851
Finished training it 55296/76743 of epoch 4, 42.63 ms/it, loss 0.307052
Finished training it 55296/76743 of epoch 4, 42.99 ms/it, loss 0.307962
Finished training it 56320/76743 of epoch 4, 43.08 ms/it, loss 0.308034
Finished training it 56320/76743 of epoch 4, 43.00 ms/it, loss 0.305273
Finished training it 56320/76743 of epoch 4, 43.45 ms/it, loss 0.306963
Finished training it 56320/76743 of epoch 4, 42.78 ms/it, loss 0.306623
Finished training it 57344/76743 of epoch 4, 49.27 ms/it, loss 0.305479
Finished training it 57344/76743 of epoch 4, 50.03 ms/it, loss 0.305837
Finished training it 57344/76743 of epoch 4, 48.73 ms/it, loss 0.307118
Finished training it 57344/76743 of epoch 4, 47.92 ms/it, loss 0.306568
Finished training it 58368/76743 of epoch 4, 43.47 ms/it, loss 0.306080
Finished training it 58368/76743 of epoch 4, 44.01 ms/it, loss 0.305846
Finished training it 58368/76743 of epoch 4, 43.90 ms/it, loss 0.304653
Finished training it 58368/76743 of epoch 4, 44.35 ms/it, loss 0.306319
Finished training it 59392/76743 of epoch 4, 42.73 ms/it, loss 0.305830
Finished training it 59392/76743 of epoch 4, 43.87 ms/it, loss 0.306512
Finished training it 59392/76743 of epoch 4, 43.24 ms/it, loss 0.304806
Finished training it 59392/76743 of epoch 4, 43.43 ms/it, loss 0.304110
Finished training it 60416/76743 of epoch 4, 44.07 ms/it, loss 0.303220
Finished training it 60416/76743 of epoch 4, 44.43 ms/it, loss 0.305485
Finished training it 60416/76743 of epoch 4, 43.41 ms/it, loss 0.304181
Finished training it 60416/76743 of epoch 4, 43.90 ms/it, loss 0.306444
Finished training it 61440/76743 of epoch 4, 43.31 ms/it, loss 0.306320
Finished training it 61440/76743 of epoch 4, 42.75 ms/it, loss 0.306523
Finished training it 61440/76743 of epoch 4, 43.28 ms/it, loss 0.304312
Finished training it 61440/76743 of epoch 4, 43.66 ms/it, loss 0.308075
Testing at - 61440/76743 of epoch 4,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216Warning: Skipping the batch 25580 with size 90
rank: 0 test_accu: 2554871.0
get out
0 has test check 2554871.0 and sample count 3274240
 accuracy 78.029 %, best 78.729 %, roc auc score 0.7528, best 0.7998
Finished training it 62464/76743 of epoch 4, 42.68 ms/it, loss 0.305671
Testing at - 61440/76743 of epoch 4,
Warning: Skipping the batch 25580 with size 90
rank: 3 test_accu: 2554871.0
get out
3 has test check 2554871.0 and sample count 3274240
Finished training it 62464/76743 of epoch 4, 42.97 ms/it, loss 0.305162
Testing at - 61440/76743 of epoch 4,
Warning: Skipping the batch 25580 with size 90
rank: 1 test_accu: 2554871.0
get out
1 has test check 2554871.0 and sample count 3274240
Finished training it 62464/76743 of epoch 4, 42.91 ms/it, loss 0.303842
Testing at - 61440/76743 of epoch 4,
Warning: Skipping the batch 25580 with size 90
rank: 2 test_accu: 2554871.0
get out
2 has test check 2554871.0 and sample count 3274240
Finished training it 62464/76743 of epoch 4, 42.34 ms/it, loss 0.306193
Finished training it 63488/76743 of epoch 4, 43.13 ms/it, loss 0.303755
Finished training it 63488/76743 of epoch 4, 43.38 ms/it, loss 0.302604
Finished training it 63488/76743 of epoch 4, 43.13 ms/it, loss 0.306739
Finished training it 63488/76743 of epoch 4, 42.77 ms/it, loss 0.307163
Finished training it 64512/76743 of epoch 4, 42.42 ms/it, loss 0.306485
Finished training it 64512/76743 of epoch 4, 42.92 ms/it, loss 0.302529
Finished training it 64512/76743 of epoch 4, 43.31 ms/it, loss 0.304193
Finished training it 64512/76743 of epoch 4, 42.91 ms/it, loss 0.306286
Finished training it 65536/76743 of epoch 4, 42.47 ms/it, loss 0.305215
Finished training it 65536/76743 of epoch 4, 42.99 ms/it, loss 0.304945
Finished training it 65536/76743 of epoch 4, 42.50 ms/it, loss 0.307092
Finished training it 65536/76743 of epoch 4, 42.27 ms/it, loss 0.304810
Finished training it 66560/76743 of epoch 4, 43.05 ms/it, loss 0.308657
Finished training it 66560/76743 of epoch 4, 42.72 ms/it, loss 0.304627
Finished training it 66560/76743 of epoch 4, 42.92 ms/it, loss 0.305194
Finished training it 66560/76743 of epoch 4, 42.42 ms/it, loss 0.308720
Finished training it 67584/76743 of epoch 4, 43.89 ms/it, loss 0.302994
Finished training it 67584/76743 of epoch 4, 43.86 ms/it, loss 0.303911
Finished training it 67584/76743 of epoch 4, 43.40 ms/it, loss 0.301961
Finished training it 67584/76743 of epoch 4, 43.94 ms/it, loss 0.304666
Finished training it 68608/76743 of epoch 4, 42.68 ms/it, loss 0.306016
Finished training it 68608/76743 of epoch 4, 43.62 ms/it, loss 0.304649
Finished training it 68608/76743 of epoch 4, 43.49 ms/it, loss 0.303401
Finished training it 68608/76743 of epoch 4, 43.31 ms/it, loss 0.303097
Finished training it 69632/76743 of epoch 4, 44.22 ms/it, loss 0.303658
Finished training it 69632/76743 of epoch 4, 44.01 ms/it, loss 0.301736
Finished training it 69632/76743 of epoch 4, 44.47 ms/it, loss 0.303281
Finished training it 69632/76743 of epoch 4, 43.70 ms/it, loss 0.301997
Finished training it 70656/76743 of epoch 4, 43.69 ms/it, loss 0.302893
Finished training it 70656/76743 of epoch 4, 44.25 ms/it, loss 0.303292
Finished training it 70656/76743 of epoch 4, 44.01 ms/it, loss 0.302274
Finished training it 70656/76743 of epoch 4, 44.05 ms/it, loss 0.305452
Finished training it 71680/76743 of epoch 4, 42.90 ms/it, loss 0.304404
Finished training it 71680/76743 of epoch 4, 43.74 ms/it, loss 0.304328
Finished training it 71680/76743 of epoch 4, 43.33 ms/it, loss 0.301504
Finished training it 71680/76743 of epoch 4, 43.35 ms/it, loss 0.304493
Testing at - 71680/76743 of epoch 4,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216Warning: Skipping the batch 25580 with size 90
rank: 0 test_accu: 2556282.0
get out
0 has test check 2556282.0 and sample count 3274240
 accuracy 78.073 %, best 78.729 %, roc auc score 0.7481, best 0.7998
Testing at - 71680/76743 of epoch 4,
Warning: Skipping the batch 25580 with size 90
rank: 1 test_accu: 2556282.0
get out
1 has test check 2556282.0 and sample count 3274240
Finished training it 72704/76743 of epoch 4, 43.45 ms/it, loss 0.303926
Finished training it 72704/76743 of epoch 4, 43.47 ms/it, loss 0.303299
Testing at - 71680/76743 of epoch 4,
Warning: Skipping the batch 25580 with size 90
rank: 2 test_accu: 2556282.0
get out
2 has test check 2556282.0 and sample count 3274240
Finished training it 72704/76743 of epoch 4, 42.90 ms/it, loss 0.303763
Testing at - 71680/76743 of epoch 4,
Warning: Skipping the batch 25580 with size 90
rank: 3 test_accu: 2556282.0
get out
3 has test check 2556282.0 and sample count 3274240
Finished training it 72704/76743 of epoch 4, 43.59 ms/it, loss 0.302215
Finished training it 73728/76743 of epoch 4, 44.23 ms/it, loss 0.303933
Finished training it 73728/76743 of epoch 4, 44.35 ms/it, loss 0.304739
Finished training it 73728/76743 of epoch 4, 44.44 ms/it, loss 0.301355
Finished training it 73728/76743 of epoch 4, 43.60 ms/it, loss 0.303571
Finished training it 74752/76743 of epoch 4, 43.52 ms/it, loss 0.304433
Finished training it 74752/76743 of epoch 4, 43.87 ms/it, loss 0.302682
Finished training it 74752/76743 of epoch 4, 43.18 ms/it, loss 0.305638
Finished training it 74752/76743 of epoch 4, 43.51 ms/it, loss 0.304920
Finished training it 75776/76743 of epoch 4, 43.48 ms/it, loss 0.305074
Finished training it 75776/76743 of epoch 4, 43.89 ms/it, loss 0.300913
Finished training it 75776/76743 of epoch 4, 44.12 ms/it, loss 0.305247
Finished training it 75776/76743 of epoch 4, 43.80 ms/it, loss 0.303486
Warning: Skipping the batch 76742 with size 14
Testing at - 76743/76743 of epoch 5,
steps testing: 0.0steps testing: 0.007818302646495447steps testing: 0.015636605292990893steps testing: 0.023454907939486336steps testing: 0.03127321058598179steps testing: 0.039091513232477226steps testing: 0.04690981587897267steps testing: 0.05472811852546812steps testing: 0.06254642117196357steps testing: 0.07036472381845901steps testing: 0.07818302646495445steps testing: 0.0860013291114499steps testing: 0.09381963175794535steps testing: 0.1016379344044408steps testing: 0.10945623705093624steps testing: 0.11727453969743169steps testing: 0.12509284234392715steps testing: 0.13291114499042259steps testing: 0.14072944763691803steps testing: 0.14854775028341347steps testing: 0.1563660529299089steps testing: 0.16418435557640437steps testing: 0.1720026582228998steps testing: 0.17982096086939525steps testing: 0.1876392635158907steps testing: 0.19545756616238616steps testing: 0.2032758688088816steps testing: 0.21109417145537704steps testing: 0.21891247410187248steps testing: 0.22673077674836792steps testing: 0.23454907939486339steps testing: 0.24236738204135883steps testing: 0.2501856846878543steps testing: 0.2580039873343497steps testing: 0.26582228998084517steps testing: 0.2736405926273406steps testing: 0.28145889527383605steps testing: 0.2892771979203315steps testing: 0.29709550056682693steps testing: 0.3049138032133224steps testing: 0.3127321058598178steps testing: 0.3205504085063133steps testing: 0.32836871115280875steps testing: 0.33618701379930416steps testing: 0.3440053164457996steps testing: 0.35182361909229504steps testing: 0.3596419217387905steps testing: 0.36746022438528597steps testing: 0.3752785270317814steps testing: 0.38309682967827685steps testing: 0.3909151323247723steps testing: 0.39873343497126773steps testing: 0.4065517376177632steps testing: 0.4143700402642586steps testing: 0.4221883429107541steps testing: 0.43000664555724954steps testing: 0.43782494820374496steps testing: 0.4456432508502404steps testing: 0.45346155349673584steps testing: 0.4612798561432313steps testing: 0.46909815878972677steps testing: 0.4769164614362222steps testing: 0.48473476408271765steps testing: 0.49255306672921306steps testing: 0.5003713693757086steps testing: 0.508189672022204steps testing: 0.5160079746686994steps testing: 0.5238262773151948steps testing: 0.5316445799616903steps testing: 0.5394628826081858steps testing: 0.5472811852546812steps testing: 0.5550994879011767steps testing: 0.5629177905476721steps testing: 0.5707360931941675steps testing: 0.578554395840663steps testing: 0.5863726984871585steps testing: 0.5941910011336539steps testing: 0.6020093037801493steps testing: 0.6098276064266448steps testing: 0.6176459090731402steps testing: 0.6254642117196356steps testing: 0.6332825143661311steps testing: 0.6411008170126266steps testing: 0.648919119659122steps testing: 0.6567374223056175steps testing: 0.6645557249521129steps testing: 0.6723740275986083steps testing: 0.6801923302451038steps testing: 0.6880106328915992steps testing: 0.6958289355380947steps testing: 0.7036472381845901steps testing: 0.7114655408310856steps testing: 0.719283843477581steps testing: 0.7271021461240764steps testing: 0.7349204487705719steps testing: 0.7427387514170674steps testing: 0.7505570540635628steps testing: 0.7583753567100583steps testing: 0.7661936593565537steps testing: 0.7740119620030491steps testing: 0.7818302646495446steps testing: 0.78964856729604steps testing: 0.7974668699425355steps testing: 0.8052851725890309steps testing: 0.8131034752355264steps testing: 0.8209217778820218steps testing: 0.8287400805285172steps testing: 0.8365583831750127steps testing: 0.8443766858215082steps testing: 0.8521949884680036steps testing: 0.8600132911144991steps testing: 0.8678315937609945steps testing: 0.8756498964074899steps testing: 0.8834681990539853steps testing: 0.8912865017004808steps testing: 0.8991048043469763steps testing: 0.9069231069934717steps testing: 0.9147414096399672steps testing: 0.9225597122864626steps testing: 0.930378014932958steps testing: 0.9381963175794535steps testing: 0.946014620225949steps testing: 0.9538329228724444steps testing: 0.9616512255189399steps testing: 0.9694695281654353steps testing: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216Warning: Skipping the batch 25580 with size 90
rank: 0 test_accu: 2557275.0
get out
0 has test check 2557275.0 and sample count 3274240
 accuracy 78.103 %, best 78.729 %, roc auc score 0.7431, best 0.7998
Warning: Skipping the batch 76742 with size 14
Testing at - 76743/76743 of epoch 5,
Warning: Skipping the batch 25580 with size 90
rank: 3 test_accu: 2557275.0
get out
3 has test check 2557275.0 and sample count 3274240
Warning: Skipping the batch 76742 with size 14
Testing at - 76743/76743 of epoch 5,
Warning: Skipping the batch 25580 with size 90
rank: 1 test_accu: 2557275.0
get out
1 has test check 2557275.0 and sample count 3274240
Warning: Skipping the batch 76742 with size 14
Testing at - 76743/76743 of epoch 5,
Warning: Skipping the batch 25580 with size 90
rank: 2 test_accu: 2557275.0
get out
2 has test check 2557275.0 and sample count 3274240
ng: 0.9772878308119307steps testing: 0.9851061334584261steps testing: 0.9929244361049216Warning: Skipping the batch 25580 with size 90
rank: 0 test_accu: 2547953.0
get out
0 has test check 2547953.0 and sample count 3274240
 accuracy 77.818 %, best 77.835 %, roc auc score 0.7782, best 0.7782
Warning: Skipping the batch 76742 with size 14
Testing at - 76743/76743 of epoch 5,
Warning: Skipping the batch 25580 with size 90
rank: 3 test_accu: 2547953.0
get out
3 has test check 2547953.0 and sample count 3274240
Warning: Skipping the batch 76742 with size 14
Testing at - 76743/76743 of epoch 5,
Warning: Skipping the batch 25580 with size 90
rank: 1 test_accu: 2547953.0
get out
1 has test check 2547953.0 and sample count 3274240
Warning: Skipping the batch 76742 with size 14
Testing at - 76743/76743 of epoch 5,
Warning: Skipping the batch 25580 with size 90
rank: 2 test_accu: 2547953.0
get out
2 has test check 2547953.0 and sample count 3274240
